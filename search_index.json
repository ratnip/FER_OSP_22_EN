[["index.html", "Let’s program in R (“Statistical Programming Fundamentals” course book) Foreword", " Let’s program in R Damir Pintar 2022-12-07 (“Statistical Programming Fundamentals” course book) ** NOTE: During the current academic year, the “Statistical Programming Fundamentals” is revised chapter by chapter. After the subject is New chapters will be dynamically added to this HTML document. If you need to have access to all the materials, contact the author of the tutorial at damir.pintar@fer.hr** Foreword This tutorial is based on interactive lessons used in the “Statistical Programming Fundamentals” at the Faculty of Electrical Engineering and Computing at the University of Zagreb. But the topics discussed here are not only useful to the students of the mentioned faculty - knowledge of the language R will be good both in academia and in the business world. Although R is known as a “programming language made up of statisticians, for statisticians” and is most often associated with the field of data science within which it is used for complex statistical analysis and data mining, it can be very useful for tasks related to the management of smaller or larger data at tasks that are not necessarily strictly oriented to advanced analytics. Namely, popular graphical tools with their interactive tabular presentation are very intuitive and excellent for simpler tasks, but as the need for more complex tasks appears, they quickly lose their efficiency and simplicity; on the other hand, the interactive program approach offered by R is initially somewhat more demanding but long-term highly cost-effective because complex tasks can be dealt with in an efficient, consistent and insightful way. For this reason, in the business world there is a clear shifting trend from classic GUI office tools to platforms with better support for more complex calculations and the creation of attractive visualizations. This is evidenced by a strong increase in the popularity of R language and other platforms with similar approach to data analysis. The aforementioned popularity of R language results in an increased need for learning resources, which are not currently very much present in Croatia. This coursebook will try to make learning R as easy and interesting as possible through its “learning through examples” approach. Emphasis will be placed primarily on mastering R as a programming language. For this reason, the initial chapters will focus on “programmatical aspects”, followed by a review of available tools presumed to be useful for the widest set of readers - tools for data gathering, extracting useful information, and visualizations. Since R is a domain-oriented language, R’s role in its support for statistical analysis will be reviewed followed byexamining selected machine learning methods and their applications. Although there will be enough information to put all the presented methods into context, the idea of this textbook is not to teach readers statistics nor deeply enter the field of machine learning - the intention of the author is to intrigue readers to continue exploring this interesting area, adequately armed with platform knowledge that will enable all new knowledge is immediately practically applied in further research. "],["introduction.html", "1 Introduction 1.1 What is R? 1.2 Installing Software Support 1.3 Overview of the development interface RStudio 1.4 How to use this coursebook?", " 1 Introduction 1.1 What is R? 1.1.1 General facts about R Programming language R came from the programming language S, developed for the needs of Bell Telephone Laboratory owned by AT &amp; T corporation. It was designed as an internal statistical analysis tool. The basic philosophy of the S language (inherited by the programming language R) was domain orientation - ie facilitating work with data analysts without the need to adapt conventions to traditional programming languages. Language S gained significant popularity in business analysts and statisticians within the 80s and 90s, but is now only available through a commercial variant called S-PLUS. The programming language R was created at the University of Auckland (NZ) and is released under the GNU Open Code Code. The standard distribution of the R programming language consists of: “core” R, with basic functions and so called “core” base package that provides basic functionality a collection of additional packages (“base” - base and “recommended” - recommended) for data management, visualization and statistical analysis We must not ignore the excellent integration of R with a rich repository called CRAN (Comprehensive R Archive Network) that enables fast and easy installation of any packet from that repository, after which it becomes part of the local R installation. Since the R community is extremely productive when it comes to the development of new packages, often after the introduction of new experimental methods and algorithms, CRAN quickly offers packages that implement them. Also, strong and continuous enthusiasm of the R community for the enhancement of existing R elements alleviates or eliminates a large number of various deficiencies of the base language. R as a language can often be seen as a DIY project of sorts where, after getting acquainted with the supplied “factory” components (in this case basic functions and packages), the user begins to adapt his development environment by choosing a package that exactly matches their needs and preferences. Creativity and flexibility in using R is considered to be of great advantage, even though it may result in a certain informality and liberal approach to programming. This is occasionally not favoured by users from a more strict and formal programming background, used to having a clear set of guidelines and rules to be followed. Despite the exceptionally high acceptance of the R language for data analysis and the variety of options offered to the user, it is necessary to be aware of some of its limitations: R intensely uses RAM which has been considered a serious restriction for a long time. With the increase of the memory capacity in modern hardware systems, as well as the rise of processing engines which can integrate with R and relieve it of the intense memory requirements when it comes to large datasets, this limitation is much less important today. Still, the fact remains that R can quickly hog the available RAM of your machine, though it is often the result of the neglect or ignorance of a developer who has not adopted the “R” approach when it comes to programming, opting to leverage patterns borrowed from other programming languages which result in suboptimal R code. R is quite unconventional so the learning curve is initially steeper, especially for programmers accustomed to standard conventions of other programming languages. On the other hand, if viewed long-term, programming in R eventually becomes very quite simple and user-friendly since most of the complex tasks are abstracted into high-level functions that transparently perform low-level operative tasks. It is often said that R is more focused towards the goal we want to achieve and cares less about the exact way to reach it. R is not a “fast” language; although it is a language that is expected to work over large data sets, R is not optimized for performance speed or even for parallelism; although there is a great deal of effort to implement virtually all key routines in C which prevents significant slowdowns, and there are a number of packages that offer support for multithreading, the fact remains that R is not designed to have its scripts get executed as quickly as possible; If speed is a priority, it is often necessary to look for alternative solutions - which is why it is often said that R is primarily a research language, not a production language. R is primarily intended for interactive work, i.e. performing a series of machine instructions that are dynamically executed with the help of a program console. This is tailored to the standard process of data analysis where the analyst can download data, clean it, transform, develop models, test, etc. while getting continuous feedback from a computer, providing the opportunity to dynamically adapt the analysis process. This does not mean that programming language can not be programmed in a classical “procedural” way by developing algorithms encapsulated in functions that automatically perform their tasks after being called, however where R truly shines is while performing interactive tasks. This principle is also reflected when it comes to learning R; it’s a programming language which is much easier to learn through the interactive approach of performing specific, goal-oriented tasks, experimenting with data sets, trying out data exploration methods, and so on, rather than using a “classic” approach by designing scripts that implement some low-level programming jobs. 1.1.2 R alternatives Programming Language R is a popular but not the only solution for interactive data analysis and statistical programming. Below we will give a brief overview of some of the more popular technologies and solutions used today for this purpose, with a brief comparison and a review of the advantages and disadvantages compared to language R. SAS and SPSS - SAS (Statistical Analysis System, developed by SAS Institute) and SPSS (Software Package for Statistical Analysis, developed by IBM) are two different software packages that we put under the same paragraph primarily because they are commercial tools, ie tools that require full payment for their full functionality. Similarly, SAS and SPSS are relatively easy to learn and their functionality is largely based on carefully designed user interfaces. These tools emphasize efficiency and are an excellent option for large companies looking for a consistent, robust solution for their analytics, not bothered by the commercial nature of such solutions. Weka and Orange - Weka (Waikato Environment for Knowledge Analysis, developed by Waikato University in New Zealand) and Orange* (deep data analysis software developed at the University of Ljubljana) are free software for exploratory data analysis and data mining that base their functionality on relatively simple graphing interfaces and visual programming approach. These solutions are very good for users who are not too demanding in terms of the flexibility and complexity of their analysis because they allow the implementation of defined steps in the analysis process in a very accessible and clear way. This does not mean that these tools can not do more complex analysis, but they are still more suited to analyses through the predefined functionality of the provided graphical interface. Python (Numpy / Pandas / Scikit) - in the last couple of years, Python is the most serious competitor of language R, primarily because Python is a very popular programming language with a very similar process approach to data analysis compared to one used by language R. The discussion of which language to choose is very common in the field of data science, usually without a clear final conclusion. The actual differences are not as big as those discussions may make it seem - while R is strongly domain-oriented and emphasis is placed on ease of use with a wide range of available overlapping packages to enable the user to choose the one that best suits him, Python emphasizes the rigid formal structure and principle “for one job one way of doing”. Therefore, it could be said that R is somewhat more suitable for “data research” while Python’s advantage is easier development and integration of analytical modules in a production environment, especially if said environment is already implemented in Python. But with the strong development of both languages and the mutual overlapping of functionality, this distinction becomes less relevant - it is no longer a problem to integrate R scripts into existing systems regardless of the platform they are running on, and the Python community is developing its versions of popular packages from R that faithfully emulate their functionality. Ultimately, it can be said that the initial choice between these two alternatives is not so important - the approach they use is so similar and the functionality sharing is so pronounced that learned concepts are easily transferable between both languages. It also must be said that the RStudio environment allows for mixing Python and R code in a single report, further closing the divide between these languages. Rapidminer - this is a cloud-based data science software platform that provides an integrated environment for data preparation, machine learning, deep learning, text mining, and predictive analytics. It is used for business and commercial applications as well as for research, education, training, rapid prototyping, and application development and supports all steps of the machine learning process including data preparation, results visualization, model validation and optimization. Rapidminer is primarily template-based, however it is possible to write extensions for it using R or Python. 1.2 Installing Software Support Installing the R language support software is pretty simple, especially if the recommended development interface RStudio is used as a platform. This is not the only option - one of the popular alternatives is the multilingual platform Jupyter Notebook which offers its own R support. Readers are encouraged to explore all available options and choose the final selection of the interface that personally matches their needs best; however this coursebook strongly recommends choosing RStudio mainly because of a clear, user-friendly and functionality-rich interface, easy installation and a very rich support for a variety of functionalities - from installing new packages, easy retrieval of documentation, creating visualizations and publishing reports, to integrating with other data science-related software. Therefore the rest of the coursebook will assume that readers are using the RStudio IDE. To successfully set up R software, you need to install the following: R language distribution RStudio integrated development environment It is recommended to use the latest available versions. At the time of writing this book, they are R 4.0 and RStudio 1.3. If these versions differ from those on your computer, there will probably be no problem if the version numbers are higher than the above; otherwise, their upgrade is recommended. The procedure for installing this software on the operating system Microsoft Windows will be described below. If you are working on some other operating system, such as a Linux distribution or Mac OS, the procedure is somewhat different, but still not too complex - it’s enough to do a web search focused on installing R and RStudio on a particular OS and follow further instructions. To find the software mentioned in the search engine, type the following terms: download R download RStudio In both cases, you will get links to the executable files that you have to run to install the software on your computer. In the case of R, this can be a file R-4.2.2-win.exe (exact numbers may differ). In the interface RStudio you can see more options - choose a free “desktop” version. Commercial versions have some additional functionalities that are mostly oriented to use in professional multi-user environments and are not essential to normal work. You can run the executable files and let the wizard install all the necessary components on your computer. It is recommended to accept all of the default installation options except for the choice of the installation folder - instead of the subfolder Program Files “it is better to install R directly in the root folder (eg”C:\\R\\R-4.2.2”), if possible. This way, it will be easier to check the currently installed version and potentially update it later. For the same reason, it is recommended that RStudio be installed in the folder “C:\\R\\RStudio”. If you do not have the option or you do not want to choose these folders, you can use others or leave the default options - this choice should not ultimately affect the further work. After installing RStudio it is highly recommended you create a separate subfolder where you will be doing most of your R related work (for example, folder “C:\\R\\projects”). After launching RStudio, the application should look similar to the following image: Figure 1.1: RStudio interface layout If there are any problems, make sure that you have completed all of the installation steps listed above. Below we will deal with the details of the interface shown. Before continuing, you might consider creating a new “project” (File -&gt; New Project -&gt; New Directory) and create a project called “IntroToR” in the projects folder mentioned above. You can then later put all the resources related to this course in this project folder. When you want to open RStudio and continue working on tasks from this course, it will be enough to double-click the IntroToR.Rproj file in the above subfolder, or choose the “IntroToR” project in the upper right corner of the screen. 1.3 Overview of the development interface RStudio Let’s look at the interface RStudio. We see it is being divided into three windows - the left part is the “work area” with the programming console, waiting for us to enter instructions. On the right, there are auxiliary windows that show different things, depending on the selected tab; In the upper right hand corner, we can see, among other things, variables in our current working environment (which is initially empty). We can also choose to see command history, control connections to other data storage and analysis software etc.. The bottom part serves to display documentation, file structures, installed packages, visualizations, etc. 1.3.1 Interactive console Let’s go back to the left part of the interface, the “interactive console”. R, by its nature, is an “interpreter language” in the sense that the programming console expects from the user to enter commands which are then immediately interpreted and executed. Though it is possible to create larger scripts that are then executed “all at once”, working with the R language often boils down to using command-by-command principle. This is precisely why we are talking about “data analysis via interactive programming” - the analyst is “programming” by entering commands and can at any time study the obtained results, deciding on further steps. Let’s see how the interactive console works. With the help of a keyboard, you can type a simple math expression - eg 3 + 2 - and press the ENTER key. We will see that R will immediately deliver the result - if we want, we can easily use it as a calculator! For mathematical expressions that do not have predefined operator symbols we need to use functions. For example, a square root can be calculated using the sqrt () function. Let’s try typing sqrt(10) in the console and pressing ENTER. R again shows the result immediately. At this point, the screen should look like the next picture. Figure 1.2: R as a calculator One of the problems of using R this way is the messy mixing of commands and results, not allowing us an easy high-level overview of the sequence of commands we were performing. Furthermore, if for some reason the command that we execute results in an error (and we then keep trying to correct it by entering the proper command), the console soon becomes cluttered with error reports. This is why analysts often prefer using “R scripts” that allows for entering commands in a separate place before sending them to the console, visually distinguishing the procedure we want to execute with the obtained results gained after the planned instructions are executed. 1.3.2 Writing R scripts In the toolbar, select File -&gt; New File -&gt; R Script (or press the CTRL + SHIFT + N key combination). We see that the “working area” on the left becomes divided into two parts. The upper part represents the space for our “script” - actually the series of commands we want to execute - while the interactive console now occupies the lower part of the work surface. If we want, we can tweak the size of these (and other windows) by moving the bordering bars between them. Also, there’s an easy way of switching the focus between the two, through the usage of CTRL + 1 and CTRL + 2 key combinations. Try to write two simple commands in the scripting window - the first one should be print(\"hello!\") And underneath it a simple mathematical expression 3 + 4. Return the cursor to the first line and press the CTRL + ENTER key combination. If we have correctly followed these steps, the command at the cursor site will automatically be copied to the interactive console and executed. The cursor will now be the next command that you can do with CTRL + ENTER. The screen should now look similar to the next image. Figure 1.3: R script This is one of the common ways of working in RStudio- first we create some programming instructions in the script space, after which we send them to the console. If something is wrong with the command, we can easily modify it and perform it again. If you want to execute a block of commands, you can select them by clicking and dragging and then pressing the CTRL + ENTER key. Scripts can also contain comments (starting with the # character that R interprets as “ignore this line”). Finally, we can store our scripts in a file - by convention, R scripts have a simple extension R, for example myScript.R. However, we can go one step further. Despite the fact that the R scripts are quite adequate for comfortable work in the R language, there is an additional technology that gives us even more flexibility in working with the R - R Markdown. 1.3.3 R Markdown Writing R scripts is very similar to the classic concept of “programming” - we write commands that are (usually) executed sequentially, and optionally we add comments for the purpose of the documentation. However, data analysis process commonly involves dissemination of results via data science reports, either for the analysts themselves or to the intended audience. RStudio interface supports a technology that provides an effective combination of programming and structured documentation using the principle of “interactive notebooks”. Interactive notebooks allow the user to combine formatted text (optionally with formulas and figures) with executable code, and text formatting, and then insert executable code, ending up with a format resembling a notebook. For this RStudio uses the R Markdown technology, as well as its slightly updated cousin, R Notebook. Since the differences between these two are relatively superficial, we will focus on the slightly simpler one R Markdown. This technology is easiest to demonstrate via example - in the toolbar, select File -&gt; New File -&gt; R Markdown ... and in the next window choose an arbitrary title (eg \"Testing\"). You can optionally edit the metadata, such as add the author’s name, and finally choose one of the options for final form of report (HTML is recommended due to its lowest dependency on additional software). Unlike the R script, which will initially appear empty, when creating an RMD document RStudio will create a new pre-filled document. This is done in this way for the simple reason that the user gets an easily modifiable template with all the basic elements included as a reminder. We will delete most of this template for our needs - so feel free to remove everything after the initial header, i.e. below the second ---. Then, we can write any text below. We can also experiment with headers which start with #, ##, ### characters - these are NOT “R comments”, since we are now not programming, we are writing formatted text. By using * and ** characters in front and back of the words we can make letters become bold and italicized, respectively. Everything mentioned so far in this paragraph is pure “markdown”, which basically means “plain text with added formatting information that can be converted into formatted text with the help of additional tools, if desired”. When we want to incorporate executable code into our “report”, we need to create so-called “code chunks”. This can be done by selecting Insert -&gt; R on the toolbar or using the CTRL + ALT + I combination of keys. Notice that the chunk begins and ends with a specially selected string of characters - three so called “backticks” (they look like simple apostrophes, but are angled towards the left). Likewise, the beginning of the chunk contains description of certain parameters in the opening brackets, which can affect the way RStudio is processing this “code chunk”, most notably by having us state which programming language we will use. In this coursebook, we will almost exclusively use the language R, although other options are available if they had been previously installed on the platform running RStudio. The code chunk behaves the same as the standard R script - we can enter commands and execute them. The difference is just that the results can be seen immediately in the R Markdown document itself (in addition to them showing up in the console). If this is not something that we want, we can turn this functionality off (click on the gear in the toolbar and select Chunk output in console), however we usually prefer to have the results right below the code that created them, notebook-style. If we follow the instructions, the screen may look similar to the following image: Figure 1.4: R Markdown document We can now try to create a “report” from the current document. First, we must save it under a particular name (eg Testing.rmd), and then we can click on the Knit button to convert the document from pure text to an HTML file. (Note - if our platform is missing some packages, we will see that in the warning toolbar which will show up - we just need to pick the option “Install” and wait until RStudio downloads the required packages from the CRAN repository) R Markdown documents are much more powerful than it may seem judging by the elements that have been presented so far. Chunks can have plenty of different parameters which influence their behaviour. The output format can be PDF, DOCX as well as other forms such as presentation slides, books intended for mobile devices, interactive web applications etc. The coursebook you are reading is actually nothing more than a series of RMD files converted into the appropriate form you are currently using. As we will explain in the next chapter, RMD files are also the main way for you to use this coursebook effectively and try out the examples and tasks that follow. The universality and flexibility of technology R Markdown is exceptionally great, and is very well accepted by the R community. 1.4 How to use this coursebook? The basic idea of this coursebook is “learning through application”. Therefore, the lessons below will not focus on merely showing and talking about new concepts, but rather encouraging the reader to learn out each new concept by solving a series of easy or intermediate tasks. Each chapter that follows has an accompanying “workbook”. Simply put, it is an RMD file that contains all the examples from the lecture, accompanied by a concise text for easier reference to the concepts being dealt with. The basic idea is that the reader reads the coursebook and solves the workbook in parallel, looking at the task solution only after it is solved within the programming interface. Some exercises will be trivial, require simply removing the # sign (meaning “comment”) from the start of the command and executing it. In spite of the trivial approach, in this way, however, the reader is encouraged to independently test the command rather than just look at its result. Other exercises will be a bit more involved. Each exercise will also have a solution underneath (which will be hidden if using the interactive version of the coursebook). Readers are encouraged to only look at the solution after first solving the exercise themselves. Finally, each chapter will end with a set of additional exercises which will not have accompanying. It is recommended to successfully solve all these exercises, since the lessons that follow presume the well-accepted knowledge of all the topics that are discussed previously (and some exercises will sneakily introduce some helpful functions or tricks which may become very useful later on). Let’s get to know the concept of workbooks more closely. First, you need to download and open a workbook that matches the lesson you are reading. It is easy to recognize it by looking at the chapter number - the notebook for this chapter should be named 01_Introduction_WB.Rmd. It is recommended that all workbooks that you plan to use are copied somewhere to the local computer together with all the accompanying files, and then perhaps create a backup copy of the original workbook (since solving a workbook will change its contents). As stated previously, the workbook will typically contain all the program code in the chapter to which it refers, but usually only the minimal amount of text sufficient for easier understanding and solving the exercises. Workbooks will leverage two types of tasks: Examples and Exercises. Examples will be pieces of code that will just need to be executed, without any modification. Exercises on the other hand expect at least some changes, and often require entering completely new segments of program code. An Example might look like this: Example 1.1 - a few simple mathematical expressions 3 + 2 # adding log(10) # natural logarithm! log10(10) # this is a base-10 logarithm! By the way, we comment with the &quot;#&quot; sin(0.5 * pi) # pi is one of the built-in constants ## [1] 5 ## [1] 2.302585 ## [1] 1 ## [1] 1 You can execute the commands from the examples individually, or the entire chunk at once with the CTRL + SHIFT + ENTER key combination. No modification of the code is necessary (although you should always feel free to experiment further with the given commands, either in the chunk itself or in the console!). As stated, Exercises on the other hand always require a certain - even minimal - intervention. Exercise 1.1 - Commands for checking/changing the working directory # Make the following commands by removing the comment character #getwd() # current working directory #setwd(&quot;.&quot;) # here we can specify a new working folder if desired # usually not a good idea when working with RMD files getwd() # directory in which we are currently working setwd(&quot;.&quot;) # here we can specify a new working folder if desired # usually not a good idea when working with RMD files The exercise will often be related to the most recently introduced concept. For example, we might be learning the assignment operator, and explaining that although language R supports the usage of = operator for assigning a value to a variable, it is recommended to use the &lt;- operator for that purpose, for various reasons to be explained later (use ALT + - to quickly write &lt;-). Also, note that R supports the so-called autoprint functionality, when a command or a set of commands is executed, the value of the last expression will be shown on screen. This means that if we create a new variable x and want to print it on the screen, we do not have to put print(x)as the last command, but rather just x. Also, using an assignment operator does not return a value in itself, which is why we do not see anything printed out on screen after assigning a value to a variable. Let’s try to experiment with these concepts in the following exercise. Exercise 1.2 - Assignment operator # store `5` in a variable called `x` # then print the variable `x` on the screen x &lt;- 5 x ## [1] 5 Now that we have some basic knowledge about language R and the programming interface we will be using, we can begin by learning the basic elements of the R programming language. Programirajmo u R-u by Damir Pintar is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.Based on a work at https://ratnip.github.io/FER_OPJR/ "],["tipovi.html", "2 Basic data types and operators 2.1 Basic data types 2.2 Operators 2.3 Missing, unknown, and non-existent values Homework exercises", " 2 Basic data types and operators “Basic” or “primitive” types of data are the underlying building blocks of programming languages. They are basically embedded mechanisms that allow storing basic information - most commonly of logical, numeric, or character nature. Most programming languages use very similar methods of storing such information, which means that we can expect to see similar basic data types in almost every programming language - the difference is often in certain implementation specifics such as the name of the basic type, the default number of bytes is uses etc. In any case, the most common first step in learning a new programming language is getting to know the basic types of data that it supports. The next thing that may interest us is the language syntax, that is, the specific way programming instructions are written so the programming language can adequately interpret them and execute. The R language syntax follows similar conventions seen in languages such as Python, Ruby, or Java, but with its own specifics. Some basic syntax rules are: each command must, as a rule, go to its own line, but the indentation and semicolons at the end are optional; programming blocks are delinated with brackets; variables types need not be declared in advance, their type is inferred based on the assigned value; comments start with #; etc. The rest of the syntax will be best learned through examples. We will start with basic operators and functions and work from there. 2.1 Basic data types R offers six basic data types: type examples logical TRUE, FALSE ili T, F integer 2L, 5L, 123456789L double 4, 6, 3.14, 2e5 complex 5 + 2i, 7 + 1i character \"A\", \"B\", \"Pero\", \"ABCDEFGHijklmnoPQRSTUVwyz\" raw as.raw(2), charToRaw(\"1\") Some remarks: integer and real types are often treated together as a numeric type (although this is not entirely consistent!) complex type must have a declared imaginary constant even if it is 1 (2 + i is not a good record!) The type of “raw” bytes is relatively rarely used Checking whether a variable is of a certain type can be done with the help of is.&lt;type_name&gt; functions. Before we get to test this function in the upcoming exercise, we will introduce one small trick: in exercises where we print more things on the screen, it is useful to visually separate the different result segments so that we can easily understand which part of the code is referenced. For this purpose, we will use the cat(\"-----------\\n\") command that simply prints a dashed line followed with the newline character. We opted for this solution instead of simply using the “empty” print(\"\") function because that function always prints out the index of the result as well as the string quotation marks, while the cat command is just a “raw” print, which is in this case more appropriate. Exercise 2.1 - checking data types # try the following commands: #is.logical(FALSE) #is.integer(2L) #is.double(1.11) # perform the following checks: # is 5L numeric? # is 3.14 numeric? # is &quot;ABC&quot; character? # is 4 + 2i complex? # is 5 integer? # try the following commands: is.logical(FALSE) is.integer(2L) is.double(1.11) cat(&quot;-----------\\n&quot;) # perform the following checks: # is 5L numeric? is.numeric(5L) # is 3.14 numeric? is.numeric(3.14) # is &quot;ABC&quot; character? is.character(&quot;ABC&quot;) # is 4 + 2i complex? is.complex(4 + 2i) # is 5 integer? is.integer(5) ## [1] TRUE ## [1] TRUE ## [1] TRUE ## ----------- ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] FALSE Types of some variables or constants can be retrieved with the help of typeof orclass functions. The difference between these functions is the following: typeof answers to the question “in which underlying format is this variable stored?”; hence, it will return the “primitive” or “basic” type ( integer, double) class answers to the question “what IS this variable?”; it will return the “object type”, which is actually the value stored in the class attribute of this variable Exercise 2.2 - data type retrieval # print the types of the following constants: TRUE, 2L, F, 3.14, &quot;ABC&quot; # print the classes of the same constants. Do you see any differences? # print the types of the following constants: TRUE, 2L, F, 3.14, &quot;ABC&quot; typeof(TRUE) typeof(2L) typeof(F) typeof(3.14) typeof(&quot;ABC&quot;) cat(&quot;-----------\\n&quot;) # print the classes of the same constants. Do you see any differences? class(TRUE) class(2L) class(F) class(3.14) class(&quot;ABC&quot;) ## [1] &quot;logical&quot; ## [1] &quot;integer&quot; ## [1] &quot;logical&quot; ## [1] &quot;double&quot; ## [1] &quot;character&quot; ## ----------- ## [1] &quot;logical&quot; ## [1] &quot;integer&quot; ## [1] &quot;logical&quot; ## [1] &quot;numeric&quot; ## [1] &quot;character&quot; Data can be explicitly converted from one type to another using the functions as.&lt;type_name&gt;: Exercise 2.3 - conversion of data types # perform the following conversions and print the result # 2.35 to integer # TRUE to ntomeric # 100L to character # 2.35 to character # 2e2 to character # 0 to logical # 2.75 to logical # perform the following conversions and print the result # 2.35 to integer as.integer(2.35) # TRUE to ntomeric as.numeric(TRUE) # 100L to character as.character(100L) # 2.35 to character as.character(2.35) # 2e2 to character as.character(2e2) # 0 to logical as.logical(0) # 2.75 to logical as.logical(2.75) ## [1] 2 ## [1] 1 ## [1] &quot;100&quot; ## [1] &quot;2.35&quot; ## [1] &quot;200&quot; ## [1] FALSE ## [1] TRUE R will always perform an implicit conversion of types if possible: Exercise 2.4 - implicit conversion # Write the following phrases and print the results: # arithmetic operator between logical and numeric variables # arithmetic operator between integer and numeric variables # logical operator negation (!) applied to numeric variable # arithmetic operator between logical and numeric variables TRUE + 5 # arithmetic operator between integer and numeric variables 5L + 3.14 # logical operator negation (!) applied to numeric variable !25 ## [1] 6 ## [1] 8.14 ## [1] FALSE Implicit conversion will only be performed if it is meaningful - for example, we cannot perform arithmetic operations between a character type and a numeric type. 2.2 Operators As in other programming languages, R allows using various operators when forming expressions. Some of the more frequently used operators are: arithmetic +, -, *, /, ^, %% (division reminder), %/% comparison &lt;, &lt;=, &gt;, &gt; =, ==, != logical ! (negation), &amp;&amp; (scalar AND), || (scalar OR), &amp; (vector AND), | (vector OR) assignment &lt;- or= Exercise 2.5 - operators # try the `5 / 2` and` 5 %/% 2` expressions # calculate the &quot;square of 17&quot; and &quot;the remainder of 101 divided by 12&quot; # check what is the result of the following expressions: `17 &gt; 13`,`!TRUE`, `5 &amp;&amp; 0`,`0. || 2` # try the `5 / 2` and` 5 %/% 2` expressions 5 / 2 5 %/% 2 cat(&quot;-----------\\n&quot;) # calculate the &quot;square of 17&quot; and &quot;the remainder of 101 divided by 12&quot; 17 ^ 2 101 %% 12 cat(&quot;-----------\\n&quot;) # check what is the result of the following expressions: `17 &gt; 13`,`!TRUE`, `5 &amp;&amp; 0`,`0. || 2` 17&gt; 13 ! TRUE 5 &amp;&amp; 0 0. || 2 ## [1] 2.5 ## [1] 2 ## ----------- ## [1] 289 ## [1] 5 ## ----------- ## [1] TRUE ## [1] FALSE ## [1] FALSE ## [1] TRUE Logical values and comparison operators will most commonly be used with the conditional expressions, better known as “if-else” commands. In R, the syntax of such commands looks like this: if (expression) {block} else {block} Let’s try this on the following task: Exercise 2.6 - conditional expressions # Write a command that performs the following: # &quot;if 100 is an even number print &#39;Success!&#39;&quot; # Write a command that performs the following: # &quot;if 100 is an even number print &#39;Success!&#39;&quot; if (100 %% 2 == 0) print(&quot;Success!&quot;) ## [1] &quot;Success!&quot; We have noted above that we have two types of logical operators for “and” and “or”. We will explain the difference later, for now it is enough to know that instructions that control the program flow exclusively use the “C++”-like operators &amp;&amp; i ||. Before, we have already mentioned that R offers two assignment operators, &lt;- and =. There are some minor differences, but those mostly pertain on using these operators in other contexts - when used purely for assigning a result of an expression to a new variable, their functionality is almost identical. In the literature, both versions can be seen for assigning values, but we will primarily and consistently use &lt;-, if nothing than because that way the code is visually more distinctive from code from the other programming languages. NOTE: an easy way to type in the &lt;- operator is to press the keys ALT and - The operands in the expression that uses the assignment operator are called the “lvalue” (left value) and “rvalue” (right value), respectively. Rvalue is an expression that needs to be calculated, while the left (lvalue) is interpreted as “the place where the result of the expression on the right will be stored”. This means that examples like this x + 1 &lt;- 2 # error !!!] do not work - it is not unambiguous what is being stored where. Therefore, as a rule, the lvalue is most commonly a (new or existing) variable, though in some occasions we will actually be seeing a function call. This may appear confusing, but there is a perfectly intuitive explanation for this which we will bring later. Naming the variables mostly follows the rules from other programming languages, with some slight peculiarities - we can use letters, numbers, underscores and dots (the dot . is treated like a regular character!). The first symbol must be a letter or a dot. .myVarijable &lt;- 5 #OK my.Variable &lt;- 5 #OK _myVariable &lt;- 5 # not OK 123Variable &lt;- 5 # not OK If we use variable names which consist of multiple words, it is customary tp pick one of the following conventions: myVariable &lt;- 1 # camelcase my_Variable &lt;- 2 # underscore seperation or my.variable &lt;- 3 # point separation Sticking consistently to one of these choice will result in a nicer, more readable code. R also allows a way to go around the variable-naming conventions, and to use any printable character in a variable name. If we want to use this functionality, we then must put this name inside “backticks”: Exercise 2.7 - variable name with special characters # Enter an arbitrary name with special characters inside the left apostrophes # and print the value of the variable # `` &lt;- 2 # Enter an arbitrary name with special characters inside the left apostrophes # and print the value of the variable # `` &lt;- 2 `!% ^$*@ __ =` &lt;- 2 `!% ^$*@ __ =` ## [1] 2 This way of naming variables is not too useful in practice, but it has its purpose - since the operators in R are actually functions (whose names are literally +, ^ etc.), by using left backticks we can directly reference them in their original form, which can be very practical in the so-called functional programming (which we will talk about in one of the future lessons). Assigning values to new variable names results in creation of new variables in the working environment (called the “global environment”). All variables we have created so far can be seen with the ls() function. If we want to delete some variables, we just provide their names in the call function rm(), without quotation marks (e.g. rm (x, y, z)). To delete all variables from the working environment, we can use the call rm(list=ls()), but this should be done with caution (there’s no “undo”!). Exercise 2.8 - printing and deleting global environment variables # print all of the global environment variables that have been created so far # delete some of the above variables - eg rm(x, y, z) # list all remaining variables # delete ALL variables from the global environment # (cautiously with this call in practice!) # Make sure the global environment is empty # print all of the global environment variables that have been created so far ls() # delete some of the above-written variables - eg rm(x, y, z) # list all remaining variables rm(x, y) ls() # delete ALL variables from the global environment # (cautiously with this call in practice!) # Make sure the global environment is empty rm(list=ls()) ls() Finally, whenever we need help with some function, we have the following options available: write only &lt;function_name&gt; (without parenthesis with parameters) and press - if the function is written in R (and not just proxy to a C implementation) the screen will print the original source code of the function Write help(&lt;function_name&gt;) or ?&lt;function_name&gt; to get a documentation page with the list of parameters, examples, and so on. Write example(&lt;function_name&gt;) where we get a list of examples of using said function The following code chunk shows how to use the above methods (to save space, we will not show the result, but feel free to try out these commands in the console). #program code for `ls` function ls # help for `ls` function ?ls # or help(ls) # examples of using the `ls` function example(ls) 2.3 Missing, unknown, and non-existent values In R there are three ways of modeling “non-existent” values: NA - (not available) - for missing or unknown values of a particular type NaN - (not a number) - “impossible” number, e.g. 0 / 0 NULL - non-existent value, literally “nothing” NaN is a subclass of NA. The difference between NA and NULL is subtle, but important. NA means that the value is possibly there, we just don’t know what it is. NA values still have a type, so an unknown numeric value is still numeric. NULL on the other hand is a placeholder for “nothing” - it is its own class, and it denotes that whatever we are referencing is empty. One important note for SQL users - what is NULL in SQL is NA in R. Do not be mixing SQL’s NULL and R’s NULL, since they are usually completely different things! Exercise 2.9 - working with NA, NaN and NULL # how much is &quot;5 + unknown number&quot; # how much is &quot;5 + non-existent number&quot; # check classes of the following: # NA # arithmetic operation between numeric and NA # NaN # NULL # how much is &quot;5 + unknown number&quot; 5 + NaN # how much is &quot;5 + non-existent number&quot; 5 + NA cat(&quot;-----------\\n&quot;) # check classes of the following: # NA # arithmetic operation between numeric and NA # NaN # NULL class(NA) # logical type is &quot;weakest&quot;! class(5 + NA) class(NaN) class(NULL) ## [1] NaN ## [1] NA ## ----------- ## [1] &quot;logical&quot; ## [1] &quot;numeric&quot; ## [1] &quot;numeric&quot; ## [1] &quot;NULL&quot; Checking missing values is similar to checking data types - we use the is.na,is.nan and is.null functions. Exercise 2.10 - check NA, NaN and NULL # which of the following is NA? NA, NaN, NULL, &quot;&quot;, 0 # which of the following is NaN? NA, NaN, NULL # which of the following is NULL? NA, NaN, NULL # which of the following is NA? NA, NaN, NULL, &quot;&quot;, 0 is.na(NA) is.na(NaN) is.na(NULL) is.na(&quot;&quot;) is.na(0) cat(&quot;-----------\\n&quot;) # which of the following is NaN? NA, NaN, NULL is.nan(NA) is.nan(NaN) is.nan(NULL) cat(&quot;-----------\\n&quot;) # which of the following is NULL? NA, NaN, NULL is.null(NA) is.null(NaN) is.null(NULL) ## [1] TRUE ## [1] TRUE ## logical(0) ## [1] FALSE ## [1] FALSE ## ----------- ## [1] FALSE ## [1] TRUE ## logical(0) ## ----------- ## [1] FALSE ## [1] FALSE ## [1] TRUE To end, we dedicate some room to a discussion of the NA value, since we will often encounter it in practice. Simply put, if the NA values appear, we can expect the following side effects: results of arithmetic expressions which contain NA as operands will result in NA values the results function calls which get NA as parameters can result with NA (but sometimes there is an option to use the parameter na.rm = T which actually means ‘ignore NA values’) logical expressions which contain NA may or may not necessarily result in a NA value, depending on whether the term depends on NA or not (eg TRUE || NA has the result of TRUE, but FALSE || NA has the result NA) With this last one, we must be especially careful as the NA in the conditional term results in a mistake: if (NA &lt; 2) print (&quot;Success!&quot;) # error !! In this lesson we have learned the basic elements of the language R. However, in practice, we much more often work with complex data types - vectors, matrices, data frames and lists - which are the subject of the following lesson. Homework exercises What is the result of the following commands? Try to predict the result before executing each command. as.complex(2) as.integer(-3.25) as.logical(&quot;0&quot;) as.numeric(TRUE) as.character(11.5 + 2i) as.numeric(&quot;ABC&quot;) How do the following expressions look like in R: “ten to the power of nine multiplied by 3” “natural logarithm of 5” “integer division of 10 by 3” “the remainder of integer division of 10 by 3” “tangent of 75 degrees” R has a special constant for “infinity”. Try to find what it is by using an arithmetic expression. Then, by using if, check whether reducing “infinity” from “infinity” results in a NaN value. Store NULL in a variable called x. Then try to convert this variable into a numeric type. Explain what you think has happened (full explanation will be given in the following chapter). Program in Ru &lt;/ span&gt; by Damir Pintar is licensed under Creative Commons Attribution-NonCommercial-NoDerivative 4.0 International License Based on a work at https://ratnip.github.io/FER_OPJR/ "],["vektori.html", "3 Vectors, matrices and lists 3.1 Vector 3.2 Index vectors 3.3 Matrices and arrays 3.4 Matrix slicing 3.5 Example 3.2 - matrix slicing 3.6 Lists Homework exercises", " 3 Vectors, matrices and lists 3.1 Vector The vector is the primary “complex” data types in the language R, in the sense that it can contain more values of the same type. It is similar to the term “array” in the C language. However, there is one important difference, which may be not immediately obvious. Unlike C, R does not really have “basic data types”, even though the last chapter may have given the impression it is so. In R, (almost) each variable type is actually a vector. Even the variables and constants we were showing in the previous lesson were actually single-element vectors. This revelation has far-reaching consequences to be discussed in detail below, but before delving into specifics we first need to get acquainted with the basic syntax of creating and managing vectors. 3.1.1 Creating a vector When we want to create a new vector variable which stores more then one value we must use the function simply named c (from combine or concatenate). # numeric vector m &lt;- c(1, 2, 3, 4, 5) # logic vector v &lt;- c(T, F, T) # character vector names &lt;- c(&quot;Ivo&quot;, &quot;Pero&quot;, &quot;Ana&quot;) So, simply stated, a vector is an arranged set of elements of the same type. If we create a new vector with elements of different types, R will automatically convert all elements into the “strongest” type, which will eventually become the type of vector itself (the term “stronger” type in this context means the type able to store everything without any loss of information which might happen if it was stored in a “weaker” type). Generally the conversion goes in the direction of logic -&gt; numeric -&gt; character types. Exercise 3.1 - creating vectors # create a new vector `x` with four arbitrary elements of the following types: # logical, double, character and integer # print the vector content and its class on screen # create a new vector `x` with four arbitrary elements of the following types: # logical, double, character and integer x &lt;- c(T, 1.25, &quot;Ivo&quot;, 10L) # print the vector content and its class on screen x class(x) ## [1] &quot;TRUE&quot; &quot;1.25&quot; &quot;Ivo&quot; &quot;10&quot; ## [1] &quot;character&quot; A vector can be explicitly converted to another type with the help of as.&lt;type_name&gt; functions, already introduced in the previous chapter. If unambiguous conversion is impossible, the element will be converted to NA, and the conversion will be accompanied with a suitable warning. Exercise 3.2 - explicit vector type conversion x &lt;- c(1, T, 2L) y &lt;- c(1L, 2L, 3L) z &lt;- c(1.25, TRUE, &quot;Ana&quot;) # consider what might be the result first, and then perform the following conversions # vector `x` in numeric type # vector `y` in character type # vector `z` in an integer type x &lt;- c(1, T, 2L) y &lt;- c(1L, 2L, 3L) z &lt;- c(1.25, TRUE, &quot;Ana&quot;) # consider what might be the result first, and then perform the following conversions # vector `x` in numeric type # vector `y` in character type # vector `z` in an integer type as.numeric(x) as.character(y) as.integer(z) ## Warning: NAs introduced by coercion ## [1] 1 1 2 ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; ## [1] 1 NA NA Think about why in the last example the value TRUE became NA instead of 1L that you might have expected. If you cannot figure out the reason, try to print the z vector itself and notice the results of the implicit conversion you might have neglected (which converts the TRUE logical value to a string of \"TRUE\" that can no longer be interpreted as its logical counterpart, which would otherwise result in the numeric value 1L). 3.1.2 Vector concatenation Remember that we said c can mean “combine elements” but also concatenate? With the c function we can also concatenate multiple vectors to one: a &lt;- c(1, 2, 3) b &lt;- c(4, 5) c &lt;- c(6, 7, 8) # variable can be called &quot;c&quot; in spite of the function c() d &lt;- c(a, b, c) # d is now c(1, 2, 3, 4, 5, 6, 7, 8) When creating vectors, we are not confined to exclusively using the c function. In addition to it, R also offers multiple convenient ways of creating new vectors: : - “range” operator, giving the range from upper to lower bound, both included seq - sequence function, similar to the range operator but with additional options rep - replicate function, repeats the provided elements a certain number of times Exercise 3.3 - vector creation helper functions # print the results of the following commands # 1:5 # rep(c(1, 2, 3), times = 3) # rep(c(1, 2, 3), each = 3) # seq(1, 5, by = 0.5) # print the results of the following commands 1:5 rep(c(1, 2, 3), times = 3) rep(c(1, 2, 3), each = 3) seq(1, 5, by = 0.5) ## [1] 1 2 3 4 5 ## [1] 1 2 3 1 2 3 1 2 3 ## [1] 1 1 1 2 2 2 3 3 3 ## [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 Vectors can also be created by means of functions corresponding to the names of the vector types (numeric,character, etc.) whereby as a parameter we specify the desired length of the vector. This is often done as a “storage preparation” for the elements which will subsequently be filled in. If the length is not zero, the vector will be filled with the chosen number of appropriate zero-equivalents, depending on the actual type. Interestingly, we can also create an “empty” vector of a certain type, and it will still be considered a vector, only having the length of zero (and by using the c function we can easily add elements to it later). x &lt;- numeric(2) # vector is filled with &quot;zero&quot; elements, in this case (0, 0) y &lt;- character(5) z &lt;- integer(0) # &quot;empty&quot; vector! z &lt;- c(z, 1) # add to the vector the element 1 (actually &quot;merge empty vector and element 1&quot;) It is sometimes possible to get a zero-length vector as a result of an expression - for example, this often happens in conjunction with a NULL value, where the expression adds a type to literally “nothing”, resulting in an vector which is empty but still has a certain type. Finally, to check if some vector contains a certain element we can use the operator %in%: 4 %in% seq(1, 10, 2) # returns FALSE &quot;d&quot; %in% c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;) # returns TRUE We learned how to create vectors, now let’s see how we can access their elements. 3.1.3 Operator [ The vector element is accessed through the index operator [, with which we can retrieve but also modify vector elements: a &lt;- c(2, 4, 6) a[1] # prints a value of 2 a[2] &lt;- 5 # element on the 2nd place becomes 5 a[5] &lt;- 7 # we add 7 to the 5th place, and the &quot;hole&quot; is filled with NA a ## [1] 2 ## [1] 2 5 6 NA 7 Notice a somewhat unusual fact - the first element of the vector in R has the index 1, not 0! This is an important difference compared to the indexing of elements in most other programming languages. The reason for this peculiarity is simple - R is primarily a language for data analysis, and when referring to data, especially in tabular form. When data analysts refers to their data, it is much easier to count rows or columns in order they appear in a data set than to constantly do a mental “add 1” calculation - so the first row is always “row 1”, never “row 0”, even though someone from programming background would readily recognize it as such. The example above actually shows a very simplified case for retrieving vector elements and modifying them. However, there is an extremely important feature of language R called vectorization, that - informally speaking - states that R often prefers doing “more things at once”. This has nothing to do with parallel execution of tasks, but rather with the declarative approach to defining tasks which would in other languages require low-level programming, most commonly using loops. Specifically, in the case of referencing vector elements, we rarely retrieve or modify elements one by one, but rather we refer to multiple elements at once using the principles of vectorization and recycling. Understanding these terms is crucial for learning the R language, so we will explain them in detail below. 3.1.4 Principles of vectorization and recycling The notion of vectorization or more precisely vectorized operator and functions simply means that most operator and functions by design work on multiple elements at once. If we ask R to make an operation or function over a vector of values, R will perform the function or operation over each element separately and package the results in a new, resulting vector. Likewise, if we use a binary operator on two vectors as operands, the corresponding operation will be performed over the “paired” or “aligned” elements of both vectors (supposing for now that the vectors are of the same length). Let’s demonstrate this in the following exercise. Exercise 3.4 - vectorization principle x &lt;- seq(-5, 5, 1) a &lt;- 1:3 b &lt;- 4:6 # call the abs function to calculate the absolute value # over the vector `x` and print the result # add vectors `a` and` b` with operator `+` # and print the result # multiply vectors `a` and `b` with operator `*` # and print the result # call the abs function to calculate the absolute value # over the vector `x` and print the result abs(x) cat(&quot;-----------\\n&quot;) # add vectors `a` and `b` with operator `+` # and print the result a + b cat(&quot;-----------\\n&quot;) # multiply vectors `a` and `b` with operator `*` # and print the result a * b ## [1] 5 4 3 2 1 0 1 2 3 4 5 ## ----------- ## [1] 5 7 9 ## ----------- ## [1] 4 10 18 Carefully consider the results of the previous task. If necessary, draw representations of the vector a and b on paper (with the elements arranged vertically) and notice how R does the “pairing” of the elements. Notice also that we are not really talking about “vector operations” here in a strict mathematical sense, but about aligning the elements of two vectors and performing simple operations over each of these pairs. This is especially evident in the last example where there is no “vector multiplication” in some of the mathematical interpretations, but rather simple multiplication of the parallel elements of the two vectors. What if the vectors are not of the same length? R in this case uses the principle of recycling. The Recycling Principle states that when the vectors are not of the same length, the shorter vector is “recycled” as many times as needed to reach the length of the longer vector. The most common scenarios of using this principle are operations where on one side we have a vector with multiple elements and on the other a single-element vector. What we should be trying to avoid though is a recycling scenario where the length of a “big” vector is not a multiple of the “small” length - R will still recycle a shorter vector, only it will have to be “cut off”, which will result in an appropriate warning. Exercise 3.5 - recycling principle a &lt;- 1:4 b &lt;- c(1, 2) c &lt;- rep(5, 3) # multiply vector `a` with the number 2 and print the result # divide vector `a` with vector `b` and print the result # multiply vectors `a` and `c` and print the result a &lt;- 1:4 b &lt;- c(1, 2) c &lt;- rep(5, 3) # duplicate vector `a` and print the result 2 * a # divide vector `a` with vector `b` and print result a / b # multiply vectors `a` and `c` and print the result a * c ## Warning in a * c: longer object length is not a multiple of shorter object ## length ## [1] 2 4 6 8 ## [1] 1 1 3 2 ## [1] 5 10 15 20 Now we can finally demystify the difference between “scalar” and “vector” logical operators. scalar logical operators &amp;&amp; and || are intended for use with single-element vectors, they return unique values of TRUE or FALSE and are suitable for use in various conditional terms. vector logical operators &amp; and | use standard R’s vectorization and recycling principles, i.e., they are intended to work with logical vectors and as a result give a logical vector Exercise 3.6 - scalar and vector logical operators a &lt;- c(T, F, F) b &lt;- c(T, T, F) # apply scalar and vector version of logical operator &quot;or&quot; # over the `a` and `b` vectors and print the result # apply scalar and vector version of logical operator &quot;or&quot; # over the `a` and `b` vectors and print the result a || b ## Warning in a || b: &#39;length(x) = 3 &gt; 1&#39; in coercion to &#39;logical(1)&#39; a | b ## [1] TRUE ## [1] TRUE TRUE FALSE We see that the scalar version will “use” only the first pair of logic vector elements. This means while it could theoretically be used conditional expressions, there is no justifiable reason for it, and R will in this case warn us to address the fact that we are probably using the “wrong” operator. The next example with the relational operators may initially seem trivial, but it is important to pay special attention to the results we get since they will have very important implications later on. Let’s take a look what happens when vectorization is applied in conjunction with relational operators. Exercise 3.7 - vectorization of relational operators x &lt;- 1:5 y &lt;- seq(-10, 10, 5) # print x and y # print the result of the x &gt; y command and explain the result # print the result of the x &lt; 3 command and explain the result # print x and y x y cat(&quot;-----------\\n&quot;) # print the result of the x &gt; y command and explain the result x&gt; y cat(&quot;-----------\\n&quot;) # print the result of the x &lt; 3 command and explain the result x &lt; 3 ## [1] 1 2 3 4 5 ## [1] -10 -5 0 5 10 ## ----------- ## [1] TRUE TRUE TRUE FALSE FALSE ## ----------- ## [1] TRUE TRUE FALSE FALSE FALSE Thus, by vectorizing the relational operators over the vectors (or combinations of vectors and scalars), as a result we get logical vectors. The interpretation of these results is crucial - it actually answers the question “on what positions is the condition of this expression fulfilled”? In other words, the results actually represent a template that describes how to filter elements of a vector based on a filtering expression. This is the basic foundation of the so-called. logical indexing, which is one of the vector indexing methods that we will learn below. 3.2 Index vectors We have already learned that a vector can be retrieved with a help of a numerical index (and we did not forget the fact that the first element has an index 1). This concept can be expanded by taking multiple elements from the vector at once. which is often referred to as “slicing”. The basic principle of choosing multiple elements at once is simple - we only need to specify the indexes of the elements we want. R offers three basic ways of indexing: integer- or position-based indexing conditional or boolean-based indexing label-based indexing Which indexing we choose depends on whether we want to access the elements based on their position, name, or condition, and each type of indexing essentially amounts to using a particular vector type as a parameter for the indexing operator. Such a vector is then called an “index vector”, based on its role in the expression. Let’s get to know each of the types of indexing in detail. 3.2.1 Positional Indexing Positional Indexing is the generalization of an already familiar indexing principle where we simply write the numeric position (index) of the element we are interested in. If we want more elements, we simply put their indices “packed” into a numeric vector. Try solving the next exercise by using the appropriate numeric vectors as indexing parameters. Exercise 3.8 - Positional indexing x &lt;- 1:10 # print the first element of the vector `x` # print the first three elements of the vector `x` # print the first, fifth, and seventh elements of the vector `x` # print the first element of the vector `x` x[1] # print the first three elements of the vector `x` x[1:3] # print the first, fifth, and seventh elements of the vector `x` x[c(1,5,7)] ## [1] 1 ## [1] 1 2 3 ## [1] 1 5 7 Thus, the positional index vector is simply the ordinary numeric vector we use in conjunction with the index operator [ to determine which elements of another vector we want to “keep”. Let’s look at some of the features of the positional index vector: Exercise 3.9 - Positional indexing (2) x &lt;- 1:10 # answer the following questions with the help of an appropriate example # what does index 0 return? # what does a negative index return? # what happens if you use an index outside of vector boundaries x &lt;- 1:10 # answer the following questions with the help of an appropriate example # what does index 0 return? x[0] # what does a negative index return? x[-1] # what happens if you use an index outside of vector boundaries x[20] ## integer(0) ## [1] 2 3 4 5 6 7 8 9 10 ## [1] NA Indexing is not only used to retrieve elements. By combining the indexing operator and the assignment operator we can change the vector elements (also leveraging the principle of “doing more things at once”): Exercise 3.10 - Positional indexing and assignment a &lt;- 1:10 # set all vector elements of `a` from the second to the eighth place to zero # print vector `a` b &lt;- 1:20 b [2 * 1:5] &lt;- 0 # Consider what the vector `b` looks like after the above command # print the vector `b` and explain the result a &lt;- 1:10 # set all vector elements of `a` from the second to the eighth place to zero # print vector `a` a [2:8] &lt;- 0 a b &lt;- 1:20 b [2 * 1:5] &lt;- NA # Consider what the vector `b` looks like after the above command # print the vector `b` and explain the result b ## [1] 1 0 0 0 0 0 0 0 9 10 ## [1] 1 NA 3 NA 5 NA 7 NA 9 NA 11 12 13 14 15 16 17 18 19 20 3.2.2 Conditional indexing If we carefully considered the results obtained with examples with vectorized relational operators then we can very easily grasp the way conditional indexing works. The principle is simple - for the index vector we choose a logical vector of the same length as the vector whose elements we want to retrieve. The elements of this logical vector determine which elements are retained (the positions where the value is TRUE) and which we throw out (positions where the value is FALSE). Exercise 3.11 - conditional indexing x &lt;- 1:10 # create a logical vector `y` of length 10 with an arbitrary combination of # TRUE and FALSE values # index the vector `x` with the `y` vector, print and explain the result # print all vector elements `x` which are less or equal to 5 # use the appropriate expression as a logical index vector x &lt;- 1:10 # create a logical vector `y` of length 10 with an arbitrary combination of # TRUE and FALSE values y &lt;-c(T, T, F, T, F, F, F, T, F, T) # index the vector `x` with the `y` vector, print and explain the result x[y] # print all vector elements `x` which are less or equal to 5 # use the appropriate expression as a logical index vector x[x &lt;= 5] ## [1] 1 2 4 8 10 ## [1] 1 2 3 4 5 The last command, while simple, is one of the key principles for filtering elements in the language R. The combination of the index operator and the conditional expression represents a concise but very powerful vector filtering mechanism. Let’s try this principle in a few more examples. Exercise 3.12 - conditional indexing y &lt;- seq (1, 100, 7) students &lt;- c(&quot;Ivo&quot;, &quot;Petra&quot;, &quot;Marijana&quot;, &quot;Ana&quot;, &quot;Tomislav&quot;, &quot;Tin&quot;) # print a vector which contains all even, and then all odd vector elements of `y` # (&quot;odd&quot; and &quot;even&quot; refers to element&#39;s value, not position) # print all vector elements from `students` which represent 3-letter names # (note: we use the `nchar` function to count the characters in R) y &lt;- seq (1, 100, 7) students &lt;- c(&quot;Ivo&quot;, &quot;Petra&quot;, &quot;Marijana&quot;, &quot;Ana&quot;, &quot;Tomislav&quot;, &quot;Tin&quot;) # print a vector which contains all even, and then all odd vector elements of `y` # (&quot;odd&quot; and &quot;even&quot; refers to element&#39;s value, not position) c(y[y %% 2 == 0], y[y %% 2 != 0]) # print all vector elements from `students` which represent 3-letter names # (note: we use the `nchar` function to count the characters in R) students[nchar(students) == 3] ## [1] 8 22 36 50 64 78 92 1 15 29 43 57 71 85 99 ## [1] &quot;Ivo&quot; &quot;Ana&quot; &quot;Tin&quot; If the concept of conditional indexing with the help of conditional expressions is still unclear, one of the things that can help is to sketch the intermediate results - simply print the result of the expression within the indexing brackets and then consider how that result affects the final solution. 3.2.3 Label-based indexing Label-based indexing works on the principle of explicitly naming the elements we want to “keep”. In order to be able to use this type of indexing though we must ensure one necessary prerequisite - we need to first assign names to our vector elements. The vectors we used so far did not have named elements. Each element had its predefined position within the vector and its value but did not have any additional special identifiers. Programming language R allows you to attach names to vector elements in a very simple way - by using a combination of the names function, the assignment operator, and the character vector with selected names. We need to make sure however that the vector name is of the same length as the original vector. Exercise 3.13 - label-based indexing height &lt;- c(165, 173, 185, 174, 190) names(height) &lt;- c(&quot;Marica&quot;, &quot;Pero&quot;, &quot;Josip&quot;, &quot;Ivana&quot;, &quot;Stipe&quot;) # print the vector `height` # print the height of Pero and Josip height &lt;- c(165, 173, 185, 174, 190) names(height) &lt;- c(&quot;Marica&quot;, &quot;Pero&quot;, &quot;Josip&quot;, &quot;Ivana&quot;, &quot;Stipe&quot;) # print the vector `height` height # print the height of Pero and Josip height[c(&quot;Pero&quot;, &quot;Josip&quot;)] ## Marica Pero Josip Ivana Stipe ## 165 173 185 174 190 ## Pero Josip ## 173 185 We see that label-based indexing needs a corresponding character vector as the index parameter. (NOTE: A more careful reader will notice an unusual fact in the above code - it uses a function call as an lvalue! Understanding why this is possible requires some slightly advanced knowledge about the inner workings of the R language. For now it is enough to know that the above exercise isn’t really calling a function called names, but rather a function called names&lt;-, a member of a special kind of “assignment” functions which allow using the intuitive and easily readable syntax seen above) If for some reason we want to delete the names of vector elements, simply forward NULL to names(&lt;vector_name&gt;). names(height) &lt;- NULL This will conclude the story of the index vectors. We learned different ways of creating a vector and getting and modifying its elements. Now is the time to try to add the additional “dimension” to the vectors - by getting acquainted with matrices and the arrays. 3.3 Matrices and arrays Out simply - the matrices and the arrays are what you get when you add more dimensions to vectors. Matrix is a two-dimensional vector, i.e. a vector whose elements are organized in “rows” and “columns”. Array is a vector with three or more dimensions. While matrices are used relatively often in practice, the arrays are somewhat limited to very specific use cases. Because of this fact in this chapter we will mainly deal with matrices, although the concepts presented are very easily applicable to arrays too. One common thing about the matrices and arrays, which is a well-known fact to readers who come from programming backgrounds, is that their multidimensionality is actually completely virtual. Both the matrix and the array are actually one-dimensional vectors and it’s only the usage of multidimensional indices which allows these structures to behave as if they are truly multidimensional. On other words, when the programmer uses a multidimensional index, R simply maps it to the “real”, one-dimensional index of the element in the underlying one-dimensional vector. This fact is not limiting in the slightest though - programmatically, we can still in most cases treat the matrix as if it is truly a two-dimensional structure; the knowledge of its underlying one-dimensional nature can only give us additional flexibility in working with the matrices, and also allows us to write better code. There are several ways to create a new matrix: by fitting a one-dimensional vector inside a matrix structure: we use the matrix function with this one-dimensional vector as a parameter, followed by the desired number of rows and/or columns provided through the nrow and ncol parameters “manually” by setting the “dimension attribute” of a one dimensional vector using the dim function with a given two-element numeric vector for dimensions “binding” rows or columns together with functions rbind (row-bind) and cbind (column-bind) Let’s try to see this in action in the following exercise. Exercise 3.14 - the matrix function x &lt;- 1:12 # create a matrix with 3 rows and 4 columns using the `matrix` function # print the result on the screen # repeat the procedure but add the parameter `byrow = T` to the calling function # print the result on the screen and compare it to the previous result # create a matrix with 3 lines and 4 columns using the `matrix` function # print the result on the screen matrix(x, nrow = 3, ncol = 4) # repeat the procedure but add the parameter `byrow = T` to the calling function # print the result on the screen and compare it to the previous result matrix(x, nrow = 3, ncol = 4, byrow = T) ## [,1] [,2] [,3] [,4] ## [1,] 1 4 7 10 ## [2,] 2 5 8 11 ## [3,] 3 6 9 12 ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 4 ## [2,] 5 6 7 8 ## [3,] 9 10 11 12 Note that unless explicitly requested otherwise, the R matrix is always filled by columns. This is done mostly because in data analysis we usually perform operations by columns. But since we often feel that filling by the rows is more “natural”, we must not forget the option of using the very useful parameter byrow. Exercise 3.15 - the dim function m &lt;- 1:10 # print the result of call of the `dim` function to the vector `m` (checking the dimensions) # use the `dim` function on vector`m` with the parameter `c(2, 5)` # print `m` and comment the result # print the results of calling functions `nrow` and` ncol` on the matrix `m` m &lt;- 1:10 # print the result of call of the `dim` function to the vector `m` (checking the dimensions) dim(m) # use the `dim` function on vector`m` with the parameter `c(2, 5)` dim(m) &lt;- c(2, 5) # print `m` and comment the result m # print the results of calling functions `nrow` and` ncol` on the matrix `m` nrow(m) ncol(m) ## NULL ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 3 5 7 9 ## [2,] 2 4 6 8 10 ## [1] 2 ## [1] 5 We see that the “ordinary” vector does not actually have a dimension, which is manifested by the NULL values we get as a result when asking for it. By invoking the function dim we can add the similarly called attribute dim which formally turns this vector into a matrix (or array in a general case). Provided dimensions dictate how the elements are (virtually!) organized in rows and columns, which means that when choosing the dimensions we must take care they correspond to the current number of elements. Once the matrix has its dimensions added, we can retrieve them again by using the dim function, or just the number of rows or columns with the nrow and ncol functions. The resulting matrix is like the one in the previous example filled in by the columns. Since here we do not have the opportunity to use the byrow parameter, one of the ways to get a matrix filled by rows is to transpose the resulting result with the t function. m &lt;- t(m) # transpose the matrix and store it back in the variable `m` Finally, a matrix can be created by “gluing” rows and columns with the help of rbind andcbind. This is also a convenient way to add new rows and columns to an existing matrix. Exercise 3.16 - functions rbind and cbind a &lt;- 1:4 b &lt;- 5:8 c &lt;- c(0.0) # create a matrix `m` in which vectors `a` and `b` will be the columns # add a new row to the top of the matrix `m` with vector elements taken from`c` # print matrix `m` a &lt;- 1:4 b &lt;- 5:8 c &lt;- c(0.0) # create a matrix `m` in which vectors `a` and `b` will be columns m &lt;- cbind(a, b) # add a new row to the top of the matrix `m` with vector elements taken from`c` # print matrix `m` m &lt;- rbind(c, m) m ## a b ## c 0 0 ## 1 5 ## 2 6 ## 3 7 ## 4 8 3.4 Matrix slicing All the learned principles for “slicing” the vector using index vectors can be applied on matrices. The differences are as follows: we index each dimension individually first we index the rows, then the columns, dividing the index vectors with a , If we want “all rows” or “all columns” we simply omit the corresponding index vector(but keep the ,) 3.5 Example 3.2 - matrix slicing # `m` is a 3 x 5 matrix , with column names from `a` to `e` m &lt;- matrix(1:15, nrow = 3, byrow = T) colnames(m) &lt;- letters[1:5] # note the function and the special R variable called &quot;letters&quot; m[1, 2:5] # first line, all columns from second to fifth m[c(F, T, T), c(&quot;a&quot;, &quot;b&quot;)] # second and third rows, columns `a` and` b` m[,] # all rows and all columns (same as just `m`) ## b c d e ## 2 3 4 5 ## a b ## [1,] 6 7 ## [2,] 11 12 ## a b c d e ## [1,] 1 2 3 4 5 ## [2,] 6 7 8 9 10 ## [3,] 11 12 13 14 15 In practice, the matrix usually uses a combination of positional and label-based indexing; conditional indexing is not too practical because of the two-dimensional nature of the matrix (although it is feasible, we just have to keep in mind that the lengths of logical vectors we use for indexing need to have the proper length of their corresponding dimension). One of the things we need to keep in mind is the R-language tendency to “help” us by simplifying the result. Thus, the result of a slicing operation that leaves only one row or column will automatically become a vector, i.e. it will lose the dim attribute. This is sometimes does not something we want, especially if we are working on scripts that expect a matrix further down the line, even if it has the dimension of rows or columns 1. In this case, we need to put an additional parameter drop = F after the index vectors. This is often somewhat unwieldy, which is why there are many R-language packages that “repair” this by offering the splicing functionality while keeping the result in a consistent format. Still, it’s useful to keep in mind the existence of the drop = FALSE option when there is danger that our programming script will fail if it gets a vector as a result instead of a one-dimensional matrix. Exercise 3.17 - matrix slicing m &lt;- matrix (1:30, 6, 5, T) colnames (m) &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;) # create a submatrix `m2` which contains everything from the second to the fourth row # and from the third to the fifth column # print `m2` # set all elements in column `c` of `m` to zero # and then print the first two rows of matrix `m` # print only column `d` from `m2` # print only column `d`, but add the `drop = FALSE` parameter when indexing # separate the parameter with a comma (as if it was a &quot;third&quot; indexing dimension) m &lt;- matrix (1:30, 6, 5, T) colnames(m) &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;) # create a submatrix `m2` which contains everything from the second to the fourth row # and from the third to the fifth column # print `m2` m2 &lt;- m[2:4, 3:5] m2 # set all elements in column &quot;c&quot; to zero # and then print the first two lines of matrix `m` m[, &quot;c&quot;] &lt;- 0 m[1:2, ] # print only column `d` from `m` m[, &quot;d&quot;] # print only column `d`, but add the `drop = FALSE` parameter when indexing # separate the parameter with a comma (as if it was a &quot;third&quot; indexing dimension) m[, &quot;d&quot;, drop = F] ## c d e ## [1,] 8 9 10 ## [2,] 13 14 15 ## [3,] 18 19 20 ## a b c d e ## [1,] 1 2 0 4 5 ## [2,] 6 7 0 9 10 ## [1] 4 9 14 19 24 29 ## d ## [1,] 4 ## [2,] 9 ## [3,] 14 ## [4,] 19 ## [5,] 24 ## [6,] 29 We will end our overview of the matrices here. These data structures are very useful in solving various linear algebra problems. Additionally, some of the principles used for handling matrices will be useful when we soon introduce the “data frames” - one of the most useful data structures in R. Finally, although we will not extensively cover arrays, we will show an example of the program code that creates a three-dimensional array and then for element retrieval uses standard slicing principles we already learned with the vectors and matrices. myArray &lt;- array(1:24, dim = c(2, 3, 4)) # array of dimension 2 x 3 x 4 myArray[, 1:2, 3, drop = FALSE] # print all rows, first and second columns # 3rd &quot;layer,&quot; with array type retention 3.6 Lists In R lists are primarily used as a “universal data containers”. Unlike vectors (or better said the concept of a vector as we initially defined it), the list may contain different types of data or, more often, sets of different types of data. We can create a list with the list function to which we forward a string of names of elements and their contents as parameters. These elements can be anything, even other lists. myList &lt;- list(a = 1, b = 2:100, c = list(x = 1, y = 2)) Try to create your own list in the following example. Exercise 3.18 - list creation # create a new list called `stuff` that will have the following elements # element called `numbers&#39; with integers from 1 to 3 # element called `letters&#39; with letters &#39;A&#39; and &#39;B&#39; # nameless element with logical vector `c(T, F)` # element called `titles&#39; with the content: &quot;Mr&quot;, &quot;Mrs&quot; and &quot;Ms&quot; # print the `stuff` variable stuff &lt;- list(numbers = c(1,2,3), letters = c(&quot;A&quot;, &quot;B&quot;), c(T, F), titles = c(&quot;Mr&quot;, &quot;Mrs&quot;, &quot;Ms&quot;)) # print the `stuff` variable stuff ## $numbers ## [1] 1 2 3 ## ## $letters ## [1] &quot;A&quot; &quot;B&quot; ## ## [[3]] ## [1] TRUE FALSE ## ## $titles ## [1] &quot;Mr&quot; &quot;Mrs&quot; &quot;Ms&quot; Note that the list is an ordered data structure - the element without the name is shown in position 3. The str (“structure”) function allows us to inspect the properties and contents of a list contents without printing it in its entirety, which is very useful when we deal with large lists. This function is often used by data analysts, not only for lists but also for data frames, which will soon be introduced. Exercise 3.19 - list structure # print the structure of the `stuff` list # print the structure of the `stuff` list str(stuff) ## List of 4 ## $ numbers: num [1:3] 1 2 3 ## $ letters: chr [1:2] &quot;A&quot; &quot;B&quot; ## $ : logi [1:2] TRUE FALSE ## $ titles : chr [1:3] &quot;Mr&quot; &quot;Mrs&quot; &quot;Ms&quot; At the beginning of this lesson we said that one of the primary R principles is “everything is a vector”, where by vectors we mean arranged sets of elements of the same type. Initially it seems that list doesn’t conform to this principle, since it’s defining feature is the fact they may contain elements of different types. However, the surprising truth is in fact the opposite - the lists are actually vectors, and they actually do conform to the aforementioned definition. The answer to this enigma is actually rather simple - the list is in fact a recursive structure, and all the elements of the list are actually also (often small, single-element) lists, which means that formally all elements are truly of the same type. We can easily demonstrate this in the following exercise. Exercise 3.20 - list elements are lists # print the first element of the list `stuff` # check its class # print the first element of the list `stuff` stuff[1] # check its class class(stuff[1]) ## $numbers ## [1] 1 2 3 ## ## [1] &quot;list&quot; So, even though we assumed that the first element of the above list was a vector, we realized it’s actually a small list. This is often quite handy when we want to treat the list as a vector by using R functionality for vector management, however there are many cases where we do not want to work with a list element as a “small list”, but want to have it in its “original” simple vector form. To achieve this, we need to get rid of the list wrapper around the element. This can be done by using the operator [[, i.e. the “double angular brackets” operator. Exercise 3.21 - operator [[ # print the first element of the list `stuff` using the operator `[[` # check its class # print the first element of the list `stuff` using the operator `[[` stuff[[1]] # check its class class(stuff[[1]]) ## [1] 1 2 3 ## [1] &quot;numeric&quot; The aforementioned operator is most often used to retrieve the selected element by using its position in the list or its name (if defined). The second approach though is somewhat inconvenient, since we must use the syntax list[[name_element]] symbol, which is somewhat clumsy for typing since the element name also needs to be put in quotes. To make it easier to pull out elements by name, R offers an alternative way of accessing the list elements in this way bz leveraging the $ operator, i.e. using the syntax list$name_element (no quotes). Exercise 3.22 - operator $ # print the `letters` element of the `stuff` list # using `[[` the operator # print the `letters` element of the `stuff` list # using the `$` operator # print the `letters` element of the `stuff` list # using `[[` the operator stuff[[&quot;letters&quot;]] # print the `letters` element of the `stuff` list # using the `$` operator stuff$letters ## [1] &quot;A&quot; &quot;B&quot; ## [1] &quot;A&quot; &quot;B&quot; The lists are an extremely popular type of object in R, as they represent a universal template for more complex data structures, including more complex objects in the narrower sense (as we will see later). The list is also the “foundation” for the most popular and most commonly used element of the R-language: the data frame - which we will learn in the next chapter. Finally, we need to learn how to add an element to the list. The easiest way to do this is simply by using the aforementioned operator $ - we simply write something like list$newElement &lt;- newElementContents. In a similar fashion, we can delete a list element simply by assigning the NULL value to it. Exercise 3.23 - adding list elements # add the `evenNumbers` element to the `stuff` list which contains # all even numbers from 1 to 100 # delete the third element from this list # print the `stuff` list # in the `stuff` list add the `evenNumbers` element which contains # all even numbers from 1 to 100 stuff$evenNumbers &lt;- seq(2, 100, 2) # delete the third element from the list stuff[[3]] &lt;- NULL # print the `stuff` list print(stuff) ## $numbers ## [1] 1 2 3 ## ## $letters ## [1] &quot;A&quot; &quot;B&quot; ## ## $titles ## [1] &quot;Mr&quot; &quot;Mrs&quot; &quot;Ms&quot; ## ## $evenNumbers ## [1] 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 ## [20] 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 ## [39] 78 80 82 84 86 88 90 92 94 96 98 100 Homework exercises Create the following vectors: (11, 12, 13,…, 99) (0, 0, 0, 0, … , 0) (100 zeros) (0, 0.1, 0.2, …., 1.0) What is the sum of all numbers from 101 to 1001, if we skip all numbers divisible by 10? Use the sum function. Create a 3 x 3 matrix by performing the following commands (the sample function randomly picks elements from a provided vector; it will be covered in more detail in one of the following lessons): # we create a matrix of 3x3 randomly selected elements from 1 to 100 set.seed(1234) m &lt;- matrix(c(sample(1:100, 9, T)), nrow = 3, ncol = 3, byrow = T) Calculate the inverse matrix with the solve function. Make sure the multiplication of the original and inverse matrix result with the unit matrix (use the % *% operator to multiply the matrices). Initialize the stuff list used in the lesson. Do the following: print the class of the second element of the list print the element in the third place of the element of the list named letters check the length of the element called titles and add the title ‘Prof’ to the last position check if the number 4 is contained in the first element of the list add a new list of three vectors a,b and c which all contain elements (1,2,3) to the last place of the list, Program in Ru &lt;/ span&gt; by Damir Pintar is licensed under Creative Commons Attribution-NonCommercial-NoDerivative 4.0 International License Based on a work at https://ratnip.github.io/FER_OPJR/ "],["okviri.html", "4 Data frames and factors 4.1 Data frames 4.2 Selecting rows and columns 4.3 Adding and deleting rows and columns 4.4 Factors Homework exercises", " 4 Data frames and factors 4.1 Data frames The data frame is by far the most popular element of the programming language R. After all, the language R’s primary purpose is data analysis, and the data frame is provides an programmatic representation of the data set we intend to analyze. In other words, the data frame is an object similar in function to a sheet in Microsoft Excel or a table in a relational database. Almost every session in R revolves around manipulating data frames in certain ways - but while in Excel we mostly interact with the table with the help of a graphical interface, and in relational database via the query language SQL, in R we manage data programmatically using data frames. Let’s take for example the following table: zipCode cityName avgSalKn population cityTax 10000 Zagreb 6359.00 790017 18 51000 Rijeka 5418.00 128384 15 21000 Split 5170.00 167121 10 31000 Osijek 4892.00 84104 13 20000 Dubrovnik 5348.00 28434 10 This data set that contains certain parameters related to cities in the Republic of Croatia (values inside are not necessarily accurate and are used for demonstration purposes; also, note that the value of cityTax is expressed as percentage amount). We can easily imagine how to write this data in Excel or create a relational table to store it. Now we will learn how to represent this data in programming language R. In the last lesson we learned that the list is a complex data type which serves as a kind of “universal container” with the help of which we can collect a number of different objects and put them within the same structure. The data frame makes just a tiny tweak of this notion - it’s also a “universal container”, but with a restriction that each element stored within needs to have the same number of its own elements, so the container itself can assume tabular structure when its contents are represented as columns. In other words, data frame is just a list with an additional restriction regarding the length of its elements. The latter has a few very interesting consequences. First, since data frame inherits all features of a list, it allows us to leverage all functions and operators that work with lists. Additionally, the tabular nature of data frame’s contents allows us to treat it as a two-dimensional structure, effectively inheriting functions and operators that work on matrices. In other words, data frames at the same time behave as matrices as lists, allowing us to seamless apply knowledge about those data structures when manipulating this newly introduced type. But first, let’s learn how to create these objects. There are several ways to create data frames, and we’ll show two of the most frequently encountered scenarios in practice: Manual creation via the data.frame function Loading data from an external source using a helper function Let’s see both of these cases. First, we will create a data frame programmatically. Exercise 4.1 - creating data frames programatically # notice the similarity with list creation! cities &lt;- data.frame(zipCode = c(10000, 51000, 21000, 31000, 20000), cityName = c(&quot;Zagreb&quot;, &quot;Rijeka&quot;, &quot;Split&quot;, &quot;Osijek&quot;, &quot;Dubrovnik&quot;), avgSalKn = c(6359., 5418., 5170., 4892., 5348.), population = c(790017, 128384, 167121, 84104, 28434), cityTax = c(18, 15, 10, 13, 10)) # print the variable `cities` # notice the similarity with list creation! cities &lt;- data.frame(zipCode = c(10000, 51000, 21000, 31000, 2000), cityName = c(&quot;Zagreb&quot;, &quot;Rijeka&quot;, &quot;Split&quot;, &quot;Osijek&quot;, &quot;Dubrovnik&quot;), avgSalKn = c(6359., 5418., 5170., 4892., 5348.), population = c(790017, 128384, 167121, 84104, 28434), cityTax = c(18, 15, 10, 13, 10)) # print the variable `cities` cities ## zipCode cityName avgSalKn population cityTax ## 1 10000 Zagreb 6359 790017 18 ## 2 51000 Rijeka 5418 128384 15 ## 3 21000 Split 5170 167121 10 ## 4 31000 Osijek 4892 84104 13 ## 5 2000 Dubrovnik 5348 28434 10 If you like, try creating another data frame with differing lengths of subelements (“columns”). As you will see, this operation will result in an error and the data frame will not be created - R tries to keep the matrix nature of the frame always preserved. A little note regarding terminology: the “data frame” is often referred to as simply a “frame” or a “table”. Likewise, for its elements we will interchangeably use terms such as “column”, “variable” or “attribute”. Finally, adhering to data frames tabular structure, we will refer to the horizontally aligned elements as “rows” or “observations”. These terms are in line with the standard way of referencing tabular elements and the common statistical terms referring to the datasets. If there is a chance of ambiguity depending on the context, the term that most unambiguously describes the referenced element will be used. Let’s try to load the table from an external source now. Although R allows different forms of external data, we will assume that the data is obtained in a standard “CSV format” (CSV - comma-separated values). This format is one of the most popular pure text data storage methods that has the advantage of being easy to create manually, as well as being recognized by most data management tools which can often readily import/export data in such format. Below we can see an example of a CSV file that matches the data frame created in the previous example. Suppose the file is named cities.csv. Row values are separated by a comma (no spaces!). Every row (observation) is in its own your line, and the (optional!) first line represents the column names. zipCode,cityName,avgSalKn,population,cityTax 10000,Zagreb,6359.00,790017,18 51000,Rijeka,5418.00,128384,15 21000,Split,5170.00,167121,10 31000,Osijek,4892.00,84104,13 20000,Dubrovnik,5348.00,28434,10 One of the potential problems with CSV files is that they use the comma as separator (delimiter) of column elements, and in certain languages, as a standard, a “decimal comma” is used instead of a decimal point. Because of this fact, there is an “alternative” CSV standard that uses a semi-colon as a separator which would make our CSV file in this case looks like this (let’s call it citiesAlt.csv): zipCode;cityName;avgSalKn;population;cityTax 10000;Zagreb;6359,00;790017;18 51000;Rijeka;5418,00;128384;15 21000;Split;5170,00;167121;10 31000;Osijek;4892,00;84104;13 20000;Dubrovnik;5348,00;28434;10 Since the decimal point is a standard in the Republic of Croatia, in working with CSV files we have to be careful which of the two standards is being used, which cannot be discerned just from the extension alone. Luckily, the R language offers support functions for both standards, so once we identified which standard is being used in a particular file, we simply choose the appropriate function. We will assume existence of the following two files in the same directory as the workbook: cities.csv citiesAlt.csv (If you do not have these files available, you can easily create them with the help of plaintext editors (eg Notepad or gedit) by copy pasting the above rows.) To create data frames from CSV files we use the following functions: - read.csv - for “normal” CSV files with a comma as a separator - read.csv2 - for the alternative CSV standard that uses semi-colons The main input parameter of these functions is the path to the CSV file that we are loading. These functions also have a rich set of additional parameters that allow easy adoption to different scenarios. Also, both of these functions are derived from a more general function called read.table which in itself is even more flexible with respect to the number of different parameters and data load settings. It is recommended to check the documentation to see the entire spectrum of options which can be used for loading tabular data stored in plaintext files, and some of the more important ones will be listed below. As stated, a subset of the parameters (with the example of associated values) of read.csv (or read.table) functions that are useful to know are: header = FALSE - for files without a header sep = \"#\" - for files that use some more “exotic” separator, in this case # na.strings = 'NULL' - the term used in the dataset to represent the missing values that will ultimately become NA in R nrows = 2000 - maximum number of lines to be read, in this case 2000 stringsAsFactors = F - preventing automatic creation of factor columns (which we will learn in the lesson below) encoding = 'UTF-8' - for non-ASCII text encoding standards (especially if we are working with Croatian data which has diacritical characters) Let’s try to load data from available CSV files now. This data will not require special parameters, and will only be loaded by providing the path to the associated files (one that uses the comma and the other that uses the semi-colon as a separator). Exercise 4.2 - reading CSV files # load data from files `cities.csv` and `citiesAlt.csv` # and store it in variables called `cities2` and `cities3` # print `cities2` and` cities3` # load data from files `cities.csv` and `citiesAlt.csv` # and store it in variables called `cities2` and `cities3` cities2 &lt;- read.csv(&quot;cities.csv&quot;) cities3 &lt;- read.csv2(&quot;citiesAlt.csv&quot;) # print `cities2` and` cities3` cities2 cat(&quot;-----------\\n&quot;) cities3 ## zipCode cityName avgSalKn population cityTax ## 1 10000 Zagreb 6359 790017 18 ## 2 51000 Rijeka 5418 128384 15 ## 3 21000 Split 5170 167121 10 ## 4 31000 Osijek 4892 84104 13 ## 5 20000 Dubrovnik 5348 28434 10 ## ----------- ## zipCode cityName avgSalKn population cityTax ## 1 10000 Zagreb 6359 790017 18 ## 2 51000 Rijeka 5418 128384 15 ## 3 21000 Split 5170 167121 10 ## 4 31000 Osijek 4892 84104 13 ## 5 20000 Dubrovnik 5348 28434 10 We have already mentioned that data frames behave both like lists and like matrices. Let’s look at some useful functions we used with these types of objects which may now become very useful when working with data frames: nrow - number of rows ncol or length - the number of columns (“matrix” and “list” way!) dim - table dimensions names - column names head - prints several rows from the beginning of the table tail - prints several rows from the end of the table str - prints table structure summary - summarizes the statistical information about table columns Let’s try some of these functions: Exercise 4.3 - working with data frames # print the dimensions of the data frame `cities` # print the table structure of `cities` # print the first few rows of the data frame `cities` # print summarized statistical information about `cities` # print the dimensions of the data frame `cities` dim(cities) cat(&quot;-----------\\n&quot;) # print the table structure of `cities` str(cities) cat(&quot;-----------\\n&quot;) # print the first few rows of the data frame `cities` head(cities) cat(&quot;-----------\\n&quot;) # print summarized statistical information about `cities` summary(cities) ## [1] 5 5 ## ----------- ## &#39;data.frame&#39;: 5 obs. of 5 variables: ## $ zipCode : num 10000 51000 21000 31000 2000 ## $ cityName : chr &quot;Zagreb&quot; &quot;Rijeka&quot; &quot;Split&quot; &quot;Osijek&quot; ... ## $ avgSalKn : num 6359 5418 5170 4892 5348 ## $ population: num 790017 128384 167121 84104 28434 ## $ cityTax : num 18 15 10 13 10 ## ----------- ## zipCode cityName avgSalKn population cityTax ## 1 10000 Zagreb 6359 790017 18 ## 2 51000 Rijeka 5418 128384 15 ## 3 21000 Split 5170 167121 10 ## 4 31000 Osijek 4892 84104 13 ## 5 2000 Dubrovnik 5348 28434 10 ## ----------- ## zipCode cityName avgSalKn population ## Min. : 2000 Length:5 Min. :4892 Min. : 28434 ## 1st Qu.:10000 Class :character 1st Qu.:5170 1st Qu.: 84104 ## Median :21000 Mode :character Median :5348 Median :128384 ## Mean :23000 Mean :5437 Mean :239612 ## 3rd Qu.:31000 3rd Qu.:5418 3rd Qu.:167121 ## Max. :51000 Max. :6359 Max. :790017 ## cityTax ## Min. :10.0 ## 1st Qu.:10.0 ## Median :13.0 ## Mean :13.2 ## 3rd Qu.:15.0 ## Max. :18.0 4.2 Selecting rows and columns We’ve already said multiple times that data frames behave both as matrices and as lists, and one place where we employ both of these facets simultaneously is when selecting rows and columns of data frames. Specifically, we often leverage the following: two-dimensional indexing - to identify rows and columns we want to keep operator $ - for referencing individual columns In practice, one of the most common indexing methods is combining conditional selection of rows (with filtering expressions which leverage the $ operator), and the label-based indexing of columns (SQL experts will recognize this as a standard combination of WHERE and SELECT). Let’s try to apply this in practice. Exercise 4.4 - selecting rows and columns # print the table `cities` (for reference) # print the first three rows, the third and fifth column # print just the column &quot;cityTax&quot; # print zipCodes and city names of all cities which # have cityTax greater than 12% and a population of more than 100,000 # print the table `cities` (for reference) cities cat(&quot;-----------\\n&quot;) # print the first three rows, the third and fifth column cities[1:3, c(2,5)] cat(&quot;-----------\\n&quot;) # print just the column &quot;cityTax&quot; cities$cityTax cat(&quot;-----------\\n&quot;) # print zipCodes and city names of all cities which # have cityTax greater than 12% and a population of more than 100,000 cities[cities$cityTax &gt; 12 &amp; cities$population &gt; 100000, c(&quot;zipCode&quot;, &quot;cityName&quot;)] ## zipCode cityName avgSalKn population cityTax ## 1 10000 Zagreb 6359 790017 18 ## 2 51000 Rijeka 5418 128384 15 ## 3 21000 Split 5170 167121 10 ## 4 31000 Osijek 4892 84104 13 ## 5 2000 Dubrovnik 5348 28434 10 ## ----------- ## cityName cityTax ## 1 Zagreb 18 ## 2 Rijeka 15 ## 3 Split 10 ## ----------- ## [1] 18 15 10 13 10 ## ----------- ## zipCode cityName ## 1 10000 Zagreb ## 2 51000 Rijeka Notice the similarity between the last expression and the SQL query: SELECT zipCode, cityName FROM cities WHERE cities.cityTax &gt; 12 AND cities.population &gt; 100000 Choosing columns and rows is not difficult if we are well acquainted with index vector knowledge, but as it can be seen in the last example, the final expression is not necessarily easy to visually interpret (as compared to, for example, the SQL syntax that performs the same job). There are R packages which vastly reduce the complexity of writing and interpreting expressions such as these, which will be the subject of one of the future chapters. 4.3 Adding and deleting rows and columns To add and delete rows and columns, we can again try to remember how we would perform a similar task when handling matrices and lists, and then apply this knowledge to data frames. When performing data analysis though, adding individual columns is a slightly more common practice than adding rows - it is uncommon to be manually adding new observations, but creating new columns out of existing ones is a relatively standard data preparation task. The easiest way to add columns to the data frame is to mimic the way we add list elements - we just have to take care that the added column has the same number of elements as the other columns. New columns are often derived from existing columns via logical or arithmetic expressions. Exercise 4.5 - adding new columns to a data frame # add the logical column` highCityTax` to the `cities` table # which will indicate whether the cityTax is greater than 12% # assume the following (fabricated) way of estimating the income city gets from tax # - assume all cities have about 60% of working population # - assume each worker pays a tax that is roughly equal to 10% of their net salary # - assume income from city tax per worker is (cityTax percentage)*(tax income) # # add a `monthlyTaxIncome` column which will use the average salary, city tax # rate and population to estimate the monthly tax income of the cities # (in million Kns) # round the result to two decimals using the `round` function, # (example: round(100.12345, 2) ==&gt; 100.12 ) # print `cities` # add the logical column` highCityTax` to the `cities` table # which will indicate whether the cityTax is greater than 12% cities$highCityTax &lt;- cities$cityTax &gt; 12 # assume the following (fabricated) way of estimating the income city gets from tax # - assume all cities have about 60% of working population # - assume each worker pays a tax that is roughly equal to 10% of their net salary # - assume income from city tax per worker is (cityTax percentage)*(tax income) # # add a `monthlyTaxIncome` column which will use the average salary, city tax # rate and population to estimate the monthly tax income of the cities # (in million Kns) # round the result to two decimals using the `round` function, # (example: round(100.12345, 2) ==&gt; 100.12 ) cities$monthlyTaxIncome&lt;- round(0.6 * cities$population * 0.01 * cities$avgSalKn * 0.01 * cities$cityTax / 1e6 , 2) # print `cities` cities ## zipCode cityName avgSalKn population cityTax highCityTax monthlyTaxIncome ## 1 10000 Zagreb 6359 790017 18 TRUE 5.43 ## 2 51000 Rijeka 5418 128384 15 TRUE 0.63 ## 3 21000 Split 5170 167121 10 FALSE 0.52 ## 4 31000 Osijek 4892 84104 13 TRUE 0.32 ## 5 2000 Dubrovnik 5348 28434 10 FALSE 0.09 You can also add rows and columns similar to adding rows and columns to a matrix - with the rbind andcbind functions. We can use rbind to add new observations to the data frame (respecting the order of columns in the original data frame). With cbind we can add a completely new vector as a column, keeping in mind that the number of elements corresponds to the number of rows of the original data frame. Let’s try these functions on small “artificial” data frames to better demonstrate their functionality. Exercise 4.6 - data frames and rbind/cbind functions df1 &lt;- data.frame(a = c(1,2,3), b = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), c = c(T, F, T)) df2 &lt;- data.frame(a = 1, b = &quot;A&quot;, c = 3) # make a data frame which has `df1` and `df2` as rows # name it `df12` # add a `firstNames` columns containing names Ivo, Ana, Pero and Stipe # use `cbind` # print `df12` df1 &lt;- data.frame(a = c(1,2,3), b = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), c = c(T, F, T)) df2 &lt;- data.frame(a = 1, b = &quot;A&quot;, c = 3) # make a data frame which has `df1` and `df2` as rows # name it `df12` df12 &lt;- rbind(df1, df2) # add a `firstNames` columns containing names Ivo, Ana, Pero and Stipe # use `cbind` df12 &lt;- cbind(df12, firstNames = c(&quot;Ivo&quot;, &quot;Ana&quot;, &quot;Pero&quot;, &quot;Stipe&quot;)) # print `df12` df12 ## a b c firstNames ## 1 1 A 1 Ivo ## 2 2 B 0 Ana ## 3 3 C 1 Pero ## 4 1 A 3 Stipe For deleting rows and columns we can also use the same methods for managing matrices and lists. Specifically: to delete rows and columns we simply use two-dimensional indexing and store the result in the original datga frame to delete columns can we assign the value NULL to the selected column Let’s try this in the example. Exercise 4.7 - deleting rows and columns # delete the first row and second column from `df12` # use the indexing method # delete the `firstNames` column by using the `NULL` method # print `df12` # delete the first row and second column from `df12` # use the indexing method df12 &lt;- df12[-1, -4] # delete the `firstNames` column by using the `NULL` method df12$firstNames &lt;- NULL # print `df12` df12 ## a b c ## 2 2 B 0 ## 3 3 C 1 ## 4 1 A 3 We will get back to data frame management in one of the future chapters, where we will introduce new packages that completely reinvent most of base R functionality for this purpose. For now, we will end the introduction of R data types with one of the extremely popular derived data types - a factor. 4.4 Factors Factors in R are a data type that represents what is referred to in statistics as a nominal or categorical variable. Namely, the attribute of some observation often takes on a value from a set of previously known categories (e.g. gender, age category, education, city of birth, political party preference, etc.). Categories are often identified by a unique set of characters, and are often leveraged for various aggregations and groupings (for example, in a sports race we can calculate the average time depending on gender or age category) or filtering (we analyze only data pertaining to certain categories). Factors in R are very useful since they inherently carry metadata about their nature, allowing various function to readily recognize factors as such and deal with them accordingly (for example, visualization functions will use a discrete set of colors and a legend to denote categorical values). However, factors can also be a source of contention for R beginners because if used incorrectly they can lead to some inconvenient side-effects. This can all be easily avoided by learning specifics how they work and sticking to certain guidelines we will outline during this chapter. Let’s first demonstrate what factors actually are with the help of a simple example. Let’s imagine that we are doing a study which has ten medical patients (referred to by their ordinal number in study), and that the next character vector describes the blood pressure level in these patients: bloodPressure &lt;- c (&quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;normal&quot;, &quot;normal&quot;, &quot;low&quot;, &quot;high&quot;, &quot;low&quot;, &quot;normal&quot;, &quot;normal&quot;) This is obviously a “categorical” variable since it can take one of three discrete values - low, normal and high. Thus, this vector is a typical candidate for “factorizing”, i.e. for converting from a character vector into a factor class object. We can easily create these objects by using the factor function to which we can simply the character vector of category names. Exercise 4.8 - factorizing a character vector bloodPressure &lt;- c (&quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;normal&quot;, &quot;normal&quot;, &quot;low&quot;, &quot;high&quot;, &quot;low&quot;, &quot;normal&quot;, &quot;normal&quot;) # print the variable `bloodPressure` # print its class # create a variable `bloodPressure.f` by factorizing # the variable `bloodPressure` # print the variable `bloodPressure.f` # print its class bloodPressure &lt;- c (&quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;normal&quot;, &quot;normal&quot;, &quot;low&quot;, &quot;high&quot;, &quot;low&quot;, &quot;normal&quot;, &quot;normal&quot;) # print the variable `bloodPressure` bloodPressure # print its class class(bloodPressure) # create a variable `bloodPressure.f` by factorizing # the variable `bloodPressure` bloodPressure.f &lt;- factor(bloodPressure) cat(&quot;-----------\\n&quot;) # print the variable `bloodPressure.f` bloodPressure.f # print its class class(bloodPressure.f) ## [1] &quot;low&quot; &quot;high&quot; &quot;high&quot; &quot;normal&quot; &quot;normal&quot; &quot;low&quot; &quot;high&quot; &quot;low&quot; ## [9] &quot;normal&quot; &quot;normal&quot; ## [1] &quot;character&quot; ## ----------- ## [1] low high high normal normal low high low normal normal ## Levels: high low normal ## [1] &quot;factor&quot; Notice the subtle difference between printing a character vector and a factor. The printout of the factor is given an additional attribute called Levels. Also, the category names are now lacking quotation marks, further reinforcing the notion that these are not really character values as such. What have we gained by turning a character vector into a factor? For starters, it will make it harder to add an observation with an invalid category to it. For example, if we try to add a new value to a factor that is not present in the current categories (e.g., “very high”) we will get a warning, and instead of the category we have specified, a new item will have the value of NA. This is usually a desirable behaviour, since we don’t like having “dirty” data with incorrect category values. However, sometimes we may be caught unaware if a perfectly valid category gets stored as NA. This may happen if in the process of categorizing a character vector this original vector did not contain all the possible categories that may generally appear. To alleviate this issue, we have the option of adding the levels parameter in which we will explicitly specify a series of all possible categories with a help of a separate character vector. Exercise 4.9 - using the levels attribute # add an 11th element to `bloodPressure.f` called &quot;very low&quot; # print the variable `bloodPressure.f` # create a variable `bloodPressure.f2` by factorizing # the variable `bloodPressure` # add the `levels` attribute which will also contain # values &quot;very low&quot; and &quot;very high&quot; # add an 11th element to `bloodPressure.f2` called &quot;very low&quot; # print the variable `bloodPressure.f2` # add an 11th element to `bloodPressure.f` called &quot;very low&quot; bloodPressure.f[11] &lt;- &quot;very low&quot; ## Warning in `[&lt;-.factor`(`*tmp*`, 11, value = &quot;very low&quot;): invalid factor level, ## NA generated # print the variable `bloodPressure.f` bloodPressure.f cat(&quot;-----------\\n&quot;) # create a variable `bloodPressure.f2` by factorizing # the variable `bloodPressure` # add the `levels` attribute which will also contain # values &quot;very low&quot; and &quot;very high&quot; bloodPressure.f2 &lt;- factor(bloodPressure, levels = c(&quot;very low&quot;, &quot;low&quot;, &quot;normal&quot;, &quot;high&quot;, &quot;very high&quot;)) # add an 11th element to `bloodPressure.f2` called &quot;very low&quot; bloodPressure.f2[11] &lt;- &quot;very low&quot; # print the variable `bloodPressure.f2` bloodPressure.f2 ## [1] low high high normal normal low high low normal normal ## [11] &lt;NA&gt; ## Levels: high low normal ## ----------- ## [1] low high high normal normal low high low ## [9] normal normal very low ## Levels: very low low normal high very high Since factors are generally very useful, it is recommended that we always take care to properly “factorize” categorical columns in our data frames. Let’s show one simple function which is often used in conjunction with factors. Analysts are often very interested in distribution of categories in a data set. To get this information, we can use the function called table who will get a factor in question as an input parameter. *** Exercise 4.10 - the table function # print the distribution of categories in `bloodPressure.f2` # print the distribution of categories in `bloodPressure.f2` table(bloodPressure.f2) ## bloodPressure.f2 ## very low low normal high very high ## 1 3 4 3 0 The table function does not necessarily require a factor and will work even with the character vector. However in that case we would not get information about categories that were not represented at all (which is often very important). The categorical variable in our examples actually has the so-called ordinal nature. In ordinal category variables the categories have a natural order (“low” blood pressure is lower than “normal” which in turn is lower than “high”). If desired, this fact can be “embedded” in the initialization process by simply adding the order parameter set to TRUE. The advantage of the ordinal factor is that it allows us to compare factor values with the help of comparative operators. Exercise 4.11 - ordinal factor # create a variable `bloodPressure.f3` by factorizing # the variable `bloodPressure` # add the `levels` attribute which will also contain # values &quot;very low&quot; and &quot;very high&quot; # also set the `order` paramater to `TRUE` # watch out for category ordering! # print the variable `bloodPressure.f3` # check if it is in fact the ordinal factor now # using the `is.ordered` function # check if the first patient has lower blood pressure # than the third # create a variable `bloodPressure.f3` by factorizing # the variable `bloodPressure` # add the `levels` attribute which will also contain # values &quot;very low&quot; and &quot;very high&quot; # also set the `order` paramater to `TRUE` # watch out for category ordering! bloodPressure.f3 &lt;- factor(bloodPressure, levels = c(&quot;very low&quot;, &quot;low&quot;, &quot;normal&quot;, &quot;high&quot;, &quot;very high&quot;), order = TRUE) # print the variable `bloodPressure.f3` bloodPressure.f3 # check if it is in fact the ordinal factor now # using the `is.ordered` function is.ordered(bloodPressure.f3) # check if the first patient has lower blood pressure # than the third bloodPressure.f3[1] &lt; bloodPressure.f3[3] ## [1] low high high normal normal low high low normal normal ## Levels: very low &lt; low &lt; normal &lt; high &lt; very high ## [1] TRUE ## [1] TRUE We have already stated that R like using the principle which goes “everything is a vector” - numbers are one-dimensional numeric vectors, matrices are vectors with added dimension parameter, lists are vectors of smaller lists, data frames are lists with added restrictions. In that vein, we can assume that factors are vectors, too. But what do they look like “under the hood”? The implementation of a factor is actually relatively straightforward - it’s simply a numeric vector where each number corresponds to a certain category, meaning that each factor vector also contains an associated “code table” in the form of an accompanying character vector. In other words, the process of factorization entails&gt; placing all categories in a separate character vector (categories are either inferred from the original vector or explicitly set with the levels parameter) assigning numeric values in the order of each category (eg: “low” -&gt; 1, “normal” -&gt; 2 etc.) “packing” together a newly created numeric vector and the associated “code table” Although these steps R works out automatically, the internal structure of a factor can easily be discovered through converting it into a pure numeric or pure character type. Exercise 4.12 - internal structure of a factor # print `bloodPressure.f3` converted to a character # print `bloodPressure.f3` converted to a numeric # print `bloodPressure.f3` converted to a character as.character(bloodPressure.f3) # print `bloodPressure.f3` converted to a numeric as.numeric(bloodPressure.f3) ## [1] &quot;low&quot; &quot;high&quot; &quot;high&quot; &quot;normal&quot; &quot;normal&quot; &quot;low&quot; &quot;high&quot; &quot;low&quot; ## [9] &quot;normal&quot; &quot;normal&quot; ## [1] 2 4 4 3 3 2 4 2 3 3 By converting the factor to the character type we actually do the operation of inverse factorization, i.e., we may go back to the original character vector. On the other hand, by converting the factor into a numerical type, we will get a list of encoded numbers that the internal factor is used to represent each category. One question can now arise - is there any benefit in converting a factor in its character or numeric counterpart? The general answer is “no”. Factor variables will automatically behave as characters wherever necessary (for example if we want to filter out all the three-lettered names). And the numeric representation is meaningless without the information what each number actually corresponds to. However, knowing what happens when we convert a factor to a character or numeric vector can help us avoid a particularly nasty error which may occur if data analyst mishandles factor variables. Good news is that since R 4.0, the possibility of this error is severely diminished, but it’s still worthwhile to know the specifics what it entails, and how to avoid it. The error in question happens when a numeric column is misidentified as a categorical column, which used to be a relatively common occurence when the analyst allowed R to automatically infer the types of columns being loaded from an external data source. Before version 4.0, R was pretty “factor happy”, meaning that it would first discern columns as either numerical (if all values could be converted into a number) or character (all other cases), which would then be followed by automatic factorization of character columns (unless this behaviour was explicitly turned off by setting the stringsAsFactors = FALSE parameter). Now imagine we have tabular data where one entry has an error (for example, 7.07 was manually inserted as 7.O7). Let’s simulate what might have happened in older versions of R. 4.4.1 Example 4.1 - mishandling factorization # simulated &quot;typing error&quot; df &lt;- data.frame(id = 1:5, measures = c(&quot;1.45&quot;, &quot;5.77&quot;, &quot;1.12&quot;, &quot;7.O7&quot;, &quot;3.23&quot;), stringsAsFactors = TRUE) # mimicking the behaviour pre-R 4.0 # trying to treat the &quot;numeric&quot; column as numeric reveals something weird mean(df$measures) ## Warning in mean.default(df$measures): argument is not numeric or logical: ## returning NA # the analyst realizes something is wrong and tries to convert the column to its proper type df$measures &lt;- as.numeric(df$measures) # measure amounts are now irreversibly lost, an error which if not caught can cause serious # problems in subsequent steps of the analysis df ## [1] NA ## id measures ## 1 1 2 ## 2 2 4 ## 3 3 1 ## 4 4 5 ## 5 5 3 How to avoid this scenario? As stated, it has now become far less likely since from R 4.0 the default value of the stringsAsFactors was switched from TRUE to FALSE. Still, it pays off to take certain precautions, especially if there is a chance that our code will be run on platforms with earlier versions of R. Some of the useful guidelines are: When using the read.csv orread.table functions, always put the string stringsAsFactors = FALSE carefully check column type data of loaded data frame perform appropriate column conversions check the results again If we adhere to these steps we will almost never come to the situation which causes us real problems. There are additional methods, like explicitly telling column types when reading from a file (colClasses parameters), or using the as.numeric(as.character(f)) syntax to be sure that a “numeric” factor will not be converted to a series of meaningless integers, but the above steps should in most cases be completely sufficient. Homework exercises Locate the file citiesNOHEADER.csv which represents the file that is the same as cities.csv except for the following features: column names are missing space is used as a separator Try using the documentation to load the data from this file into the variable called citiesNH which must end up identical to the variable cities used in this chapter. Locate the file receipt.csv and load it into the receipt variable. Ensure that character sequences were not automatically converted into factors. Print to the screen: the number of rows in this table the number of columns in the table column names For the receipt table, do the following: factorize the itemCategory column print the code, name and price of all items of the sweets and snacks category cheaper than 12 Kn print how many products each category has in the receipt add a total column that will contain the total price of each purchased item, leveraging the price and quantity calculate the total amount of the receipt Locate the file citiesNULL.csv which, if loaded without thestringsAsFactors = FALSE parameter, can result in a problematic scenario described in the lesson. Try to do the following: load the data from this file into the variable citiesNULL and deliberately set the parameter stringsAsFactors = TRUE add avgSal1 column that will represent the result of using the as.numeric function over the avgSalKn column add avgSal2 column that will represent the result of using the combination of as.character and as.numeric functions over the avgSalKn column (be careful of the order) print out citiesNULL and comment the results Programirajmo u R-u by Damir Pintar is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.Based on a work at https://ratnip.github.io/FER_OPJR/ "],["control.html", "5 Conditional statements and programming loops 5.1 Flow control commands 5.2 Loops 5.3 Example 5.1 - the repeat loop Homework exercises", " 5 Conditional statements and programming loops 5.1 Flow control commands Under flow control commands we mostly refer to programming constructs which allow for conditional execution as well as so-called “looping”, where the segment of the program will be continually executed until (optionally!) certain conditions are fulfilled and the loop is exited. We will first remind ourselves how to do conditional execution in R. 5.1.1 Conditional execution For conditional execution we use theif-then block, a construct used in almost every programming language: if (condition) {block} else {block} This command is pretty straightforward. If condition resolves to TRUE the first block will be executed, second block otherwise. We use { and } brackets to denote the start and end of block respectively, and we can do away with them completely if only one instruction is included in the block. Since we have already demonstrated the use of if-then command in Chapter 2, let’s instead show a common bug that may occur in R scripts that leverage this construct. Execute the following code and then try to correct the mistake. Exercise 5.1 - if command # execute the next conditional execution command if (2 &gt; 1) print (&quot;Success!&quot;) # find the error in the next `if-else` command and correct it if (1 &gt; 2) print (&quot;Success!&quot;) else print (&quot;Fail!&quot;) # execute the next conditional execution command if (2 &gt; 1) print (&quot;Success!&quot;) # find the error in the next `if-else` command and correct it if (1 &gt; 2) {print (&quot;Success!&quot;) } else print (&quot;Failed!&quot;) ## [1] &quot;Success!&quot; ## [1] &quot;Failed!&quot; The error occurs because R is an interpreting language that normally executes instructions row by row, and will only proceed to the next row before executing if the command is left “unfinished”. In the previous example, the second if command is actually completed in the first line, so R is “surprised” when the next line starts with else. In order to prevent this scenario, it is sufficient to indicate that the command has not yet been completed, which is most easily accomplished by opening the block in the first line and closing it in the line with else. R also has a vectorized version of conditional execution in the form of a function called, appropriately enough, ifelse. This one however does not control program flow itself, but rather performs conditional assignment based on the provided logical vector. Exercise 5.2 - ifelse function a &lt;- 1:3 b &lt;- c(0, 2, 4) # what does the vector `x` look like after executing the following command? # try to predict the answer and then uncomment and check if you are correct #x &lt;- ifelse (a &lt; b, 2, 5) a &lt;- 1:3 b &lt;- c(0, 2, 4) # what does the vector `x` look like after executing the following command? # try to predict the answer and then uncomment an dcheck if you are correct x &lt;- ifelse(a &lt; b, 2, 5) x ## [1] 5 5 2 This function is particularly suitable for creating new columns of data frames when we want a logical column derived from certain conditions related to the existing columns. 5.2 Loops Loop is a programming construct where depending on a condition a block of code gets repeated multiple times. In programming language R we have three loop variants, each using a different keyword: repeat - conditionless, infinite loop while - loop that checks condition before entering for - an iterator loop (“loop with known number of repetitions”) 5.2.1 Therepeat loop The repeat is arguably the simplest type loop. It has the following syntax: repeat {block} This is an “infinite” loop where, once the block is completed, it gets re-executed again, and so on. The only way to exit this loop is to explicitly “break” out of it using the break command. In addition to break, we also have a next command that will skip the rest of the block, but will then go back to the beginning of the loop. Let’s see this loop in action in the following example. 5.3 Example 5.1 - the repeat loop # answer the following questions before running the next block: # - will the loop run indefinitely? # - what will be printed on the screen? i &lt;- 1 repeat { i &lt;- i + 1 if (i %% 2 == 0) next print(i) if (i &gt; 10) break } This type of loop is not used very frequently, mostly because it is usually more convenient to put the condition for exiting the loop in a more prominent place, which is exactly what the while loop does. 5.3.1 The while loop The while loop uses a simple syntax which means “while the following condition is met, repeat the specified code”: while (condition) {block} The condition should evaluate to TRUE or FALSE, or something that can be implicitly converted to those values. We can also use break and next commands in the while loop; break will immediately exit the loop, and next will go back to checking the condition. Exercise 5.3 - The while loop # add the looping condition so the loop # prints something on screen exactly 7 times i &lt;- 1 while () { print(i) i &lt;- i + 1 } # add the looping condition so the loop # prints something on screen exactly 7 times i &lt;- 1 while (i &lt;= 7) { print(i) i &lt;- i + 1 } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 ## [1] 6 ## [1] 7 The while loop can also become an infinite loop if we enter the condition which never becomes FALSE, for example if we literally set while(TRUE). Let’s try to use this loop in a slightly harder exercise. Exercise 5.4 - The while loop (2) n &lt;- 1234 nbin &lt;- numeric(0) # fill vector `nbin` with digits of `n` when turned into a binary form # example: if `n` was 12, `nbin` should be c(1,1,0,0) # use a `while` loop # hint: a function called `rev` can be used to reverse the order of elements in a vector # print resulting `nbin` on screen n &lt;- 682 nbin &lt;- numeric(0) # fill vector `nbin` with digits of `n` when turned into a binary form # example: if `n` was 12, `nbin` should be c(1,1,0,0) # use a `while` loop # hint: a function called `rev` can be used to reverse the order of elements in a vector # print resulting `nbin` on screen while (n != 0) { nbin &lt;- c(nbin, n %% 2) n &lt;- n %/% 2 } nbin &lt;- rev(nbin) nbin ## [1] 1 0 1 0 1 0 1 0 1 0 5.3.2 The for loop In programming languages for loop or “iterator loop” is most commonly used to traverse over a data structure (i.e. a vector) and process each element in turn, often ultimately packaging all the results in a new structure. The syntax for the for looks like this: for (i in v) {do something with i} In this expression v is a structure we are traversing over and i is a new variable which will be used to refer to the currently referenced element while inside the loop. Also, be careful not to mistake the keyword in with an operator %in% which you may recall is used for checking whether some element exists in a certain structure. Using the for loop this way will give us access to the contents of the element, but we will not be able to infer information about the original structure (for example if we want to change the element in place). There’s an alternative way of using the for loop where instead of iterating over elements themselves, we are iterating over integers we then use inside the loop for positional indexing: for (i in 1:length (a)) {do something with a[i] This way, while less elegant, is more flexible and often preferable. Exercise 5.5 - for loop a &lt;- seq(-10, 10, 4) # print vector elements of `a` one by one # with the help of `for` loop # access the elements directly # do the same, but iterate by indexes a &lt;- seq(-10, 10, 4) # print vector elements of `a` one by one # with the help of `for` loop # access the elements directly for (i in a) print(i) # do the same, but iterate by indexes for (i in 1:length (a)) print(a[i]) ## [1] -10 ## [1] -6 ## [1] -2 ## [1] 2 ## [1] 6 ## [1] 10 ## [1] -10 ## [1] -6 ## [1] -2 ## [1] 2 ## [1] 6 ## [1] 10 Notice how the second way is better if you want to change the vector elements or need information on where the element is located in the original vector. Let’s now try a slightly more complex exercise. Exercise 5.6 - for loop (2) # read data from &quot;people.csv&quot; file into a data frame called `people` # then, using a `for` loop, for each numeric column # print its name and the mean of its values (function `mean`) # read data from &quot;people.csv&quot; file into a data frame called `people` # then, using a `for` loop, for each numeric column # print first its name and then the mean of its values (function `mean`) people &lt;- read.csv(&quot;people.csv&quot;) for (i in 1:length(people)) { if (is.numeric(people[[i]])) { print(names(people)[i]) print(mean(people[[i]])) } } ## [1] &quot;birthyear&quot; ## [1] 1978.404 ## [1] &quot;weight&quot; ## [1] 75.1223 ## [1] &quot;height&quot; ## [1] 160.5191 Be careful not to forget the difference between the [ and [[ operators. Also, note how we retrieved the name of the current element simply by using a names function to get the vector names (list is a vector, as you recall), and then leveraging positional indexing and i to get the actual name. Now that now that we have learned the loop syntax, it is important to emphasize one fact - in programming language R, it is generally not recommended to use program loops. Although this may initially seem unexpected and somewhat unorthodox, the reason is simple - as you may recall, R language is designed to work by the declarative “all at once” principle. We have already seen that the principle of vectorization and recycling effectively perform jobs that would often require constructing a programming loop in other programming languages, and in the chapters that follow, we will see that R also offers many other constructs that avoid explicit code repetition with the requirement of a declarative syntax that automatically performs it. For example, the following code is syntactically correct: # example of unnecessary loop usage a &lt;- 1: 5 b &lt;- 6:10 c &lt;- numeric() for (i in 1:length (a)) c[i] &lt;- a[i] + b[i] but probably works slower and is much less readable than: # R syntax a &lt;- 1:5 b &lt;- 6:10 c &lt;- a + b All of this does not mean that we should not use loops in R, but that their use should be accompanied by an additional consideration of whether the loop is really needed and whether there is an alternative syntax that completes the same task but can be written declaratively (and is potentially faster, since many routines in R are implemented in language C). Early adoption of the “R” mode of thinking will result in long-term benefits that will be reflected in a more compact, cleaner, and often more effective program code. Homework exercises Create a data frame with the following command: cities &lt;- data.frame(zipcode = c(10000, 51000, 21000, 31000, 2000), cityName = c(&quot;Zagreb&quot;, &quot;Rijeka&quot;, &quot;Split&quot;, &quot;Osijek&quot;, &quot;Dubrovnik&quot;), cityTax= c(18, 15, 10, 13, 10)) Add a column called “taxLevel” which will be the ordinal factor variable with the levels “small”, “medium” and “high” depending on whether the percentage of tax is strictly smaller than 12, between 12 and 15 or strictly greater than 15. Use the ifelse command. Replace the loops in the next block with equivalent vectorized operations (for the second loop, review the sum function documentation). a &lt;- numeric() i &lt;- 1 while (i &lt;= 100) { a &lt;- c(a, i) i &lt;- i + 1 } total &lt;- 0 for (i in a) { if (i %% 2 == 0) total &lt;- total + i * i } print (total) Program in Ru &lt;/ span&gt; by Damir Pintar is licensed under Creative Commons Attribution-NonCommercial-NoDerivative 4.0 International License Based on a work at https://ratnip.github.io/FER_OPJR/ "],["packages.html", "6 Packages, built-in functions and environments 6.1 Working with packages 6.2 Built-in functions 6.3 Environments Homework exercises", " 6 Packages, built-in functions and environments 6.1 Working with packages The standard R distribution comes with two collections of packages (called r-base and r-recommended) that contain a language R “core” of sorts - a set of building blocks sufficient for conducting the most typical data analysis tasks using the programming language R. In addition, CRAN (Comprehensive R Archive Network) provides a rich repository of additional packages for a wide variety of applications, from “quality-of-life” upgrades to basic elements to highly specialized packages aiming for extremely specific purposes. In line with common programming language practices, R uses a notion of “packages” or “libraries” to logically organize already “pre-programmed” collections of data, functions, and compiled code. Upon starting the R environment, certain packages are automatically loaded, making their content immediately available for use. The list of loaded packages can be easily obtained using the search function, which will then show us the so-called “search path”. Exercise 6.1 - the search path # call the `search` function (no parameters) # to see which packages are loaded into the environment # call the `search` function (no parameters) # to see which packages are loaded into the environment search() ## [1] &quot;.GlobalEnv&quot; &quot;package:lubridate&quot; &quot;package:GGally&quot; ## [4] &quot;package:forcats&quot; &quot;package:stringr&quot; &quot;package:dplyr&quot; ## [7] &quot;package:purrr&quot; &quot;package:readr&quot; &quot;package:tidyr&quot; ## [10] &quot;package:tibble&quot; &quot;package:ggplot2&quot; &quot;package:tidyverse&quot; ## [13] &quot;package:MASS&quot; &quot;package:stats&quot; &quot;package:graphics&quot; ## [16] &quot;package:grDevices&quot; &quot;package:utils&quot; &quot;package:datasets&quot; ## [19] &quot;package:methods&quot; &quot;Autoloads&quot; &quot;package:base&quot; We see that most packages are listed as package::package_name. The positioning of the package name in the list also represents their “priority” in the namespace traversal path, which will be discussed later. If we want to load a new package into our environment, we can do this by using the library function with the package name provided as a parameter (without quotes). Exercise 6.2 - loading new packages into the working environment # load the `lubridate` package (or other package of your choice) # load the `lubridate` package library(lubridate) The command from the previous example commonly results in one of these two outcomes: if the package exists locally (in a folder designated for storing additional packages), it will be loaded into the working environment. Package loading can be accompanied by messages about objects that are “masked” after loading. This in particular means that the new package has temporarily denied access to certain elements from previously loaded packages because their names match. This often does not pose any problems, but if the user has the need to access the masked elements they will have to use their “full name” - e.g. they will also have to specify the name of the package where they are located. For example, if the filter function of the stats package is masked after loading the new package, it is still available through the full name stats::filter, but not directly through the name filter, as this will call the function from the latest loaded package. More details about how R resolves the names of variables and functions will be given below. if we do not have the above package on the local computer, we receive an error message that this package does not exist. In this case, supposing the package name is correct and it does exist on the CRAN repository, it is necessary to retrieve it from there using the install.packages function, which gives the name of one or more packages (with quotation marks!) as parameters. This function assumes that the R environment has a predefined CRAN mirror i.e. the specific address of the CRAN repository from where the package will be downloaded (a large number of countries have their own “copy” of the CRAN repository). If we are working in the RStudio interface, it has probably automatically turned on the setting which finds the closes CRAN repository, but in the very rare chance there are problems (which aren’t related to internet connectivity) it might be useful to check the documentation and see how the access to another CRAN repository can be established. Exercise 6.3 - installing a package from a CRAN repository # install the `hflights` package from the CRAN repository # (You can do this even if you already have the specified package) # load the package again into the work environment # print the search path # install the `dplyr` package from the CRAN repository # (You can do this even if you already have the specified package) install.packages(&quot;hflights&quot;) # load the package again into the work environment library(hflights) # print the search path search() ## [1] &quot;.GlobalEnv&quot; &quot;package:lubridate&quot; &quot;package:GGally&quot; ## [4] &quot;package:forcats&quot; &quot;package:stringr&quot; &quot;package:dplyr&quot; ## [7] &quot;package:purrr&quot; &quot;package:readr&quot; &quot;package:tidyr&quot; ## [10] &quot;package:tibble&quot; &quot;package:ggplot2&quot; &quot;package:tidyverse&quot; ## [13] &quot;package:MASS&quot; &quot;package:stats&quot; &quot;package:graphics&quot; ## [16] &quot;package:grDevices&quot; &quot;package:utils&quot; &quot;package:datasets&quot; ## [19] &quot;package:methods&quot; &quot;Autoloads&quot; &quot;package:base&quot; The install.packages function has many additional parameters which might be a good idea to check, especially if certain problems arise while using the package. For example, setting the dependencies parameter to TRUE will explicitly state that all packages that the new package being installed is depending on need to be installed, too, if for some reason they didn’t get installed during the first installation try. Note: as a rule, we install packages only once, through the console so that there is never a need to install the package installations in R Markdown documents; also, for easier organization of reports, loading all required packages is usually done by at the beginning of the document, in the code snippet called setup. If we want to update packages, one of the easiest way to do this is to simply install them again (caution: if there is a huge discrepancy between package versions, this can cause issues with the code). If we want to find out more information about a package, one way to achieve this would be to do this would be calling the library function with the parameter called help set to the package name. library(help = dplyr) # recommendation: try directly in the console However, usually it’s more convenient to simply search for the package name (i.e. “CRAN dplyr”) in the web browser and then read the documentation PDF. Another quite popular way of perusing documentation of the package is with the help of the so-called “vignettes”. Vignettes are actually “mini-tutorials” of a package done in HTML which present the functionality of the package in an accessible way with the help of detailed explanations and the associated program code. We can look at which vignettes are installed on the system by calling the browseVignettes() function without parameters (or optionally adding as the parameter the package name if we only care about its vignettes). If the package has only one vignette (for example, stringr), we can also open the vignette immediately with the help of the vignette option. vignette(&quot;stringr&quot;) # recommendation: try directly in the console 6.2 Built-in functions In previous chapters, we have already introduced some of the functions that we get bundled in with our R distribution. These are, for example, numeric functions (log,abs, sqrt,round, etc.), vector creation functions (rep,seq, etc.), package management functions (install.packages, library, etc.) and so on. R rarely uses the term “built-in” functions since - as it was already shown - the R environment automatically loads some commonly used packages whose elements are immediately available for use, without necessarily indicating the name of the package they are in. Let’s take the stats package for example. This package contains a rich set of functions related to statistical processing. One of these functions is rnorm, which returns a numerical vector of the desired length whose elements are randomly selected from the normal distribution with arithmetic mean 0 and standard deviation 1 (these values can also be changed using the mean and sd parameters). If we want, we can easily invoke this function by using its full name, i.e. the package_name::function_name(parameters) syntax. Exercise 6.4 - calling a function with its full name # create a vector `x` that will have 10 random elements # drawn from standard normal distribution # use the full name of the `rnorm` function of the`stats` package # round the elements of vector `x` to two decimal places # use the full name of the `round` function from the `base` package # print vector `x` # create a vector `x` that will have 10 random elements # drawn from standard normal distribution # use the full name of the `rnorm` function of the `stats` package x &lt;- stats::rnorm(10) # round the elements of vector `x` to two decimal places # use the full name of the `round` function from the `base` package x &lt;- base::round(x, 2) # print vector `x` x ## [1] 1.43 0.98 -0.62 -0.73 -0.52 -1.75 0.88 1.37 -1.69 -0.63 Although this is a syntactically correct way of calling a function, it’s usually more common to see a call which excludes package names and simply names the function directly. Exercise 6.5 - calling a function without the package name # create vector `y` by the same principle as vector x # use only one line of code # use the function names without the name of the package # print vector `y` # create vector `y` by the same principle as vector x # use only one line of code # use the function names without the name of the package y &lt;- round(rnorm(10), 2) # print vector `y` y ## [1] 0.02 0.71 -0.65 0.87 0.38 0.31 0.01 -0.04 0.72 -0.50 We can ask ourselves - how does R know where to find the function’s implementation, if we did not explicitly specify the package where it’s contained? There’s a very easy answer to this, which will be outlined in the next subchapter dealing with environments.Before we delve into this, let’s just remind ourselves that R allows us to quickly get help on the function by simply calling ?function_name or help(function_name), and that we can get examples of using the function through example(function_name). We should use these calls very often even if we think that we are well acquainted with the function we are calling - it is possible that there is an additional parameter (or a related function that is also often listed in the documentation), which will further help us in carrying out the task related to the function we want to use. 6.3 Environments As already mentioned, working in R often boils down to writing instructions on how to manipulate various objects. To do this, we need mechanisms which help us easily refer to the objects concerned. In R (and other programming languages), this is called “binding”. When we created a variable called x of the numeric type and assigned a number 5 to it, what we actually did was asking R to reserve a place a memory for a new data container (for numerical data) and to document a new character string reference which was then “bound” to this container, allowing us to retrieve or change its contents. Let’s now try to think what happens when our code refers to x. When R sees this name, it must search its internal “records” to determine which variables currently exist, of what types they are and how to access them. In order to find the variable which corresponds to stated name, R uses a mechanism called “lexical scoping”, based on the concept of “environments”. An “environment” is often referred to as a “bag of names”. It helps us to logically group the names of the objects we use and to help R find the name in other environments if the variable does not exist in the current environment. The latter is enabled with the system that dictates that every environment needs to have its own “parent environment” (except the one on the very top, the so-called “empty environment”). This system of parent environment links then creates a kind of “environment hierarchy”, often referred to as “search path”; R, looking for the default variable name, searches the environments “upwards” until it finds the first appearance of the requested name or encounters an the empty environment. An interesting fact is that the environment itself is also an object - if we want, we can create a reference to it, send it to functions as a parameter, and so on. The “default” environment in which we work and in which we create new variables is the so-called “global environment”, or .GlobalEnv (watch out for the dot!). It is at the bottom of the environment hierarchy. We can get a reference to it via the mentioned variable name, or by using the globalenv() function. Exercise 6.6 - global environment # create a variable `e` which refers to the global environment # print `e` # create a variable `x` and assign the number `5` to it # execute the `ls` function, without parameters # execute the `ls` function with `e` as a parameter # print `x` # print `e$x` (notice the list syntax!) # create a variable `e` which refers to the global environment e &lt;- .GlobalEnv # or e &lt;- globalenv() # print `e` e # create a variable `x` and assign the number `5` to it x &lt;- 5 # execute the `ls` function, without parameters #ls() # try directly on console! # execute the `ls` function with `e` as a parameter #ls(e) # try directly on console! # print `x` x # print `e$x` (notice the list syntax!) e$x ## &lt;environment: R_GlobalEnv&gt; ## [1] 5 ## [1] 5 —–TU JE PROBLEM —– From the last example, we can see that the environment also references itself, so this is a completely correct (although unnecessarily complicated) syntax for printing the x variable: e$e$e$e$e$e$e$e$e$e$e$e$e$e$e$e$e$e$e$e$x The environments are somewhat similar to lists, meaning that they basically “encapsulate” a certain number of objects in a unique structure which then allows for refering to them byh names. The most important differences between environments and lists are: the order of elements in the environment is irrelevant the environment (as a rule) has a link to its parent environment If we have a reference to an environment, we can easily get a reference to its parent environment using the parent.env function. Exercise 6.7 - parent environments # print out the parent environment of the global environment and explain the result # print out the parent environment of the global environment and explain the result parent.env(e) ## &lt;environment: package:lubridate&gt; ## attr(,&quot;name&quot;) ## [1] &quot;package:lubridate&quot; ## attr(,&quot;path&quot;) ## [1] &quot;C:/R/R-4.2.1/library/lubridate&quot; As we can see, the parent of the global environment is the last loaded package. This should not really be too unusual - the global environment has the largest “priority” when referencing the variables, but immediately below it are the objects and functions that we last loaded into the work environment (supporting the assumption that the “most recent” package is the one that we intend to use immediately). In other words, by loading a package, the new package is always “slotted in” between the global environment and the package that was previously loaded last. When we called the search function, what we actually got was the hierarchy of environments that represented all loaded packages in the order of their loading. In other words, the “search path” and “environment hierarchy” are basically the very same thing. If we want, we can make easily create our own environments and place them in their own hierarchy. We can even go one step further and create new variables in these environments (whose references will be tied to that environment instead of the global one). With these environments we can: put new variables in using the assign function or the combo of &lt;- and $ operators (like adding an element to a list) retrieve variables using the get function or the $ operator (like retreiving element from a list) list all variables using the ls function and the reference to the environment check if a variable exists using the exists function Look at the example below to get the feeling how custom environments work. # example - a small hierarchy of custom environments e &lt;- emptyenv() # the empty environment e2 &lt;- new.env() e3 &lt;- new.env() # hierarchy `e3` --&gt; `e2` --&gt; `e` (empty) parent.env(e2) &lt;- e parent.env(e3) &lt;- e2 # creating variable `x` in `e2` assign(&quot;x&quot;, 5, e2) # or e2$x &lt;- 5 # checking if there is an `x` in `e2` exists(&quot;x&quot;, e2) # listing all variables from `e2` ls(e2) # printing `x` from `e3` (even though it doesn&#39;t exist there) get(&quot;x&quot;, e3) # or e3$x ## [1] TRUE ## [1] &quot;x&quot; ## [1] 5 Why use the environment in practice? The environment is a convenient way of “wrapping” a set of variables that we can then send together in a function - for example variables which refer to large datasets. This was especially important in earlier versions of R that always defaulted to the so-called copy-on-modify mechanism, which goes: the function will use the reference to the original object sent to it as a parameter up to the point a command is met that will try to change said object; at that moment a copy of that object is created and all the changes pertain to the copy. This meant that sending lists containing very large elements could severely impact the performance since any changes on those elements would trigger copying them first, and then doing the change. An easy way to avoid this was simply wrapping those elements in environments instead. Since R 3.1.0 lists sent to a function will keep using a reference instead of making a deep copy, so the need to leverage the “environment workaround” is diminished. Finally, let’s demonstrate the attach function that certain data analysts tended to use to speed up the analysis process and write more readable code, but which can cause serious problems if used improperly. This function basically insert the data frame’s reference directly into the search path, allowing us to refer to its columns as if they were variable names in the global environment, without the need to reference the data frame itself. This sounds convenient, but has some very unfortunate side effects, best shown through an exercise. Exercise 6.8 - attach function cities &lt;- data.frame( zipcode = c(10000, 51000, 21000, 31000, 2000), cityName = c(&quot;Zagreb&quot;, &quot;Rijeka&quot;, &quot;Split&quot;, &quot;Osijek&quot;, &quot;Dubrovnik&quot;), avgSalary = c(6359., 5418., 5170., 4892., 5348.), population = c(790017, 128384, 167121, 84104, 28434), tax = c(18, 15, 10, 13, 10)) # execute function `attach` with `cities` as parameter # do this only once! # print the search path and comment on the result # print the `tax` &quot;variable&quot; # change the third element from the `tax` variable from 10 to 12 # print `cities`. Why is the tax in the 3rd row still 10? # execute the `ls` function # use the `detach` function to remove `cities` from the search path # execute function `attach` with `cities` as parameter # do this only once! attach(cities) ## The following object is masked from package:tidyr: ## ## population # print the search path and comment on the result search() cat(&quot;-------------------------\\n&quot;) # print the `zipcode` variable tax cat(&quot;-------------------------\\n&quot;) # change the third element from the `tax` variable to 12 tax[3] &lt;- 12 # print `cities` cities cat(&quot;-------------------------\\n&quot;) # execute the `ls` function #ls() # try it on console! # use the `detach` function to remove `cities` from the search path detach(cities) ## [1] &quot;.GlobalEnv&quot; &quot;cities&quot; &quot;package:lubridate&quot; ## [4] &quot;package:GGally&quot; &quot;package:forcats&quot; &quot;package:stringr&quot; ## [7] &quot;package:dplyr&quot; &quot;package:purrr&quot; &quot;package:readr&quot; ## [10] &quot;package:tidyr&quot; &quot;package:tibble&quot; &quot;package:ggplot2&quot; ## [13] &quot;package:tidyverse&quot; &quot;package:MASS&quot; &quot;package:stats&quot; ## [16] &quot;package:graphics&quot; &quot;package:grDevices&quot; &quot;package:utils&quot; ## [19] &quot;package:datasets&quot; &quot;package:methods&quot; &quot;Autoloads&quot; ## [22] &quot;package:base&quot; ## ------------------------- ## [1] 18 15 10 13 10 ## ------------------------- ## zipcode cityName avgSalary population tax ## 1 10000 Zagreb 6359 790017 18 ## 2 51000 Rijeka 5418 128384 15 ## 3 21000 Split 5170 167121 10 ## 4 31000 Osijek 4892 84104 13 ## 5 2000 Dubrovnik 5348 28434 10 ## ------------------------- What happened up there? With the attach function, the cities data frame became a “mini-environment”, i.e. its columns became available within the search path. The obvious benefit of this is that we can refer to the columns directly, without referencing the original data frame and operator $. But this seemingly practical trick has hidden traps - first, if the column names match variable names in the global environment, then these variables will take precedence (we will get a warning when attaching, but not if we create new variables with identical names later on). Second - and much more problematic - if we try to change the column of the data frame by directly referencing just its name, R will silently apply the copy-on-modify principle by creating a new variable in a global environment that will be a copy of the referenced column. An inattentive analyst can completely miss the fact that the changes are not reflected at the data frame itself, and then proceed with the analysis as if these changes were made, which can have far-reaching consequences. These potential problems are very widespread among R beginners, so in the R literature it is commonly suggested that the attach function is not used unless it is deemed very necessary. For example. Google’s R-style guide says “the error potentials for using the attach function are numerous, so avoid it”. If we really dislike having to continual refer to the name of the data frame when referencing its columns, there are new packages that allow exactly this without the unfortunate side-effects of the attach function. We will be diving deep into these packages in one of the latter chapters - until then, the safest way to refer to data frame columns is to always use the $ operator coupled with the name of the data frame itself. Homework exercises Load the following packages in the working environment: magrittr, dplyr, tidyr,ggplot2. Print the search path and check where the loaded packages are. The following commands will create a vector of 20 randomly selected natural numbers from 1 to 100. # 20 random natural numbers from 1 to 100, with repetition set.seed(1234) a &lt;- sample(1:100, 20, replace = T) Use the cheat sheets and/or official documentation to find built-in functions that perform the following tasks. Print vector a the values of the vector a arranged in reverse order unique values from the vector a the values of the vector a sorted in ascending order We mentioned that loaded packages are actually “environments”. If we want to get a direct reference to them, we need to use as.environment and the package name. Try to get a reference to the package::magrittr package in the form of an environment, and use ls to check which names are contained within it. Programirajmo u R-u by Damir Pintar is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.Based on a work at https://ratnip.github.io/FER_OPJR/ "],["user.html", "7 User Defined Functions 7.1 User defined functions 7.2 The apply family Homework exercises", " 7 User Defined Functions 7.1 User defined functions Although R is an object-oriented programming language, it leans heavily towards the realm of functional programming. This functional paradigm is not new (it dates back to the 1950s), but has recently gained considerable popularity as a kind of complement to the object-oriented programming, which might be said was the dominant programming paradigm in the last few decades. In order not to delve too deep into the subject of functional programming and its relationship to object-oriented principles, we will list only a few indicative features and guidelines related to these two leading paradigms. Object-oriented programming in principle, sees the program as a system of nouns where the components are realized in the form of objects that encapsulate the attributes of the mentioned noun and the methods that perform certain tasks related to the given noun. Also, object-oriented systems focus on the controlled change of the components’ state, commonly as a result of the exchange of messages between them. Functional programming sees the program as a system of verbs where the functions, i.e. the tasks we want to execute, have priority over the components over which these tasks are executed. Functional programming models the information system through components that generally do not change their own state, so that the result of the program is strictly dependent on the inputs, which facilitates testing and maintenance. In short, the distinction between object-oriented programming and function programming can be oversimplified as follows: “For object-oriented programming, we create data that contains functions, and in functional programming we create functions that contain data”. We do not have to be too bothered with the features of functional programming to learn R, nor should it be necessary to adopt a completely new programming paradigm. But for successful mastering of R, adapting some of the functional programming concepts can prove to be extremely useful since it will allow us to write cleaner and more efficient code that will be in accordance with the way in which R is designed as a language. In R, the following is true: functions are “first-order” objects, we can reference them with a variable of the selected environment, send them to functions as arguments, receive as return values function and store them in data structures, such as a list. The function in R is simply an “executable” object. A large number of functions - especially those that replace the program loop construct - work on the principle of functional languages where we perform the work in a manner that declaratively specifies which function we want to apply on which data structure, and let the programming language itself perform low-level tasks such as iteration by structure and preparation of the result. Examples of this will be learned soon, but now let’s first learn how to create our own functions in R. 7.1.1 Defining a new function In a general case, the definition of a new function looks like this: function_name &lt;- function(input arguments) { function_body return_statement } We can notice that the function definition leverages the operator &lt;-. This is not a coincidence - the definition of a function is merely creating a “callable” variable in a certain environment - the name of that variable is the name of the function we are creating. In R we do not define the types of input and output arguments. Input arguments have a name and an optional default value. The functions formally return one single value, which is not necessarily restrictive as it sounds - returning multiple variables simply means we wrap them first in the form of a vector or a list. The return keyword (whose syntax is like a function, i.e. return(x)) can be used to explicitly state what is being returned, but is actually optional - the function automatically returns the result of the last expression in the function, so we can simply put the name of the returning variable as the last line in the function, or even just leave the expression which calculates it, even though that can slightly compromise the readability. For example, we can write a simple function that doubles the input parameter like this: doubleUp &lt;- function(x) { y &lt;- 2 * x return(y) } or, shorter: doubleUp &lt;- function(x) { y &lt;- 2 * x y } or even like this: doubleUp &lt;- function(x) { 2 * x } Let’s try to create another simple function. For starters, let’s make our own implementation of the abs function, called myAbs. Exercise 7.1 - first user defined function # create a function called `myAbs` which # will mimic R&#39;s `abs` function (but will not call it directly) # create a function called `myAbs` which # will mimic R&#39;s `abs` function (but will not call it directly) # BAD SOLUTION! myAbs &lt;- function(x) { if (x &lt; 0) -x else x } # try myAbs(c(1, -1)). Why doesn&#39;t this work correctly? # create a function called `myAbs` which # will mimic R&#39;s `abs` function (but will not call it directly) # GOOD SOLUTION myAbs &lt;- function(x) { ifelse(x &lt; 0, -x, x) } We usually want to write functions which follow R’s philosophy of “everything is a vector”, so they should work properly on vectors, not just scalar, if it makes sense concerning the planned functionality. Finally, if we want to increase the robustness of the function in such a way that we reject the execution of the logic within a function if certain conditions are not satisfied, we can use the stopifnot function. This function calculates the default logical expression and terminates the function if the specified condition is not true. Exercise 7.2 - using stopifnot inside a function definition # write the function `parallelMax` which requires two numeric vectors as input # and returns a vector of the same size containing the larger # between two corresponding elements of the original vectors # if one or both vectors aren&#39;t numeric or aren&#39;t the same size # the function must throw an error # do not use loops! # execute this new function over the following vector pairs # c(T, F, T) i c(1, 2, 3) # c(1, 2, 3, 4) i c(5, 6, 7) # c(1, 2, 3) i c(0, 4, 2) # (second part of the exercise should be tested inside the console!) # write the function `parallelMax` which requires two numeric vectors as input # and returns a vector of the same size containing the larger # between two corresponding elements of the original vectors # if one or both vectors aren&#39;t numeric or aren&#39;t the same size # the function must throw an error # do not use loops! parallelMax &lt;- function(a, b) { stopifnot(is.numeric(a) &amp;&amp; is.numeric(b) &amp;&amp; length(a) == length(b)); ifelse(a &gt; b, a, b) } When calling a function, we can optionally specify the parameter names, and R will even allow the mixing of named and unnamed parameters (although this is not something we should often use in practice). When R connects the sent values with formal parameters, the named parameters will have priority and will be resolved first, after which the unnamed parameters will be resolved in te order they were provided. We can see this in the next exercise, in which we will use the opportunity to showcase a very useful function - paste. This function concatenates character strings with the addition of a space separator (there is an alternative function paste0 for joining without spaces). Exercise 7.3 - function parameters printABC &lt;- function(a, b, c) { print(paste(&quot;A:&quot;, a, &quot;B:&quot;, b, &quot;C:&quot;, c)) } # think before executing - what will be printed with the following command? #printABC(1, a = 2, 3) printABC &lt;- function(a, b, c) { print(paste(&quot;A:&quot;, a, &quot;B:&quot;, b, &quot;C:&quot;, c)) } # think before executing - what will be printed with the following command? printABC(1, a = 2, 3) ## [1] &quot;A: 2 B: 1 C: 3&quot; In practice, we should stick to conventions which dictate first using unnamed parameters in the order they appear in the function definition, and then named. It is customary to set only those named parameters whose default value does not suit us, whereas strict ordering does not matter (although using the order provided in the function definition will increase the legibility of our code). If we want to write a function that receives an arbitrary number of arguments, we can use the element ..., i.e. the ellipsis. An example of this feature is the built-in paste function which can receive an arbitrary number of character strings. If we use the ellipsis in our functions, we should place them at the end of the list of input arguments, and within the function itself we simply convert it into a list, and then access its parameters in the way that suits us. Exercise 7.4 - function with an arbitrary number of parameters printParams &lt;- function(...) { params &lt;- list(...) for (p in params) print(p) } # call the above function with any random parameters printParams(c(1, 2, 3), 5, T, data.frame(x = 1:2, y = c(T, F))) ## [1] 1 2 3 ## [1] 5 ## [1] TRUE ## x y ## 1 1 TRUE ## 2 2 FALSE 7.1.2 The “copy-on-modify” principle One of the more common questions raised when learning a new programming language is whether the functions work in “call-by-value” or “call-by-reference” mode. The difference is basically whether the function may change the content of the variables sent at the place of the formal argument or not; call-by-value principle forward only copies of original arguments. On the other hand, the call-by-reference principle makes it so the function receives “references” of the original variables, i.e. it behaves as if the original variables were passed to the function and all changes to them would be reflected in the calling function or program. The language R uses a hybrid principle known as copy-on-modify. With this principle, references are forwarded to the function, which allows us to transmit “large” variables without the fear of them getting unnecessarily copied. But this is only valid if the function does not change the value of the resulting variables - at the moment when the function attempts to make any changes, copying the variable is carried out and the function continues to work on the copy. Let’s check the above statements in a following examples. 7.1.3 Example 7.1 - “copy-on-modify” # creating a data frame df &lt;- data.frame(id = 1:5, name = LETTERS[1:5]) # function changes a column and returns nothing # (assignment operator does not have a return value) f &lt;- function(x) { x$name[1] &lt;- &quot;change!&quot; } # the original data frame is unchanged f(df) df ## id name ## 1 1 A ## 2 2 B ## 3 3 C ## 4 4 D ## 5 5 E The function actually creates a new temporary environment within which it stores “local” variables. In the above example, a new copy of the column in question is created and changed - but the original data frame column is unchanged. It is important to note that the function could access an external variable even without sending it to the function, since by referencing the x variable that does not exist in the local environment the R search function will continue in the parent’s environment, which in this case would be the global environment. Attempting to change this variable would still fail - R would detect an attempt to change the variable and create a local copy of the same name. 7.1.4 Example 7.2 - “copy-on-modify (2)” # creating a data frame df &lt;- data.frame(id = 1:5, name = LETTERS[1:5]) # function changes a column of the external data frame and returns nothing f &lt;- function() { df$name[1] &lt;- &quot;change!&quot; } # the original data frame is unchanged f() df ## id name ## 1 1 A ## 2 2 B ## 3 3 C ## 4 4 D ## 5 5 E One way to work around is is to wrap the data frame in its own environment. This way we can “force” the function to use call-by-reference, and at the same time ensure that no deep copies will be unnecessarily created. 7.1.5 Example 7.3 - “copy-on-modify” and environments # creating a data frame in a new environment e &lt;- new.env() parent.env(e) &lt;- emptyenv() e$df &lt;- data.frame(id = 1:5, name = LETTERS[1:5]) # function changes a data frame using a reference from the environment f &lt;- function(e) { e$df$name[1] &lt;- &quot;change!&quot; } f(e) e$df ## id name ## 1 1 change! ## 2 2 B ## 3 3 C ## 4 4 D ## 5 5 E A simpler way of solving the above task would be using the &lt;&lt;- operator. This operator’s function is to change the variable of the given name that is located somewhere in the search path. R will follow the search path, and change the first occurrence of the specified variable. If the variable of this name does not exist anywhere in the search path, R will create a new variable in the first environment above the environment of the function. 7.1.6 Example 7.4 - the &lt;&lt;- operator # operator `&lt;&lt;-` f &lt;- function(x) { x &lt;&lt;- 7 x &lt;- 6 } x &lt;- 5 f() x ## [1] 7 Let’s see how this would work with our data frame. 7.1.7 Example 7.5 - changing a data frame column with the &lt;&lt;- operator # creating a data frame df &lt;- data.frame(id = 1:5, name = LETTERS[1:5]) f &lt;- function() { df$name[1] &lt;&lt;- &quot;change!&quot; } f() df ## id name ## 1 1 change! ## 2 2 B ## 3 3 C ## 4 4 D ## 5 5 E However this operator should be used very cautiously, and we will achieve greater robustness using the assign or$operator with reference to the environment where the variable we want to change is. Finally, we must mention one feature of functions in R - the so-called. “lazy evaluation”. This simply means that R will not evaluate the received parameter until it is explicitly used. Up to that moment, this object is so-called. “promise” - R “knows” how to evaluate that object but it will not do so until it really needs it. This increases the efficiency of the language; if a parameter is used only in a conditional branch, then in scenarios when it is not needed it will not consume memory. But equally, we need to be careful because a lazy evaluation can lead to unexpected problems if we do not take into account its existence. 7.1.8 Function as an object We have already said that R has good support for the so-called “functional programming” which represents a programming paradigm that puts emphasis on designing functions without reliance on objects with interchangeable states. One of the characteristics of such languages are “first class functions”, which means that the language supports the definition of functions in such a way that they are equal objects to all other types of objects - they can be stored in a variable, used as an input argument of another function or as a return value, stored in other data structures, etc. Let us show this on a trivial example. We know that R offers the function sum within the base package, and this function calculates the arithmetic sum of the vector elements we send to it as an input parameter. But sum is actually the name of the variable that references the code that implements this function. If we want, we can very easily bind this function to some other variable by which we have effectively changed its name, or - better said - provided an alternative way of calling from a completely different environment. sum2 &lt;- sum sum2(1:10) # same as sum(1:10) This is easiest to understand in a way that the function is simply an “callable variable”, whereby the “call” refers to the use of a syntax that includes a reference to the function and input arguments framed in parentheses, which will return some value after execution in the R environment. The function can also be a return value from another function. funcCreator &lt;- function() { f &lt;- function(x) x + 1 f } newFunc &lt;- funcCreator() # we get the &quot;add one&quot; function newFunc(5) ## [1] 6 The function simply creates a new function and returns it to the calling program as it would have done with any other object. The return value is stored in the variable that is now “callable” - if we add brackets and parameters it will be executed in the way it is defined within the function that created it. Note that we could use the fact that the function returns the result of the last expression and define the function even shorter: # shorter definition funcCreator &lt;- function() { function(x) x + 1 } These functions are often referred to as “factories” or “generators” of functions, and in contrast to the above example, in practice, the function generator often receives some parameters that determine how the returned function will behave. Try to create a function factory that returns the multiplication functions using a pre-set parameter. Exercise 7.5 - function factory # create the `multiplicationFactory` function that creates # multiplication functions by the pre-set constant # use the above function to create the `times2` function # which doubles the received number # call the `times2` function with parameter 3 and print out the result # create the `multiplicationFactory` function that creates # multiplication functions by the pre-set constant multiplicationFactory &lt;- function(x) { function(a) a*x } # use the above function to create the `times2` function # which doubles the received number times2 &lt;- multiplicationFactory(2) # call the `times2` function with parameter 3 and print out the result times2(3) ## [1] 6 The multiplicationFactory function actually creates a “family” of functions that all provide the multiplication option with the selected number - i.e. parameter selected by the programmer itself. This way of managing functions may be initially confusing, but by using it in practice (which we will show in the next chapter), it is easy to notice the added flexibility and effectiveness of such an approach. If we define a function, and do not bind it to some variable, then we created the so-called “anonymous function”. # anonymous function function(x) x * x We can notice that each function is initially “anonymous”. If we return to the function definition syntax, we see that it is actually a combination of creating an anonymous function and binding it to a new variable. Of course, leaving the function anonymous as we did in the example above does not make much sense, just as it does not make sense to define a vector or list without creating a reference to that object - in that case the created object is not in any way usable because there are no links to it and will be quickly deleted by R within the “garbage collection” routine. We can ask ourselves - is there a scenario where the anonymous function is meaningful and useful? Explicit anonymous functions are used when a “disposable” function is needed, for example, as an argument for some other function. If the function we want to send as an argument is easy to define in a single line, and we do not plan to use it afterwards in the program, then it makes no sense to define it separately and assign it its own reference. An example of this will be seen in the apply family of functions. At the end of this section, we repeat the most important things - in R, the function is an object like any other, the only specificity is that it is an object that is “executable”, ie, which, using the function call syntax, does some work and returns some value. Even anonymous function can be executed (although only once, since we do not have a reference for future calls). # calling the anonymous function (function(x) x + 1)(2) ## [1] 3 7.2 The apply family Very often, knowledge of the basics of the language R is reflected by the skill of using the so-called apply family of functions, available in thebase package. These functions are specifically designed to perform repetitive tasks over various data structures, and as such they replace the program logic that would usually be realized in a through program loops. Additionally, these functions typically receive other functions as input arguments and, to a certain extent, encourage the functional programming paradigm. The family name comes from the fact that these functions commonly have a suffix “apply”. Some of the functions from this family are: apply lapply sapply vapply tapply,mapply, rapply … All of these functions work in a similar way - they receive a data set, a function that we want to apply to elements of that set, and optional additional parameters, and as the output give a set of function results, most often “packaged” in an appropriate format. The difference is mainly in the types of input and output arguments, as well as specific details about the implementation of the function itself and/or the way results are prepared. This family of functions is best learned through examples. We will begin with the “basic” function - apply. 7.2.1 The apply function The apply function is the only one that literally shares the name with the family of these functions. It is intended to work with matrices (actually with arrays, but since it is relatively rare to use data structures that have more than two dimensions, here we will focus only on matrices). The command syntax is as follows: result &lt;- apply( &lt;matrix&gt;, &lt;rows (1) or columns (2)&gt;, &lt;function_name&gt; ) Or, described in words, to implement the apply function, we: choose a matrix decide whether to “cut it” by rows or columns declare which function we want applied to each row (or column) Depending on how function works, as a result we get a matrix or (which is a more frequent case) a vector. Let’s try to use this function in a concrete example. Exercise 7.6 - the apply function m &lt;- matrix(1:9, nrow = 3, ncol = 3, byrow = TRUE) # print matrix `m` # use the `apply` function to calculate # and print the column sums of the `m` matrix # use the `apply` function to calculate # and print the multiplicaton of row elements # from the `m` matrix # print matrix `m` m cat(&quot;------------\\n&quot;) # use the `apply` function to calculate # and print the column sums of the `m` matrix apply(m, 2, sum) cat(&quot;------------\\n&quot;) # use the `apply` function to calculate # and print the multiplicaton of row elements # from the `m` matrix apply(m, 1, prod) ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 4 5 6 ## [3,] 7 8 9 ## ------------ ## [1] 12 15 18 ## ------------ ## [1] 6 120 504 If we want to perform a custom task to the rows/columns, we often use an anonymous function, for example: apply(m, 1, function(x) x[1]) # return the first element of each row Exercise 7.7 - the apply function and anonymous functions # for each row of `m` calculate the natural logarithm # of the sum of row elements # rounded to 2 decimals # use the `apply` function # for each row of `m` calculate the natural logarithm # of the sum of row elements # rounded to 2 decimals # use the `apply` function apply(m, 1, function(x) round(log(sum(x)),2)) ## [1] 1.79 2.71 3.18 Let’s repeat - apply (and related functions) implicitly disassembles the input data structure into elements. In the examples above, these elements - rows or columns - are actually numeric vectors. The argument x received by an anonymous function is exactly that vector, or, better said each of these vectors that are sent one by one. The results of the function are “remembered” and “packed” into the final result. Let’s try to program the last example without using the apply function. Exercise 7.8 - loop as the alternative to the apply function # for each row of `m` calculate the natural logarithm # of the sum of row elements # rounded to 2 decimals # use the for program loop # for each row of `m` calculate the natural logarithm # of the sum of row elements # rounded to 2 decimals # use the for program loop rez &lt;- numeric(nrow(m)) for (i in 1:nrow(m)) rez[i] &lt;- round(log(sum(m[i,])), 2) rez ## [1] 1.79 2.71 3.18 If we compare the syntax of the examples with and without using the apply function, we can see how much the syntax which uses apply s actually “cleaner”. If we use loops, we must explicitly specify the logic of passing through the structure, which draws attention away from the job description that we actually want to do. What if we want to send to the apply function a function which needs several parameters? For example, let’s say that instead of the upper function that extracts the first line element we want a function with two parameters - the first a vector (matrix row or column), and the second an integer that indicates the index of the element to extract. The answer is simple - just add additional parameters at the end of the function call. # apply function and input function with multiple parameters apply(m, 1, function(x,y) x[y], 2) # second element of each row Finally, it should be noted that for similar processing of data in the matrix form, we do not necessarily need to use apply - many popular operations such as adding row or column elements, calculating the average of the elements of the rows and columns, and the like. This has already been implemented through functions such as rowSums,colSums, rowMeans,colMeans and the like. They are easier to use, but specialized - for more flexibility, the most common option is apply. 7.2.2 The lapply, sapply and vapply functions The name of the lapply function comes from list apply - i.e. apply the function to the elements of lists. To put simply - it is a function that will receive the list and a function as the input arguments, apply the functions to each individual list element and return again a new list as a result. Exercise 7.9 - the lapply function l &lt;- list(a = 1:3, b = rep(c(T, F), 10), c = LETTERS) # use the `lapply` function to calculate the length (number of elements) # of each element of the `l` list # use the `lapply` function to calculate the length (number of elements) # of each element of the `l` list lapply(l, length) ## $a ## [1] 3 ## ## $b ## [1] 20 ## ## $c ## [1] 26 Just like with the apply function, for thelapply function, we often use anonymous functions as a parameter. The following task has no special practical use, but it will help us understand the functionality of the lapply function in combination with a slightly more complex anonymous function. Exercise 7.10 - the lapply function and anonymous functions # process the elements of the `l &#39;list as follows: # - Calculate the mean value if it is a numerical vector # - count the values of TRUE if it is a logical vector # - calculate the length of the vector for all other cases # use the `lapply` function and an anonymous function # do not forget that anonymous function can also use blocks! # process the elements of the `l &#39;list as follows: # - Calculate the mean value if it is a numerical vector # - count the values of TRUE if it is a logical vector # - calculate the length of the vector for all other cases # use the `lapply` function and an anonymous function # do not forget that anonymous function can also use blocks! lapply(l, function(x) { if (is.numeric(x)) { mean(x) } else if (is.logical(x)) { sum(x) } else length(x) }) ## $a ## [1] 2 ## ## $b ## [1] 10 ## ## $c ## [1] 26 The lapply function is essentially quite simple to use and is very popular due to this fact. But once we use it for a while, we can find it irritating that t it always returns the list as a result, although some other data structure would be more suitable for us - for example a vector, especially if the resulting list has just simple numbers as elements. For this reason, R offers the unlist function to simplify the list to a vector. Exercise 7.11 - the unlist function l &lt;- list(a = 1:10, b = 10:20, c = 100:200) # calculate the mean value of the elements of the `l` list # print the results as a numeric vector # use `lapply` and `unlist` # calculate the mean value of the elements of the `l` list # print the results as a numeric vector # use `lapply` and `unlist` unlist(lapply(l, mean)) ## a b c ## 5.5 15.0 150.0 The displayed combination of lapply andunlist will give us as a result a one-dimensional vector, which in many cases is what we want. But sometimes some other data structure would suit us - for example, a matrix. In this case we need an additional step in transforming a one-dimensional vector into a matrix using the matrix function, with the number of rows and columns being explicitly assigned. The question may arise - why is lapply not able to check the structure of the result it has created and determine the optimal data structure for formatting it (vector, matrix, or list)? That’s exactly the idea behind the sapply function, or simplified list apply. This function first performs lapply internally, and then simplifies the result to a vector, matrix or array, depending on the characteristics of the results obtained. Exercise 7.12 - the sapply function l &lt;- list(a = 1:10, b = 10:20, c = 100:200) # calculate the median of elements of the `l` list # and collect the results in a numeric vector # use the `sapply` function # extract the first and last element of each of the elements of the `l` list # use `sapply` and anonymous function # calculate the median of elements of the `l` list # and collect the results in a numeric vector # use the `sapply` function sapply(l, median) cat(&quot;------------\\n&quot;) # extract the first and last element of each of the elements of the `l` list # use `sapply` and anonymous function sapply(l, function(x) c(x[1], x[length(x)])) ## a b c ## 5.5 15.0 150.0 ## ------------ ## a b c ## [1,] 1 10 100 ## [2,] 10 20 200 Note that as a result in the last example, we received a matrix, but that R formed it “by columns”. If we wanted a matrix with elements arranged in rows, we can not use sapply for this directly, because the matrix is formed internally, without the possibility of forwarding thebyrow = T parameter. To obtain such a matrix, one option is already mentioned with the combination of lapply,unlist and matrix, or - more simply - transposing thesapply results using t function (from transpose). The sapply function is quite popular due to its simplicity and efficiency, so it is relatively often used in interactive analysis. On the other hand, the use of this function in program scripts is not recommended since its result is unpredictable in the general case - e.g. the script can expect a matrix in the continuation of the code, and the sapply function, due to the specificity of the input data, returns the vector, which can cause unforeseen results, which is not easy to spot later and diagnose where the error occurred. If we are developing our own programs in R and want to use sapply, then the better choice will be thevapply function, which works identically to sapply, but uses an additional parameter called FUN.VALUE with which we explicitly define what kind of “simplification” we expect. For example. numeric(3) means that the result of applying the function to each element of the original list should be a numeric vector of three elements. If the result for any list item differs from the expected one, the function will raise an error. Exercise 7.13 - the vapply function myList &lt;- list(numbers &lt;- c(1:5), names &lt;- c(&quot;Ivo&quot;, &quot;Pero&quot;, &quot;Ana&quot;), alphabet &lt;- LETTERS) # think which of the following calls will be successful, # and which will throw out the error # check the results on the console vapply(myList, length, FUN.VALUE = numeric(1)) vapply(myList, function(x) as.character(c(x[1], x[2])), FUN.VALUE = character(2)) vapply(myList, function(x) as.logical(x), FUN.VALUE = character(1)) Finally, let’s return briefly to lapply and consider one important fact - it is intended for use on lists, and data frames are actually lists. In other words, the lapply function is very handy for processing tabular datasets when we want to apply a particular function to the columns of the data frame. One of the more frequent operations performed in data analysis is the so-called. “standardization” of the numeric columns of the data frame - i.e. reducing all numerical values to “normal” distribution with the arithmetic mean of 0 and standard deviation of 1. This can be done by reducing each individual value by the arithmetic mean of the column (the mean function) and dividing with standard deviation of the column (function sd). This is a great way to demonstrate the use of lapply with data frames. Exercise 7.14 - the lapply function and data frames df &lt;- data.frame( a = 1:10, b = seq(100, 550, 50), c = LETTERS[1:10], d = rep(c(T,F), 5), e = -10:-1) # standardize numerical columns using `lapply` # do not change the remaining columns # round the normalized values to three decimal places # save the result in the df variable # print df # standardize numerical columns using `lapply` # do not change the remaining columns # round the normalized values to three decimal places # save the result in the df variable df &lt;- lapply(df, function(x) { if (is.numeric(x)) { round((x - mean(x))/sd(x), 3) } else x }) # print df df ## $a ## [1] -1.486 -1.156 -0.826 -0.495 -0.165 0.165 0.495 0.826 1.156 1.486 ## ## $b ## [1] -1.486 -1.156 -0.826 -0.495 -0.165 0.165 0.495 0.826 1.156 1.486 ## ## $c ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; &quot;F&quot; &quot;G&quot; &quot;H&quot; &quot;I&quot; &quot;J&quot; ## ## $d ## [1] TRUE FALSE TRUE FALSE TRUE FALSE TRUE FALSE TRUE FALSE ## ## $e ## [1] -1.486 -1.156 -0.826 -0.495 -0.165 0.165 0.495 0.826 1.156 1.486 We see that after using lapply we get a list and that if we want the result in the form of a data frame we need to add another step using theas.data.frame function. If we are looking for a simpler way that immediately gives the data frame as a result, there is one convenient “trick” that we will explain below. Let’s look at the solution of the previous problem, and put the following little change in the assignment of the result of the lapply function: df[] &lt;- lapply(...) In this way, R will not create a “new” variable named df, but rather thelapply result will be entered in the ’all rows and columns of the df data frame. This made it possible for us to get the result in the form of a data frame, which we actually wanted. For this very reason, in R scripts, we will often see a similar syntax (df [] &lt;- lapply ...). Try to modify the above example in the above manner and make sure that the result will be a data frame. Another commonly used trick in working with data frames is the following command: sapply(df, class) This command actually gives us the answer to the question - which types are the columns of the given data frame? Although there are other ways to get this information, this method is popular both because of the compactness of the results and the independence of additional packages. 7.2.3 Other functions from the apply family and the available alternatives In the previous chapters, we have probably listed the most popular members of the apply family. This family has more members, including some who do not have a suffix -apply: mapply, which works in parallel over multiple data structures rapply, which recursively applies functions within the structure tapply, which applies functions over sub-groups within a structure defined by factors Map, themapply version, which does not simplify the result by, thetapply version for data frames etc. The reason why these functions will not be explained in detail is twofold: firstly, as already mentioned, these functions are in practice applied much less often than the functions we have shown in the previous chapters. Secondly, with the increase in popularity of the language R, a large number of packages are oriented to improve the existing functions of the language R in the sense of easier and more efficient programming, especially when working with data frames. If we are looking for convenient alternative functions to those from the apply family, it’s recommended to look at some of the following packages plyr - an extremely popular package that, among other things, offers a number of functions very similar to apply functions, but derived in a way that they have a consistent signature and explicitly defined input and output formats that are easily read from the function name itself (in particular, the first letters ); so the llply function uses a list as both the input and the output, whilemdply needs a matrix as input and outputs a data frame purrr - a package that replaces the functions of theapply family with functions corresponding to similar functions from other programming languages; since the application of the same function to a number of elements of a data structure in functional languages is often called “mapping”, the set of functions of this package carries the prefix maps_, and the function names often correspond to the expected results (for examplemap2_lgl means that as a result we expect a logical vector , and the map2_df a data frame) dplyr - a relatively new package, which in a certain sense represents the successor of the plyr package but oriented almost exclusively toward data frames; the functions of this package are not so much oriented to replace the apply family functions as providing a specific platform for working with data frames in a manner similar to languages oriented precisely for this purpose, such as, for example, the SQL language In future lectures we will introduce the dplyr package precisely because this package greatly facilitates and accelerates the data analysis process and is extremely well accepted in the R community. Homework exercises R has a which function which converts a logical vector into a numeric one containing indexes where the original vector has a TRUE value (so c(T, F, F, F, F, T, F, T) becomes c(1, 6, 8)). Create a function which replicates this behaviour. Take the numerical vector x of length n. In statistics, the standardized moment of the k-th order is calculated like this: \\[\\frac{1}{n}\\sum_{i=1}^n{(x_i - \\bar{x})}^{k+1}\\] Create a factory of moment functions (moment(k)) for calculating the standardized central moment of the k-th order. Create the functions zero_moment(x) and first_moment(x) with parameter values k set to 0 and 1 accordingly. Test the functions on vector 1:1000. Compare the results given by the sd (standard deviation) function over the vector 1:1000 and root of the first moment you have calculated. Take the m matrix created by the following command: m &lt;- rbind(1:5, seq(2, 10, 2), rep(3, 5), 3:7, seq(100, 500, 100)) With the apply function and the new anonymous function, create a vector that will contain the first even element of each row, or zero if the corresponding row does not have even elements. The following commands will create a list of 100 elements where each element will be a numeric vector of a random length of 1 to 10. set.seed(1234) myList &lt;- replicate(100, sample(1:10, sample(1:10, 1))) With the help of lapply / sapply (and additional commands if necessary), create: the numerical vector v with the lengths of the list elements list l with normalized numerical vectors of the original list numerical vector ind4 with indexes of all list elements containing number 4 the df5 data frame containing columns which have all the elements of the length of 5 from the original list Programirajmo u R-u by Damir Pintar is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.Based on a work at https://ratnip.github.io/FER_OPJR/ "],["objects.html", "8 Object oriented systems in R 8.1 Object-oriented systems in R 8.2 Overview of the S3 object model 8.3 Generic functions 8.4 Adding generic functions to an object 8.5 Short overview of S4 objects Homework exercises", " 8 Object oriented systems in R 8.1 Object-oriented systems in R R is designed as an object-oriented language, together with the most commonly listed mechanisms that the object-oriented paradigm dictates: encapsulation (enveloping various attributes into a common entity), polymorphism (different classes of objects leveraging the same interface) and inheritance (new objects can be created from the existing ones by extending them with additional elements). R has inherited its initial object modelling system from the S language, which resulted in these objects being known as “S3 objects” (S3 being the language version from which they were originally taken). This object model, as will be showcased very soon, is actually rather simple and unconventional, yet fairly suitable for using in R itself, it being primarily a domain-oriented language focused on data science-related tasks. However, with the continual influx of professional programmers into the R community, the pressure increased to bring support for “proper” objects that will be more similar to the way they work in the other programming languages, mostly in order to bring better robustness in design and management of objects. At the time of this writing, we formally have four types of objects in the programming language R : “base” classes - denoting basic R elements (functions, vectors, data frames) S3 objects - OOP system inherited from S language (version 3) S4 objects - a more formal and rigorous OOP system approaching standard object-oriented mechanisms from other languages RC objects (reference classes) - the most recent way of creating objects that replicates the “classical” object-oriented principles based on the exchange of messages; a subsystem of RC is called R6, offered by the package of the same name The existence of roughly three separate models of defining objects (we ignore the basic object model since we are interested in those that support the OOP principle) can seem disheartening - is it necessary to learn all three models? How to distinguish them? Which one to choose? However, despite the fact that the story about the object nature of R during its development is (unnecessarily) complicated, the good news is that for most needs, it’s quite enough to learn how the S3 model works, which is also the simplest. A large number of popular R packages use only S3 classes and it is possible to work in language R for a very long time without meeting the need for learning S4 or RC models. For this reason, we will mostly focus on the S3 objects, with a very brief overview of S4 (readers who want more information on other models, especially the RC one which is outside the scope of this coursebook, are strongly advised to check the book called Advanced R, by the author Hadley Wickham, which has multiple chapters devoted to object oriented programming in R). 8.2 Overview of the S3 object model As already mentioned, S3 objects are actually inherited from the S programming language and represent a relatively primitive implementation of the concept of “object”, as far as expectations go regarding standard mechanism of object creation management. This is most easily communicated with the following statement: An S3 object is merely a list which has an additional class attribute. This means that an S3 object can be created in the following way: Example 8.1 - creating a new S3 object # we are creating a new object of a class `Person` pero &lt;- list(id = &quot;12345678&quot;, surname = &quot;Peric&quot;, weight = 78) class(pero) &lt;- &quot;Person&quot; Notice that we do not have a formally defined “class template” as is the established practice in other programming languages, it is only implied by the object’s structure. In practice however we would probably not expect from our users to construct objects “manually”, but rather to use a special constructor function whose parameters will ultimately define the object’s internal structure. The function would internally use the same code as above, possibly including some additional checks whether the parameters are defined correctly. Let us create such a constructor function. For simplicity’s sake, let’s forgo for now the usual insistence on vectorization and assume users will always create a single “Person” object at a time (even though realistically you should aim for making functions which allow for creating of multiple objects at once, if possible and suitable for their planned use). Exercise 8.1 - constructor function # create a function called `Person` # input parameters: id, surname, weight # returns: object of class &quot;Person&quot; # before creating the object function should check that: # - id is a character vector, a string of 8 characters # - surname is a character vector # - weight is a numeric vector, larger then 0 # create `john`, a `Person` with the following characteristics: # id: 13571313, surname: Watson, weight: 76 # print `john` # create a function called `Person` # input parameters: id, surname, weight # returns: object of class &quot;Person&quot; # function should check that: # - id is a character vector, each character string 8 characters (`nchar` function!) # - surname is a character vector # - weight is a numeric vector, larger then 0 Person &lt;- function(id, surname, weight) { stopifnot(is.character(id) &amp;&amp; nchar(id) == 8) stopifnot(is.character(surname)) stopifnot(is.numeric(weight) &amp;&amp; weight &gt; 0) p &lt;- list(id = id, surname = surname, weight = weight) class(p) &lt;- &quot;Person&quot; p } # create `john`, a `Person` with the following characertistics: # id: 13571313, surname: Watson, weight: 76 # print `john` john &lt;- Person(&quot;13571313&quot;, &quot;Watson&quot;, 76) john ## $id ## [1] &quot;13571313&quot; ## ## $surname ## [1] &quot;Watson&quot; ## ## $weight ## [1] 76 ## ## attr(,&quot;class&quot;) ## [1] &quot;Person&quot; As we can see, the obvious advantage of making constructor functions for our S3 objects is additional robustness in the form of object’s structure being enforced by the way the constructor function is called, as well as the capabilities of embedding additional checks and requirements inside the constructor code. Let’s now talk about inheritance, i.e. a mechanism which allows for creating new objects (or classes) out of the existing ones, inheriting their current features while adding new (or modifying the inherited) ones. The S3 OOP system enables inheritance, but again in a very informal and relatively trivial way. Similar to how we created an object of a certain class by simply taking a list and declaring it is a member of a certain class through the class attribute, we can also use this very same attribute to list the “parents” of the class, i.e. classes that this object is inheriting features from. The names of parent classes should be placed in the same character vector as the class name, so they follow immediately after, sorted by ‘importance’. For example, the following code creates a new mate object of class Employee which inherits the class Person: Example 8.2 - inheriting an S3 object mate &lt;- list(id = &quot;12345678&quot;, lastname = &quot;Peric&quot;, weight = 78, yearEmpl = 2001) class(mate) &lt;- c (&quot;Employee&quot;, &quot;Person&quot;) Again, a better solution would of course be creating a new constructor function which would take care to properly inherit the parent structure, and quite possibly integrate the constructor function of the parent object themselves in the construction process. 8.3 Generic functions Looking at the above way of designing objects, we can notice that we completely avoided discussion of an important feature of any OOP system - the methods, i.e. functions that are being encapsulated inside an object. And here we come to one of the more striking differences between the S3 object model and the “standard” OOP systems we might be familiar with from the other programming languages - in the S3 object model the methods are defined outside of the objects themselves, in the form of so-called generic functions. This should not necessarily be so unusual as it initially seems. If we go back to the original description of polymorphism, we can see the basic idea should be that the user is able to ask for executing similar functions (eg “print”, “draw”, “summary description”) over objects of different types. The “generic” expected functionality of a chosen function should be the same, but the specifics would differ depending on the object itself - hence the name generic function. For example, we expect that the print function will always results in some kind of printout on screen, but how this printout ultimately looks will depend on the specifics of the object we are printing. This way of designing an object can seem rather unconventional, but the fact stands that the code that uses generic functions instead of encapsulated methods tends to look far more intuitive, especially for users who do not have an extensive background in programming. Specifically, let’s compare a hypothetical command: start(car, speed = 20) with the command: car.start(speed = 20) By reading the first command, the car is perceived as an “object” (in grammatical terms), that is, an entity we ask for something to be performed on. The second command sets the car as a “subject”, which is a common practice of the object-oriented languages, but is not in line with the general understanding of how we perceive performing tasks, especially in data analysis - we manipulate and transform datasets and we draw plots, as opposed to asking data to manipulate themselves or a plot to get itself drawn. So to sum up, R is designed in such a fashion that enforces thinking about what we want to do instead of asking ourselves where the function we want to call is. If we want to print an object, it is logical to just simply forward it to the print function, and if we want to get a brief summary about it, we try calling the summary function. The big question is of course - how can one single function “know” what to do with an object? Does it need to have the implementation code for every single class it could conceivably be called on? The answer is actually rather simple - the generic function is just an “interface” to the function we “actually” want to call, and the programmer of the object (or class) is responsible for creating a separate code with the implementation logic. The trick is merely in taking care to follow the naming convention - if the generic function is called genFun, and the name of the object class is className, the function storing the implementation code needs to be called genFun.className, and should be available in the search path when the generic function is called. If no such function exists, than the function genFun.default will be called instead. We can see the proof of this in the next exercise. Exercise 8.2 - generic functions # print the source code `summary` function (just use the function name!) # print the source code of a function actually being called when you call # the `summary` function of the `factor` class object # print the `summary` function (only the function name!) summary # print the source code of a function actually being called when you call # the `summary` function of the `factor` class object summary.factor ## function (object, ...) ## UseMethod(&quot;summary&quot;) ## &lt;bytecode: 0x00000281ab2c43e0&gt; ## &lt;environment: namespace:base&gt; ## function (object, maxsum = 100L, ...) ## { ## nas &lt;- is.na(object) ## ll &lt;- levels(object) ## if (ana &lt;- any(nas)) ## maxsum &lt;- maxsum - 1L ## tbl &lt;- table(object) ## tt &lt;- c(tbl) ## names(tt) &lt;- dimnames(tbl)[[1L]] ## if (length(ll) &gt; maxsum) { ## drop &lt;- maxsum:length(ll) ## o &lt;- sort.list(tt, decreasing = TRUE) ## tt &lt;- c(tt[o[-drop]], `(Other)` = sum(tt[o[drop]])) ## } ## if (ana) ## c(tt, `NA&#39;s` = sum(nas)) ## else tt ## } ## &lt;bytecode: 0x00000281ac3c3838&gt; ## &lt;environment: namespace:base&gt; 8.4 Adding generic functions to an object The properties of the generic function are as follows: the function has an intuitive, clearly defined purpose expected mode of operation is similar for multiple object types (e.g. drawing will always result in an image of sorts) each type of object requires its own implementation depending on the characteristics of the object (e.g. the way the method of drawing the circle differs from drawing a square) The method of implementing generic functions (for S3 objects!) is actually extremely simple, which is probably the reason for their wide acceptance and great popularity in the R community. The process is reduced to three simple steps: choose the name of a generic function and declare that it is a generic function with the help of a function called UseMethod alternatively, ignore this step and choose one of the existing generic functions (often a much better choice!) create an object and declare its class implement the function called &lt;gen_function_name&gt;.&lt;class_name&gt; (optional) if you created a completely new generic function, consider implementing &lt;gen_function_name&gt;.default function and as many other implementation functions as you want, if you think the function should work on other types of objects, too And that’s all! R does not require any additional steps, the above is quite sufficient for R to recognize the new generic function and apply it to all objects for whose class this generic function is implemented in the form gen_function_name.class_name (or gen_function_name.default for all classes for which there is no special implementation). In the next exercise, let’s try to implement the generic infoAbout method for the Person class. Exercise 8.3 - new generic function peter &lt;- Person(id = &quot;12345678&quot;, surname = &quot;Parker&quot;, weight = 78) # create a new generic `infoAbout` function using the `UseMethod` function infoAbout &lt;- function(x) UseMethod(&quot;infoAbout&quot;) # implement a `infoAbout.Person` function which takes a `Person` # and writes the following on screen # ID: &lt;id&gt;, surname: &lt;surname&gt;, weight: &lt;weight&gt; # use the `paste` function to prepare the printout # and `cat` to put it on screen # implement a `infoAbout.default` function # which simply fowards the input parameter to the `cat` function # call `infoAbout` with `peter` as parameter # call `infoAbout` with `1:5` as parameter # implement a `infoAbout.Person` function which takes a `Person` # and writes the following on screen # ID: &lt;id&gt;, surname: &lt;surname&gt;, weight: &lt;weight&gt; # use the `paste` function to prepare the printout # and `cat` to put it on screen infoAbout.Person &lt;- function(p) { rez &lt;- paste0(&quot;ID:&quot;, p$id, &quot;, surname:&quot;, p$surname, &quot;, weight:&quot;, p$weight, &quot;\\n&quot;) cat(rez) } # implement a `infoAbout.default` function # which simply fowards the input parameter to the `cat` function infoAbout.default &lt;- function(x) cat(x) # call `infoAbout` with `peter` as parameter infoAbout(peter) # call `infoAbout` with `1:5` as parameter infoAbout(1:5) ## ID:12345678, surname:Parker, weight:78 ## 1 2 3 4 5 Of course, it doesn’t really make sense to have our own function for printing out stuff on screen when there are already perfectly good generic function for that purpose such as print or cat. With that in mind, let’s augment the print function so it works with our Person objects. Since we have already created our infoAbout function, and we are already armed with the knowledge that functions are first-class objects, it should be trivial to allow for Person objects to be nicely printed on screen with print. Exercise 8.4 - augmenting the existing generic functions # make sure `print` is a generic function # (print out its source code by referencing its name) # augment the `print` function so it allows pretty printing # of the `Person` class # (you may use the already created `infoAbout.Person` function) # call `print` with `peter` as parameter (or try the autoprint!) # make sure `print` is a generic function # (print out its source code by referencing its name) print # augmnet the `print` function so it allows pretty printing # of the `Person` class # (you may use the already created `infoAbout.Person` class) print.Person &lt;- infoAbout.Person # call `print` with `peter` as parameter (or try the autoprint!) print(peter) ## function (x, ...) ## UseMethod(&quot;print&quot;) ## &lt;bytecode: 0x00000281a6c9f940&gt; ## &lt;environment: namespace:base&gt; ## ID:12345678, surname:Parker, weight:78 ***. Finally, we demonstrate the ability of R to list all the currently known implementations of a generic method. To do this we simply use the methods function to which we pass the name of the method concerned. With the same function we can also check which generic functions implementations exist for a particular class. For this we use the class parameter to which we are passing the class name for which we are interested in finding generic functions implemented for it. Exercise 8.5 - methods function # list all implementations of the `summary` function # check with generic function implementations exist for the `factor` class # list all implementations of the `summary` function #methods(summary) # try on console! cat(&quot;-----------------------\\n&quot;) # check with generic function implementations exist for the `factor` class methods(class = &quot;factor&quot;) ## ----------------------- ## [1] / [ [[ [[&lt;- [&lt;- ## [6] + all.equal as.character as.data.frame as.Date ## [11] as.duration as.interval as.list as.logical as.period ## [16] as.POSIXlt as.vector as_date as_datetime as_factor ## [21] c coerce Compare corresp droplevels ## [26] format initialize is.na&lt;- length&lt;- levels&lt;- ## [31] Math Ops plot print recode ## [36] relevel relist rep scale_type show ## [41] slotsFromS3 summary Summary type_sum xtfrm ## see &#39;?methods&#39; for accessing help and source code 8.4.1 Conclusion on S3 objects In short, the conclusions about S3 objects can be as follows: S3 objects function in in a simple, informal way - they are simply lists with the arbitrary value of class attributes the S3 object methods are not encapsulated within the objects, but are designed “out of” objects in the form of generic functions much of this is left to the responsibility of the programmer who should enforce the object structure through *constructor functions and the way to handle objects through generic function implementations** S3 objects are not suitable for complex object models due to heavy model maintenance and large potential of errors 8.5 Short overview of S4 objects We will not be dealing with S4 objects in detail, but will provide a very brief overview how they look and what are some of the most significant changes from the S3 model. S4 objects offer a slight “upgrade” on S3 objects in the sense that they dictate more strictness and formality when defining and using classes, while still retaining most of the simplicity of the S3 model. The most notable (and arguably welcome) change is allowing for a formal definition of a class template. An S4 class has three main properties: name, which identifies it representation, which describes its attributes (called “slots”) (optionally) a vector of parent classes (that it “contains”) The S4 equivalent of our S3 Person class would therefore look like this: Example 8.3 - creating a new S4 class # template definition setClass(&quot;Person&quot;, representation(id = &quot;character&quot;, surname = &quot;character&quot;, weight = &quot;numeric&quot;)) # class instantiation pero &lt;- new(&quot;Person&quot;, id = &quot;12345678&quot;, surname = &quot;peric&quot;, weight = 76) Another difference is that instead of $ you use the @ operator to access the attributes (slots) of a class. Also, the function getSlots will return all the slots of the class in question. Example 8.4 - accessing S4 class slots # list class `Person` slots getSlots(&quot;Person&quot;) # retrieve slot values from `pero` instance paste0(pero@id, &quot;: &quot;, pero@surname) ## id surname weight ## &quot;character&quot; &quot;character&quot; &quot;numeric&quot; ## [1] &quot;12345678: peric&quot; S4 also leverages generic functions, but with certain differences when it comes to the syntax of creating them. We will not delve into specifics and will just briefly show one way of assigning existing generics to a new S4 object through the usage of a setMethod function. Example 8.5 - S4 objects and generics setMethod(&quot;print&quot;, signature(x = &quot;Person&quot;), function(x) { rez &lt;- paste0(&quot;ID:&quot;, x@id, &quot;, surname:&quot;, x@surname, &quot;, weight:&quot;, x@weight, &quot;\\n&quot;) cat(rez) }) print(pero) ## ID:12345678, surname:peric, weight:76 And this is where we finish our overview of R’s OOP systems. As stated, the S3 objects are still the most prevalent, and S4 are worth knowing if you come upon them in certain packages (even though most of the time it’s enough to remember to use the @ operator instead of $ to extract their attributes). As for other types of objects (including the relatively popular RC or R6 classes), they are outside the scope of this course and will be left as optional concepts to discover on your own. In general, R is probably not the best choice for implementing software solutions that heavily rely on intricate object-oriented architectures - but regardless of that, there are packages and models that allow this, with ever rising support and new features, so there is always an option of going down this road if the need arises. Homework exercises The following exercises all assume usage of S3 classes. Create a class object Block with the attributes height, width and depth equal to10, 20 and 30 respectively. Implement a constructor for the class Employee which inherits the Person class defined by the following constructor and print implemenation: Person &lt;- function(id, surname, weight) { p &lt;- list(id = id, surname = surname, weight = weight) class(p) &lt;- &quot;Person&quot; p } print.Person &lt;- function(p) { rez &lt;- paste(&quot;ID:&quot;, p$id, &quot;, surname:&quot;, p$surname, &quot;, weight:&quot;, p$weight, &quot;\\n&quot;) cat(rez) } Employee has all the attributes of the Person class as well as the superior attribute which represents a reference to a employee who is his/her superior (if such exists, otherwise it should be NA). Create two objects of the Employee class (one superior to another) and print them with the print function. Then implement your own version of the generic function print for the Employee class that prints employee data and his/her superior employee data (if it exists, otherwise it prints a message that there is no superior employee). Reprint both employees with the print function. Programirajmo u R-u by Damir Pintar is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.Based on a work at https://ratnip.github.io/FER_OPJR/ "],["pipe.html", "9 Pipeline operator and tidy data 9.1 Pipeline operator 9.2 Tidy data Exercise Tasks", " 9 Pipeline operator and tidy data 9.1 Pipeline operator Let’s look at the following example: imagine that in R we want to create 100 random real variables from the range of [0,100], round them to two decimals, select a sample of 10 variables from this set, calculate the arithmetic mean of the sample and print it on the screen. One possible solution could be: set.seed(1234) # (for repeatability) res &lt;- runif(100, 0, 100) # 100 random variables from uniform distribution from 0 to 100 res &lt;- round(res, 2) res &lt;- sample(res, 10) res &lt;- mean(res) res ## [1] 46.651 This kind of code has a lot of unnecessary repetition - in every line we use the res variable as well as the assignment operator res variable so we can store the in-between results. Alternatively, we could do everything in one row: Exercise 9.1 - Nested functions set.seed(1234) # repeat the above example, but with only one line of code mean(sample(round(runif(100, 0, 100), 2), 10)) ## [1] 46.651 Here we see a typical example of a “code sandwich” which is not only often seen in R, but also appears in most programming languages. When we use the result of one function as an input to another, we have to “nest” it in the subsequent function call ending up with an error-prone code which is equally difficult to both write and read. A natural way of “solving” a series of instructions from the previous example would be to resolve them sequentially, i.e. from “left to right”; when we finish one task, the result becomes the input for the following task and so on until the process is complete. It would be benefitial if we apply this approach through programming code. This was precisely the motivation for the development of the so-called pipeline operator, provided by the package magrittr (Bache and Wickham 2014). The weird name package is actually inspired by the name of abstract painter Rene Magritte, more specifically his famous painting La trahison des images depicting a pipe under which are the words Ceci n’est pas une pipe. In the same way, the magrittr package delivers a pipeline or pipe operator %&gt;%which is “not really a pipe”. Whatever you may think about this play on words or the painting itself which inspired this package, what is undeniable is the fact that the pipeline operator makes the code much more readable and as such has quickly become a strong favorite in the R community, especially when programming heavily relies on chaining function calls. How does the %&gt;% operator work? It’s rather simple - we place it between function calls to designate that the output from the function on the left should be the input for the function on the right. The place where the result from the previous function should go is denoted by the . symbol. We can do this as many times as we want, that is, depending on how many functions calls we “chain”. h(g(f(x), y), z, w) # code without the %&gt;% operator f(x) %&gt;% g(., y) %&gt;% h(., z, w) # code with the %&gt;% operator If the result of the previous function the first argument of the next function, then the . symbol (or in effect the whole argument) can be thrown out, so the syntax is even shorter: f(x) %&gt;% g(y) %&gt;% h(z, w) # code without dots Notice that these function calls are actually formally incorrect because they have an “invisible” first argument. Nevertheless, many R programmers prefer this syntax because it requires less typing and is somewhat more transparent, while the mentioned irregularity does not really matter in practice as long as the developer is aware of the existence of an “invisible” argument. Now let’s try to reformat our first example with the help of the `%&gt;% ’operator. Exercise 9.2 - operator %&gt;% set.seed(1234) # solve the first example again using the %&gt;% operator set.seed(1234) runif(100, 0, 100) %&gt;% round(2) %&gt;% sample(10) %&gt;% mean() %&gt;% print() ## [1] 46.651 Note that by reading the above program code, we very easily interpret the meaning of that line of program code, especially when compared to the same command written in the form of a “sandwich”. We can store the end result of our “chain” of functions in the usual way: sum1to10 &lt;- 1:10 %&gt;% sum # result is stored in variable `sum1to10` but it may be more visually consistent to use the “inverted” assignment operator: -&gt;. 1:10 %&gt;% sum -&gt; sum1to10 # works the same as the example above Also note that in situations where the result of the previous function is the only parameter of the following function, we can completely leave out the parentheses (so in the examples above, sum,sum()orsum(.) would all work equally). Now let’s try to combine the %&gt;% operator and lapply with the example already seen in the section on functions in theapply family. Exercise 9.3 - lapply function and %&gt;% operator l &lt;- list(a = 1:10, b = 10:20, c = 100:200) # create a matrix which contains the first and last element of each list element # these elements must be in their own rows # use functions lapply, unlist and matrix as well as the %&gt;% operator # save the result in the `res` variable # print &#39;res&#39; l &lt;- list(a = 1:10, b = 10:20, c = 100:200) l %&gt;% lapply(function(x) c(x [1], x [length(x)])) %&gt;% unlist %&gt;% matrix(ncol = 2, byrow = T) -&gt; res res ## [,1] [,2] ## [1,] 1 10 ## [2,] 10 20 ## [3,] 100 200 The pipeline operator is very convenient in conjunction with “classic” functions, but we may encounter a problem when we want to combine it with other operators. The cause of the problem is the syntax - the pipeline operator achieves its efficiency by imposing a new, “sequential” syntax, which is not compatible with the syntax imposed by other operators, such as +, %% or [. If it is really important for us to have a “continuous” function call chain in our code that will contain not only functions but also other operators, then one solution is to use operators as “ordinary” functions. Namely, each operator is actually a function that shares a name with the operator (using the backtick quotation mark which allows the use of symbols as variable names), so the following pairs of expressions are actually equivalent: Example 9.1 - operators as functions # each pair of instructions is equivalent 2 + 3 `+`(2, 3) 1:5 `:`(1, 5) x &lt;- c(1, 2, 3) `&lt;-`(&quot;x&quot;, c(1,2,3)) x[1] `[`(x, 1) ## [1] 5 ## [1] 5 ## [1] 1 2 3 4 5 ## [1] 1 2 3 4 5 ## [1] 1 ## [1] 1 Let’s try to use this principle in the next exercise. Exercise 9.4 - combining pipe operator with other operators set.seed(1234) # &quot;clean up &quot; the following command with the help of the pipeline operator matrix(table(sample(round(sqrt(sample(1:10000, 10000, replace = T))), 100))[1:9], 3, 3) ## [,1] [,2] [,3] ## [1,] 2 2 2 ## [2,] 1 1 1 ## [3,] 2 2 2 set.seed(1234) # &quot;clean up &quot; the following command with the help of the pipeline operator 1:10000 %&gt;% sample(10000, replace = T) %&gt;% sqrt %&gt;% round %&gt;% sample(100) %&gt;% table %&gt;% `[`(1:9) %&gt;% matrix(3, 3) ## [,1] [,2] [,3] ## [1,] 2 2 2 ## [2,] 1 1 1 ## [3,] 2 2 2 The %&gt;% operator is particularly well suited when dealing with data frames, especially in scenarios when we have a defined data transformation procedure (e.g. filtering some rows, then selecting columns, then grouping the data according to a categorical variable etc.). With the help of this operator, the code itself acts as a readily interpretable representation of our data transformation process which we can easily customize and extend later. Future examples and exercises will often extensively rely on this operator, so we recommend that you master it well before proceeding with the lessons that follow. 9.2 Tidy data It is often stated in various literature that in data analysis, data preparation is often the most time consuming segment of the process. The book “Exploratory Data Mining and Data Cleaning” mentions that preparation often requires from 50% to 80% of the total time devoted to analysis. Also, as Hadley Wickham states in his article “Tidy Data”, data preparation is often not just the first step of the analysis, but rather a process that gets repeated as new knowledge is discovered or new data is collected. Hadley Wickham also introduced the term “tidy data” to refer to the organization of a data in such a way as to facilitate its further processing and analysis. In practice, datasets we get are often not originally intended for the purposes of analysis and as such are not organized in a way that would allow them to be easily used in the analytical process. “Tidy data” is actually a set of principles which may guides us how to “rearrange” data so that its structure matches the standard, expected metadata. Tidy data principles have similarities with the relational data model, but are defined in a way that is more appropriate for statisticians and developers. These principles can be summarized as follows: the data is organized into a table each line represents an observation each column represents a property or variable of that observation Since this may sound too trivial, let’s take a look at what properties Hadley lists as typical of “messy” data: column names are not variable names but rather their values multiple different variables are stored in the same column variables are saved in rows multiple types of different observations are stored in the same table one type of observation is stored in multiple tables Below, we will give some examples of tables that do not fully conform to the definition of tidy data, and show how to easily “tidy them up”. For this, we will leverage functions provided by the tidyr package. 9.2.1 The pivot_longer andpivot_wider functions The workbook which corresponds to this leeson should have a file called students.csv. Let’s load it into our work environment. Since the file is stored using UTF-8 encoding (since it contains Croatian letters), you can also add a fileEncoding =\"UTF-8\" parameter to the read.csv command to get the special characters correctly printed. Exercise 9.5 - students data set # load data from `students.csv` file into `students` variable # familiarize yourself with the data using standard functions for this purpose # (names, sapply/class, str, head, summary ...) # in the following examples for this process, we will use the phrase &quot;briefly explore the data frame&quot; # as a shortcut for the above process students &lt;- read.csv(&quot;students.csv&quot;, fileEncoding =&quot;UTF-8&quot;, stringsAsFactors = F) str(students) head(students) ## &#39;data.frame&#39;: 27 obs. of 10 variables: ## $ JMBAG : int 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 ... ## $ Surname : chr &quot;Anić&quot; &quot;Babić&quot; &quot;Crnoja&quot; &quot;Črnjac&quot; ... ## $ Name : chr &quot;Iva&quot; &quot;Josip&quot; &quot;Petra&quot; &quot;Lucija&quot; ... ## $ Math.1 : chr &quot;2&quot; &quot;5&quot; &quot;4&quot; &quot;2&quot; ... ## $ Physics.1 : chr &quot;2&quot; &quot;3&quot; &quot;3&quot; &quot;5&quot; ... ## $ Programming : chr &quot;NULL&quot; &quot;4&quot; &quot;4&quot; &quot;2&quot; ... ## $ Electronics : chr &quot;NULL&quot; &quot;3&quot; &quot;2&quot; &quot;2&quot; ... ## $ Digital.Logic: chr &quot;4&quot; &quot;NULL&quot; &quot;3&quot; &quot;3&quot; ... ## $ Math.2 : chr &quot;2&quot; &quot;5&quot; &quot;4&quot; &quot;3&quot; ... ## $ Algorithms.1 : chr &quot;2&quot; &quot;5&quot; &quot;3&quot; &quot;4&quot; ... ## JMBAG Surname Name Math.1 Physics.1 Programming Electronics Digital.Logic ## 1 1341 Anić Iva 2 2 NULL NULL 4 ## 2 1342 Babić Josip 5 3 4 3 NULL ## 3 1343 Crnoja Petra 4 3 4 2 3 ## 4 1344 Črnjac Lucija 2 5 2 2 3 ## 5 1345 Dizla Stipe NULL 4 3 5 2 ## 6 1346 Ermić Igor NULL 3 NULL 5 5 ## Math.2 Algorithms.1 ## 1 2 2 ## 2 5 5 ## 3 4 3 ## 4 3 4 ## 5 2 2 ## 6 5 5 Note that this dataset has a lot of missing values that are written as NULL. Because R does not recognize this as a missing value, it loaded the data as character strings (or as factors if we had the stringsAsFactors parameter set to TRUE). Because the columns that relate to the ratings are obviously numeric, we can easily convert them to such using the as.numeric () (or as.numeric(as.character()) command if they are factors!). But there is a simpler way - if we know how the missing value is represented in the dataset, we can directly embed it in the read.csv command using the na.strings parameter. Exercise 9.6 - using the na.strings parameter # reload the data from the `students.csv` file into the `students` variable # add the `na.strings` parameter to the `read.csv` command with a character string representing NA # briefly explore the `students` data frame students &lt;- read.csv (&quot;students.csv&quot;, fileEncoding = &quot;UTF-8&quot;, stringsAsFactors = F, na.strings = &quot;NULL&quot;) str(students) head(students) ## &#39;data.frame&#39;: 27 obs. of 10 variables: ## $ JMBAG : int 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 ... ## $ Surname : chr &quot;Anić&quot; &quot;Babić&quot; &quot;Crnoja&quot; &quot;Črnjac&quot; ... ## $ Name : chr &quot;Iva&quot; &quot;Josip&quot; &quot;Petra&quot; &quot;Lucija&quot; ... ## $ Math.1 : int 2 5 4 2 NA NA NA 3 3 4 ... ## $ Physics.1 : int 2 3 3 5 4 3 3 4 2 2 ... ## $ Programming : int NA 4 4 2 3 NA 3 3 3 4 ... ## $ Electronics : int NA 3 2 2 5 5 3 4 2 2 ... ## $ Digital.Logic: int 4 NA 3 3 2 5 2 4 3 5 ... ## $ Math.2 : int 2 5 4 3 2 5 2 5 NA 4 ... ## $ Algorithms.1 : int 2 5 3 4 2 5 5 4 3 2 ... ## JMBAG Surname Name Math.1 Physics.1 Programming Electronics Digital.Logic ## 1 1341 Anić Iva 2 2 NA NA 4 ## 2 1342 Babić Josip 5 3 4 3 NA ## 3 1343 Crnoja Petra 4 3 4 2 3 ## 4 1344 Črnjac Lucija 2 5 2 2 3 ## 5 1345 Dizla Stipe NA 4 3 5 2 ## 6 1346 Ermić Igor NA 3 NA 5 5 ## Math.2 Algorithms.1 ## 1 2 2 ## 2 5 5 ## 3 4 3 ## 4 3 4 ## 5 2 2 ## 6 5 5 We see that the columns are now of the appropriate type - but still the data frame does not fully fit the definition of “tidy data”. The names of the columns are actually the categories of the variable course and the ‘observation’ in this table is represented by the student, even though a more logical granularity would be to have each grade as a specific observation. Now, adding a new grade from a course is only possible by adding a new column, making sure to add grades for all students, which would inevitably mean immediately entering a lot of NA values for all student/course combinations where no grade yet exists (and maybe never will, if the student never takes that course at all). Let’s try to reorganize the table so each row represents “a grade student received in a particular course”. Consider what steps should be taken to create such a table. We need to: create a categorical variable Course which would have the names of all the courses (currently spread over column names) create all student/course combinations that make sense (i.e. have a grade assigned to them) fill in the combinations with the corresponding grade value This process is not impossible, but it does require a lot of jumping through hoops to redesign the data frame. To simplify this process, we can use the pivot_longer function from thetidyr package, which performs the exact procedure we described above: it “pivots” columns into a single variable and then populates the values of that variable with the existing column/row combinations, converting a table into a “longer” shape. The function signature looks like this (not all parameters are shown): pivot_longer(data, cols, names_to, values_to, values_drop_na) You can get a detailed description of the function as well as the parameters not shown above by calling ?pilot_longer, but here we will just briefly explain some of the parameters: data represents our data frame cols represents the set of columns we “pivot”; we can specify column names separated by commas (quotes are also not required), use the syntax first_column:last_column, or even just name the columns we do NOT want to gather by prefacing them with the - sign names_to represents the name of the new column - the categorical variable we want to create (in our case \"Course\"); value_to represents the name of the new column (variable) which will hold values with values (in our case Grade\") values_drop_na describes whether we want to omit observations with NA values Let’s try out this function with our untidy data frame. Exercise 9.7 - pivot_longer function # create a `grades` data frame by using the `pivot_longer` function on the `students` data frame # new columns should be called &quot;Course&quot; and &quot;Grade&quot; # briefly explore the `grades` data frame # create a `grades` data frame by using the `pivot_longer` function on the `students` data frame # new columns should be called &quot;Course&quot; and &quot;Grade&quot; #library(tidyr) # if necessary grades &lt;- pivot_longer(students, cols = Math.1:Algorithms.1, names_to = &quot;Course&quot;, values_to = &quot;Grade&quot;, values_drop_na = T) str(grades) head(grades) ## tibble [168 × 5] (S3: tbl_df/tbl/data.frame) ## $ JMBAG : int [1:168] 1341 1341 1341 1341 1341 1342 1342 1342 1342 1342 ... ## $ Surname: chr [1:168] &quot;Anić&quot; &quot;Anić&quot; &quot;Anić&quot; &quot;Anić&quot; ... ## $ Name : chr [1:168] &quot;Iva&quot; &quot;Iva&quot; &quot;Iva&quot; &quot;Iva&quot; ... ## $ Course : chr [1:168] &quot;Math.1&quot; &quot;Physics.1&quot; &quot;Digital.Logic&quot; &quot;Math.2&quot; ... ## $ Grade : int [1:168] 2 2 4 2 2 5 3 4 3 5 ... ## # A tibble: 6 × 5 ## JMBAG Surname Name Course Grade ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 1341 Anić Iva Math.1 2 ## 2 1341 Anić Iva Physics.1 2 ## 3 1341 Anić Iva Digital.Logic 4 ## 4 1341 Anić Iva Math.2 2 ## 5 1341 Anić Iva Algorithms.1 2 ## 6 1342 Babić Josip Math.1 5 The pivot_wider function does the inverse job from the pivot_longer function. It will “expand” data from a combination of a categorical column and a corresponding “value” column so the categories become column names, and the values from the value column get appropriately “spread” over the corresponding columns. The (abridged) function signature looks like this: pivot_wider(data, names_from, names_prefix = &quot;&quot;, values_from, values_fill = NULL) Complete documentation of this function is easily retrieved by using ?pivot_wider. The shortened list of parameters outlined above do the following: data is again out data frame names_from represents the name of the column whose values we will be pivoting into new columns (no need for quotes) names_prefix is an optional prefix we can add to new columns (useful if values of new columns are numbers, again no need for quotes) values_from represents the name of the column with values we will be filling the cells of new columns with values_fill is an optional value we can put when the values are missing; if left at NULL the values will be filled with NA Let’s try to “reconstruct” the original students data frame with this command. Exercise 9.8 - pivot_wider function # &quot;pivot&quot; the `grades` data frame into a wide format to reconstruct the # original data frame # store the results in a `students2` data frame # compare `students` and` students2` data frames # &quot;pivot&quot; the `grades` data frame into a wide format to reconstruct the # original data frame # store the results in a `students2` data frame students2 &lt;- pivot_wider(grades, names_from = Course, values_from = Grade) # compare `students` and `students2` data frames head(students) head(students2) str(students) str(students2) ## JMBAG Surname Name Math.1 Physics.1 Programming Electronics Digital.Logic ## 1 1341 Anić Iva 2 2 NA NA 4 ## 2 1342 Babić Josip 5 3 4 3 NA ## 3 1343 Crnoja Petra 4 3 4 2 3 ## 4 1344 Črnjac Lucija 2 5 2 2 3 ## 5 1345 Dizla Stipe NA 4 3 5 2 ## 6 1346 Ermić Igor NA 3 NA 5 5 ## Math.2 Algorithms.1 ## 1 2 2 ## 2 5 5 ## 3 4 3 ## 4 3 4 ## 5 2 2 ## 6 5 5 ## # A tibble: 6 × 10 ## JMBAG Surname Name Math.1 Physics.1 Digital…¹ Math.2 Algor…² Progr…³ Elect…⁴ ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1341 Anić Iva 2 2 4 2 2 NA NA ## 2 1342 Babić Josip 5 3 NA 5 5 4 3 ## 3 1343 Crnoja Petra 4 3 3 4 3 4 2 ## 4 1344 Črnjac Lucija 2 5 3 3 4 2 2 ## 5 1345 Dizla Stipe NA 4 2 2 2 3 5 ## 6 1346 Ermić Igor NA 3 5 5 5 NA 5 ## # … with abbreviated variable names ¹​Digital.Logic, ²​Algorithms.1, ## # ³​Programming, ⁴​Electronics ## &#39;data.frame&#39;: 27 obs. of 10 variables: ## $ JMBAG : int 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 ... ## $ Surname : chr &quot;Anić&quot; &quot;Babić&quot; &quot;Crnoja&quot; &quot;Črnjac&quot; ... ## $ Name : chr &quot;Iva&quot; &quot;Josip&quot; &quot;Petra&quot; &quot;Lucija&quot; ... ## $ Math.1 : int 2 5 4 2 NA NA NA 3 3 4 ... ## $ Physics.1 : int 2 3 3 5 4 3 3 4 2 2 ... ## $ Programming : int NA 4 4 2 3 NA 3 3 3 4 ... ## $ Electronics : int NA 3 2 2 5 5 3 4 2 2 ... ## $ Digital.Logic: int 4 NA 3 3 2 5 2 4 3 5 ... ## $ Math.2 : int 2 5 4 3 2 5 2 5 NA 4 ... ## $ Algorithms.1 : int 2 5 3 4 2 5 5 4 3 2 ... ## tibble [27 × 10] (S3: tbl_df/tbl/data.frame) ## $ JMBAG : int [1:27] 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 ... ## $ Surname : chr [1:27] &quot;Anić&quot; &quot;Babić&quot; &quot;Crnoja&quot; &quot;Črnjac&quot; ... ## $ Name : chr [1:27] &quot;Iva&quot; &quot;Josip&quot; &quot;Petra&quot; &quot;Lucija&quot; ... ## $ Math.1 : int [1:27] 2 5 4 2 NA NA NA 3 3 4 ... ## $ Physics.1 : int [1:27] 2 3 3 5 4 3 3 4 2 2 ... ## $ Digital.Logic: int [1:27] 4 NA 3 3 2 5 2 4 3 5 ... ## $ Math.2 : int [1:27] 2 5 4 3 2 5 2 5 NA 4 ... ## $ Algorithms.1 : int [1:27] 2 5 3 4 2 5 5 4 3 2 ... ## $ Programming : int [1:27] NA 4 4 2 3 NA 3 3 3 4 ... ## $ Electronics : int [1:27] NA 3 2 2 5 5 3 4 2 2 ... In the previous example, we demonstrated the inverse functionality of the pivot_longer and pivot_wider functions, but our usage pivot_wider did not serve to tidy up the data, it just enabled us to revert to the original data frame. Let us now look at an example where pivot_wider is sed to actually make the data tidier. Let’s load data from the cars.csv file that stores the technical characteristics of specific cars. Exercise 9.9 - cars data set #load the `cars.csv` file into a data frame called `cars` #briefly explore the `cars` data frame cars &lt;- read.csv(&quot;cars.csv&quot;, fileEncoding = &quot;UTF-8&quot;, stringsAsFactors = F) str(cars) head(cars) ## &#39;data.frame&#39;: 18 obs. of 3 variables: ## $ Car.model : chr &quot;Opel Astra&quot; &quot;Opel Astra&quot; &quot;Opel Astra&quot; &quot;Opel Astra&quot; ... ## $ Technical.Characteristic: chr &quot;Cylinders&quot; &quot;HP&quot; &quot;Length m&quot; &quot;Mass kg&quot; ... ## $ Value : num 4 125 4.27 1285 4 ... ## Car.model Technical.Characteristic Value ## 1 Opel Astra Cylinders 4.000 ## 2 Opel Astra HP 125.000 ## 3 Opel Astra Length m 4.267 ## 4 Opel Astra Mass kg 1285.000 ## 5 Audi A4 Cylinders 4.000 ## 6 Audi A4 HP 136.000 This table clearly violates the principles of tidy data which dictate that only one type of variable should be stored in a column - the technical characteristics of the car are placed in a unique column called Technical.Characteristic and in the value column holds very heterogeneous values (we have mass in kilograms, length in meters, etc.). Try tidying up this data frame with the pivot_wider function. Exercise 9.10 - pivot_wider function (2) # create an `cars2` data frame which will have # the tidied data from the `cars` data frame # briefly explore the `cars2` data frame # create an `cars2` data frame which will have # the tidied data from the `cars` data frame cars2 &lt;- pivot_wider(cars, names_from = Technical.Characteristic, values_from = Value) # briefly explore the `cars2` data frame str(cars2) head(cars2) ## tibble [5 × 6] (S3: tbl_df/tbl/data.frame) ## $ Car.model: chr [1:5] &quot;Opel Astra&quot; &quot;Audi A4&quot; &quot;Renault Grand Scenic&quot; &quot;Citroen C6&quot; ... ## $ Cylinders: num [1:5] 4 4 4 6 2 ## $ HP : num [1:5] 125 136 110 215 103 ## $ Length m : num [1:5] 4.27 4.7 4.56 NA NA ## $ Mass kg : num [1:5] 1285 1470 NA 1816 1260 ## $ Valves : num [1:5] NA NA 16 NA NA ## # A tibble: 5 × 6 ## Car.model Cylinders HP `Length m` `Mass kg` Valves ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Opel Astra 4 125 4.27 1285 NA ## 2 Audi A4 4 136 4.70 1470 NA ## 3 Renault Grand Scenic 4 110 4.56 NA 16 ## 4 Citroen C6 6 215 NA 1816 NA ## 5 Fiat 500L 2 103 NA 1260 NA The pivot_longer and pivot_wider commands are not only used for ‘messy’ data. Sometimes we will be pivoting our tables because one or other format is better suited for the analysis methods we wont to employ on the data. Let’s show this on the example of recommender systems Shopping cart data (or “consumer basket data”) is a record of items purchased by a customer during their visit to the store (be it a virtual store or a real retail outlet). If we write consumer basket information in a “wide” or “matrix” format, then we organize the information so that the columns represent individual items and the rows represent one successful “visit” to the story (or simply “invoice”). Here, a value of 1 means that the item ultimately ended up in the cart, while 0 means it was not present there (alternative way would be to use numbers over 1 to denote the exact quantity). This kind of representation is suitable for some recommender system implementations, because then the choice of which items to recommend can boil down to finding a “row vector” which is the closest to the one representing the current shopping cart. On the other hand, this type of representation is very uneconomical - if the store has a large number of items on offer, data will often have long rows mostly filled with “zeros”. Alternatively, the “long” format simply puts a combination of a shopping cart identifier (or account number) and the name (or code) of the item purchased in each row. This dataset will naturally have significantly more rows, but will still be much more suitable for storage purposes in cases where the number of items in the range is far greater than the number of items in the average basket. Exercise 9.11 - Consumer basket data # Load data from the `ConsumersBasket.csv` file into the `invoices` data frame # briefly explore the `invoices` data frame invoices &lt;- read.csv(&quot;ConsumerBasket.csv&quot;, stringsAsFactors = F, encoding = &quot;UTF-8&quot;) str(invoices) head(invoices) ## &#39;data.frame&#39;: 104 obs. of 21 variables: ## $ invoiceID : int 15671 15672 15673 15674 15675 15676 15677 15678 15679 15680 ... ## $ Coca.cola.2l : int 0 1 1 0 1 0 0 0 0 0 ... ## $ Chips.150g : int 0 0 1 0 0 0 0 1 0 0 ... ## $ Nutella.400.g : int 0 1 0 0 1 0 0 0 0 0 ... ## $ Light.Beer : int 0 1 0 0 0 0 0 0 0 1 ... ## $ Dark.Beer : int 1 0 0 1 0 0 0 0 0 1 ... ## $ Fabric.Softener.1.5l: int 0 0 0 0 0 0 0 1 0 1 ... ## $ Water.2l : int 0 0 1 0 0 0 0 0 1 1 ... ## $ Oranges : int 0 0 0 1 1 0 0 0 1 1 ... ## $ Apples : int 1 0 0 1 0 0 0 0 0 0 ... ## $ Pineapples : int 0 0 1 0 0 0 0 1 1 1 ... ## $ Napkins : int 0 0 0 0 1 1 0 0 0 0 ... ## $ Patte : int 0 0 1 1 0 0 0 0 0 1 ... ## $ Ketchup : int 1 0 0 1 0 0 0 0 0 1 ... ## $ Mustard : int 1 0 0 0 0 0 0 1 0 0 ... ## $ Milk.0.5l : int 0 1 0 1 1 0 0 0 0 0 ... ## $ Sour.Cream : int 0 1 0 0 0 0 1 0 0 1 ... ## $ Feta.cheese : int 0 0 0 1 0 0 0 0 0 0 ... ## $ Sardines : int 0 0 0 0 0 0 0 0 0 1 ... ## $ Tuna.patte : int 1 1 1 0 0 1 0 0 0 0 ... ## $ Nescaffe : int 0 0 1 0 0 0 0 0 1 0 ... ## invoiceID Coca.cola.2l Chips.150g Nutella.400.g Light.Beer Dark.Beer ## 1 15671 0 0 0 0 1 ## 2 15672 1 0 1 1 0 ## 3 15673 1 1 0 0 0 ## 4 15674 0 0 0 0 1 ## 5 15675 1 0 1 0 0 ## 6 15676 0 0 0 0 0 ## Fabric.Softener.1.5l Water.2l Oranges Apples Pineapples Napkins Patte Ketchup ## 1 0 0 0 1 0 0 0 1 ## 2 0 0 0 0 0 0 0 0 ## 3 0 1 0 0 1 0 1 0 ## 4 0 0 1 1 0 0 1 1 ## 5 0 0 1 0 0 1 0 0 ## 6 0 0 0 0 0 1 0 0 ## Mustard Milk.0.5l Sour.Cream Feta.cheese Sardines Tuna.patte Nescaffe ## 1 1 0 0 0 0 1 0 ## 2 0 1 1 0 0 1 0 ## 3 0 0 0 0 0 1 1 ## 4 0 1 0 1 0 0 0 ## 5 0 1 0 0 0 0 0 ## 6 0 0 0 0 0 1 0 Exercise 9.12 - converting data frame to a ‘long’ format # convert `invoices` data frame to a &quot;long&quot; format # each row needs to have invoiceID and itemName # only bought items need to be present # name the new data frame `invoicesLong` # store the new data frame in a new CSV file # called &quot;ConsumerBasketLong.csv&quot; # convert `invoices` data frame to a &quot;long&quot; format # each row needs to have invoiceID and itemName # only bought items need to be present # name the new data frame `invoicesLong` invoicesLong &lt;- pivot_longer(invoices, cols = -invoiceID, names_to = &quot;itemName&quot;, values_to = &quot;value&quot;) invoicesLong &lt;- invoicesLong[invoicesLong$value != 0, 1:2] invoicesLong &lt;- invoicesLong[order(invoicesLong$invoiceID),] head(invoicesLong) # store the new data frame in a new CSV file # called &quot;ConsumerBasketLong.csv&quot; write.csv(invoicesLong, file = &#39;ConsumerBasketLong.csv&#39;, row.names = F) ## # A tibble: 6 × 2 ## invoiceID itemName ## &lt;int&gt; &lt;chr&gt; ## 1 15671 Dark.Beer ## 2 15671 Apples ## 3 15671 Ketchup ## 4 15671 Mustard ## 5 15671 Tuna.patte ## 6 15672 Coca.cola.2l Exercise 9.13 - converting data frame to a ‘wide’ format # try formatting the &quot;long&quot; format back to &quot;wide&quot; # store the new data frame in a new CSV file # called &quot;ConsumerBasketWide.csv&quot; invoicesWide &lt;- invoicesLong invoicesWide$value &lt;- 1 invoicesWide &lt;- pivot_wider(invoicesWide, names_from = itemName, values_from = value, values_fill = 0) head(invoicesWide) write.csv(invoicesWide, file = &#39;ConsumerBasketWide.csv&#39;, row.names = F) ## # A tibble: 6 × 21 ## invoi…¹ Dark.…² Apples Ketchup Mustard Tuna.…³ Coca.…⁴ Nutel…⁵ Light…⁶ Milk.…⁷ ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 15671 1 1 1 1 1 0 0 0 0 ## 2 15672 0 0 0 0 1 1 1 1 1 ## 3 15673 0 0 0 0 1 1 0 0 0 ## 4 15674 1 1 1 0 0 0 0 0 1 ## 5 15675 0 0 0 0 0 1 1 0 1 ## 6 15676 0 0 0 0 1 0 0 0 0 ## # … with 11 more variables: Sour.Cream &lt;dbl&gt;, Chips.150g &lt;dbl&gt;, Water.2l &lt;dbl&gt;, ## # Pineapples &lt;dbl&gt;, Patte &lt;dbl&gt;, Nescaffe &lt;dbl&gt;, Oranges &lt;dbl&gt;, ## # Feta.cheese &lt;dbl&gt;, Napkins &lt;dbl&gt;, Fabric.Softener.1.5l &lt;dbl&gt;, ## # Sardines &lt;dbl&gt;, and abbreviated variable names ¹​invoiceID, ²​Dark.Beer, ## # ³​Tuna.patte, ⁴​Coca.cola.2l, ⁵​Nutella.400.g, ⁶​Light.Beer, ⁷​Milk.0.5l 9.2.2 The separate and unite functions The tidyr package has a number of other useful features for efficient transformation and clean up of our data frames, and here we will address two more commonly used onesm called separate and unite. The separate function is useful when a column has “complex” values that we want to separate into two or more columns. Exercise 9.14 - Deparments data set # read data from the `departments.csv` file into the` departments` variable # briefly explore the `departments` data frame departments &lt;- read.csv(&quot;departments.csv&quot;, stringsAsFactors = F) str(departments) head(departments) ## &#39;data.frame&#39;: 28 obs. of 4 variables: ## $ Department: chr &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; ... ## $ Quarter : chr &quot;Q1-2015&quot; &quot;Q2-2015&quot; &quot;Q3-2015&quot; &quot;Q4-2015&quot; ... ## $ RevenuesKn: num 12416 224290 10644 191229 258697 ... ## $ ExpensesKn: num 23101 63886 35468 12249 61515 ... ## Department Quarter RevenuesKn ExpensesKn ## 1 A Q1-2015 12416.2 23100.5 ## 2 A Q2-2015 224290.1 63886.1 ## 3 A Q3-2015 10643.7 35467.8 ## 4 A Q4-2015 191229.3 12249.1 ## 5 A Q1-2016 258697.4 61514.6 ## 6 A Q2-2016 121865.3 46092.6 This table shows the revenues and expenditures of a company departments by quarter. Quarters are currently stored in a complex variable called Quarter consisting of identifiers of the annual quarter (Q1, Q2, Q3 or Q4) and year. For analysis purposes, it would probably be more convenient to break this down into two columns - Quarter (which would store only the quarter identifier) and Year. The tidyr package for this purpose offers a separate function with the following signature: separate(data, col, into, sep = &quot;[^[:alnum:]] +&quot;, remove = TRUE, convert = FALSE, extra = &quot;warn&quot;, fill = &quot;warn&quot;, ...) The complete documentation of the function can be viewed with the command ?separate while here we explain some important parameters: col - column to be separated (no quotes required) into - names of new columns (character vector is recommended) sep - value separator in original column, default value is actually a regular expression for “something that is not an alphanumeric character” remove - describes whether or not to remove the original column Let’s try to apply this function to the departments data frame. Exercise 9.15 - the separate function # Separate the `Quarter` column into the `Quarter` and `Year` columns while removing the original column # save the resulting data frame to the `departments2` variable # try to do everything within one command with the help of the `%&gt;%` operator # briefly explore the `departments2` data frame departments %&gt;% separate(Quarter, c(&quot;Quarter&quot;, &quot;Year&quot;), &quot;-&quot;) -&gt; departments2 str(departments2) head(departments2) ## &#39;data.frame&#39;: 28 obs. of 5 variables: ## $ Department: chr &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; ... ## $ Quarter : chr &quot;Q1&quot; &quot;Q2&quot; &quot;Q3&quot; &quot;Q4&quot; ... ## $ Year : chr &quot;2015&quot; &quot;2015&quot; &quot;2015&quot; &quot;2015&quot; ... ## $ RevenuesKn: num 12416 224290 10644 191229 258697 ... ## $ ExpensesKn: num 23101 63886 35468 12249 61515 ... ## Department Quarter Year RevenuesKn ExpensesKn ## 1 A Q1 2015 12416.2 23100.5 ## 2 A Q2 2015 224290.1 63886.1 ## 3 A Q3 2015 10643.7 35467.8 ## 4 A Q4 2015 191229.3 12249.1 ## 5 A Q1 2016 258697.4 61514.6 ## 6 A Q2 2016 121865.3 46092.6 Note that the Quarter andYear columns are actually categorical variables so it would probably be a good idea to factorize them if we are to use them in further analysis. The separate function is often used to disassemble dates (eg 2016-10-28 into the year, month and day), but in such situations it is recommended to use the lubridate package created precisely for easier date management. We will introduce this package in one of the following chapters. Finally, let’s learn the unite function, which is somewhat less commonly used and is actually an inverse of the separate function. The unite function signature is: unite(data, col, ..., sep = &quot;_&quot;, remove = TRUE) In this case, too, we can easily retrieve the documentation for unite, and will just briefly describe the parameters that potentially require additional explanation: col - new column name (quotes not required) ... - the names of the columns we merge - we don’t have to use quotation marks, and if there are many columns we can use the same syntax to select as with the gather function Let’s try using this function on the departments2 data frame. Exercise 9.16 - the unite function # merge the `Quarter` and `Year` columns from the `departments2` table into a unique` Quarter` column # remove the previous `Quarter` and `Year` columns # use `-` as a separator # save the result to the `departments3` variable # use the `%&gt;% &#39;operator to put everything in one line # compare `departments` and `departments3` data frames departments2 %&gt;% unite(Quarter, Quarter, Year, sep = &quot;-&quot;) -&gt; departments3 str(departments2) head(departments2) str(departments3) head(departments3) ## &#39;data.frame&#39;: 28 obs. of 5 variables: ## $ Department: chr &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; ... ## $ Quarter : chr &quot;Q1&quot; &quot;Q2&quot; &quot;Q3&quot; &quot;Q4&quot; ... ## $ Year : chr &quot;2015&quot; &quot;2015&quot; &quot;2015&quot; &quot;2015&quot; ... ## $ RevenuesKn: num 12416 224290 10644 191229 258697 ... ## $ ExpensesKn: num 23101 63886 35468 12249 61515 ... ## Department Quarter Year RevenuesKn ExpensesKn ## 1 A Q1 2015 12416.2 23100.5 ## 2 A Q2 2015 224290.1 63886.1 ## 3 A Q3 2015 10643.7 35467.8 ## 4 A Q4 2015 191229.3 12249.1 ## 5 A Q1 2016 258697.4 61514.6 ## 6 A Q2 2016 121865.3 46092.6 ## &#39;data.frame&#39;: 28 obs. of 4 variables: ## $ Department: chr &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; ... ## $ Quarter : chr &quot;Q1-2015&quot; &quot;Q2-2015&quot; &quot;Q3-2015&quot; &quot;Q4-2015&quot; ... ## $ RevenuesKn: num 12416 224290 10644 191229 258697 ... ## $ ExpensesKn: num 23101 63886 35468 12249 61515 ... ## Department Quarter RevenuesKn ExpensesKn ## 1 A Q1-2015 12416.2 23100.5 ## 2 A Q2-2015 224290.1 63886.1 ## 3 A Q3-2015 10643.7 35467.8 ## 4 A Q4-2015 191229.3 12249.1 ## 5 A Q1-2016 258697.4 61514.6 ## 6 A Q2-2016 121865.3 46092.6 Exercise Tasks Initialize the random number generator using the command set.seed(1234). Then, with the help of a single command and the `%&gt;% ’operator, perform the following: create 100,000 random numbers drawn from the normal distribution with arithmetic mean of 10000 and standard deviation of 1000 round the numbers to the first larger integer drop duplicates from the set sort the set in ascending order randomly select 100 elements from the set organize these 100 elements into a 10x10 matrix, arranged in rows calculate sums of rows of the matrix print the mean of line sums on the screen. The weather.csv file contains meteorological station meteorological data which measures the temperature, pressure, humidity and wind speed every hour (data are downloaded and adapted from the data set of theweatherData package available on CRAN). Do the following: load the file into the data frame and examine the loaded data (names, str, summary,head …) answer: is it a tidy dataset? Why? Take the appropriate steps to obtain a data frame that complies with the tidy data principle save the new data frame to the file called weatherClean.csv Programirajmo u R-u by Damir Pintar is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.Based on a work at https://ratnip.github.io/FER_OPJR/ References "],["dates.html", "10 Working with dates and character strings 10.1 Working with dates 10.2 The lubridate package 10.3 Working with character strings Exercise Tasks", " 10 Working with dates and character strings 10.1 Working with dates Managing dates and timestamps is always a challenge when working with real-life datasets, since we have to take into account things like: different date and time format specifications different internal representations different time zones difference between mathematical and calendar understanding of time periods One of the more commonly used standards is the so-called “unix time” (or “POSIX time”), which counts as the number of seconds elapsed since midnight on January 1, 1970 UTC (Coordinated Universal Time). This is not an universal standard for all operations systems or applications; for example, Microsoft Excel has its own format where it counts the days since 1.1.1900 and then the number of hours, minutes and seconds elapsed since midnight. The R programming language has offers three main classes for date/time management: Date for dates POSIXct for compact representation of timestamps POSIXlt for “long” representation of timestamps (in list format) 10.1.1 The Date class We use the Date class when we want to note the date but not the exact time of an observation or event. This class does not have a constructor, and we most commonly create Date objects using the following functions: Sys.Date() which returns today’s date as.Date(&lt;date_string&gt;) which accepts a character string as a parameter The function as.Date() by default accepts dates in the following format: %Y-%m-%d. Here, %Y represents a four-digit year, while %m and %d are two-digit months and days. If we want to interpret a date that is written in another format then we need to add an additional parameter called format which will parametrically describe the format we are using (e.g. for 28/10/1978 the format parameter value should be %d/%m/%Y). Other format specifications can easily be viewed using the ?strptime command, although a much simpler approach entails using functions of thelubridate package (to be introduced later in this chapter). Exercise 10.1 - class Date # print out today&#39;s date # convert the following character strings to a `Date` type object and print the result on the screen: # &#39;1986-12-27&#39;, &#39;2016-31-05&#39;, &#39;17.10.2015 &#39;, &#39;01#01#2001&#39; # print out today&#39;s date Sys.Date() # convert the following character strings to a Date type object and print the result on the screen: # &#39;1986-12-27&#39;, &#39;2016-31-05&#39;, &#39;17.10.2015 &#39;, &#39;01#01#2001&#39; as.Date(&quot;27/12/1986&quot;) as.Date(&#39;2016-31-05&#39;, format = &#39;%Y-%d-%m&#39;) as.Date(&#39;17.10.2015&#39;, format = &#39;%d.%m.%Y&#39;) as.Date(&#39;01#01#2001&#39;, format = &#39;%d#%m#%Y&#39;) ## [1] &quot;2022-12-07&quot; ## [1] &quot;0027-12-19&quot; ## [1] &quot;2016-05-31&quot; ## [1] &quot;2015-10-17&quot; ## [1] &quot;2001-01-01&quot; Dates allow using simple arithmetic operations. We can add or substract days from a date by using operators + and - with integers, or we can calculate the difference between two dates with the operator -. *** Exercise 10.2 - date arithmetics # print out what date was 1000 days before today # add one day to 2/28/2015. and 2/28/2016 and print the result # print out how many days have passed since 1.1.2000. until today # print out what date was 1000 days before today Sys.Date() - 1000 # add one day to 2/28/2015. and 2/28/2016 and print the result as.Date(&#39;2015-02-28&#39;) + 1 as.Date(&#39;2016-02-28&#39;) + 1 # print out how many days have passed since 1.1.2000. until today Sys.Date() - as.Date(&#39;2000-01-01&#39;) ## [1] &quot;2020-03-12&quot; ## [1] &quot;2015-03-01&quot; ## [1] &quot;2016-02-29&quot; ## Time difference of 8376 days The last expression will actually result in an object of class difftime which is an object representation of a time interval. Printing this object uses so-called “automatic” unit selection (specifically, the units parameter is by default set to auto) that will attempt to select the most appropriate time unit for printing. If we want to explicitly choose which time unit we want (seconds, minutes, hours, days or weeks), then it’s easier to forgo using the - operator and leverage the difftime() function directly. Specific time unit can then be chosen by setting the units parameter to seconds, minutes etc. Exercise 10.3 - function difftime # How many weeks passed between 1.3.2016. i 1.3.2015.? # use the `difftime` function # NOTE: You do not need to explicitly call the `as.Date` function, the `difftime()` function # will do it by itself if you submit the date in the default format # how many hours have passed between 1.3.2015. and today? # How many weeks passed between 1.3.2016. i 1.3.2015.? # use the `difftime` function # NOTE: You do not need to explicitly call the `as.Date` function, the `difftime()` function # will do it by itself if you submit the date in the default format difftime(&#39;2016-03-01&#39;, &#39;2015-03-01&#39;, units = &quot;weeks&quot;) # how many hours have passed between 1.3.2015. and today? difftime(Sys.Date(), &#39;2015-03-01&#39;, units = &quot;hours&quot;) ## Time difference of 52.28571 weeks ## Time difference of 68113 hours The difftime function actually works with timestamps as well, i.e. we don’t necessarily have to work at the date level, we can get information on finer granularity when it comes to time units. We will show this in more detail after we learn the class POSIXct. Also, if we only require a number (of seconds, hours, days, etc.), we can easily transform the difftime output into an integer using the as.numeric function. The R language also implements a special variant of the seq function for working with dates, which has the following signature: seq(from, to, by, length.out = NULL, along.with = NULL, ...) The parameters of this function are as follows: from - start date (required parameter) to - final date by - step of the sequence in days, or a character string which denotes the time interval such as \"7 days\", \"2 weeks\" etc. (for all possibilities see the documentation!) length.out - length of sequence along.with - vector whose length we take for reference (along.with(x) is the same as length.out = length(x)) Let’s try this function. Exercise 10.4 - function seq and dates # print the date sequence from 1/1/2010. to 1/1/2030. in 6-month increments # make a schedule for one round of cleaning the common areas of an apartment building # common areas must be cleaned every 3 weeks # each apartment must get their own date # apartments are described by the following data frame apartments &lt;- data.frame(appId = 1:10, surname = c(&quot;Ebert&quot;, &quot;Ladovac&quot;, &quot;Cerić&quot;, &quot;Dikla&quot;, &quot;Anic&quot;, &quot;Perić&quot;, &quot;Žužić&quot;, &quot;Babić&quot;, &quot;Ibiza&quot;, &quot;Radler&quot;)) # Add a `cleaningDate` column with one date for each apartment # in order of apartment numbers, starting today # print out the &#39;apartments&#39; data frame # print the date sequence from 1/1/2010. to 1/1/2030. in 6-month increments seq(as.Date(&#39;2010-01-01&#39;), as.Date(&#39;2030-01-01&#39;), by = &quot;6 months&quot;) # Add a `cleaningDate` column with one date for each apartment # in order of apartment numbers, starting today seq(Sys.Date(), by = &quot;3 weeks&quot;, along.with = apartments$appId) -&gt; apartments$cleaningDate # print out the &#39;apartments&#39; data frame apartments ## [1] &quot;2010-01-01&quot; &quot;2010-07-01&quot; &quot;2011-01-01&quot; &quot;2011-07-01&quot; &quot;2012-01-01&quot; ## [6] &quot;2012-07-01&quot; &quot;2013-01-01&quot; &quot;2013-07-01&quot; &quot;2014-01-01&quot; &quot;2014-07-01&quot; ## [11] &quot;2015-01-01&quot; &quot;2015-07-01&quot; &quot;2016-01-01&quot; &quot;2016-07-01&quot; &quot;2017-01-01&quot; ## [16] &quot;2017-07-01&quot; &quot;2018-01-01&quot; &quot;2018-07-01&quot; &quot;2019-01-01&quot; &quot;2019-07-01&quot; ## [21] &quot;2020-01-01&quot; &quot;2020-07-01&quot; &quot;2021-01-01&quot; &quot;2021-07-01&quot; &quot;2022-01-01&quot; ## [26] &quot;2022-07-01&quot; &quot;2023-01-01&quot; &quot;2023-07-01&quot; &quot;2024-01-01&quot; &quot;2024-07-01&quot; ## [31] &quot;2025-01-01&quot; &quot;2025-07-01&quot; &quot;2026-01-01&quot; &quot;2026-07-01&quot; &quot;2027-01-01&quot; ## [36] &quot;2027-07-01&quot; &quot;2028-01-01&quot; &quot;2028-07-01&quot; &quot;2029-01-01&quot; &quot;2029-07-01&quot; ## [41] &quot;2030-01-01&quot; ## appId surname cleaningDate ## 1 1 Ebert 2022-12-07 ## 2 2 Ladovac 2022-12-28 ## 3 3 Cerić 2023-01-18 ## 4 4 Dikla 2023-02-08 ## 5 5 Anic 2023-03-01 ## 6 6 Perić 2023-03-22 ## 7 7 Žužić 2023-04-12 ## 8 8 Babić 2023-05-03 ## 9 9 Ibiza 2023-05-24 ## 10 10 Radler 2023-06-14 10.1.2 ThePOSIXct andPOSIXlt classes The class POSIXct is used when in addition to the date we also need to know the exact time for some observation or event. The usual way of creating an object of this class is using the following functions: Sys.time() which returns the current timestamp (using the timezone set by the operating system) as.POSIXct(&lt;timestamp_string&gt;) which uses a character string representing the date and time The function as.POSIXct() expects a timestamp character string that uses the following format: %Y-%m-%d %H:%M:%S. First three format specifications are identical to the date format specification, while %H, %M and %S represent two-digit hours, minutes and seconds (24-hour time format is assumed unless am or pm is noted). The as.POSIXct function can also accept an optional tz parameter which explicitly sets the timezone. To parse other timestamp formats, it is necessary - as with the class Date - to add a format parameter containing a specification on how to interpret the given character string. Again, for the list of all parameters we can refer to the the ?strptime command, although as with the Date class we will later learn it’s often easier to use one of the functions of the lubridate package. Exercise 10.5 - class POSIXct # print the current date and time # convert the following character strings to timestamps and print them on the screen: # &quot;2015-10-28 15:30:42&quot; # &quot;01-12-2001 14:30&quot; &lt;- timestamp read in New York, USA, EST time zone # print the current date and time Sys.time() # convert the following character strings to timestamps and print them on the screen: # &quot;2015-10-28 15:30:42&quot; # &quot;01-12-2001 14:30&quot; &lt;- timestamp read in New York, USA, EST time zone as.POSIXct(&quot;2015-10-28 15:30:42&quot;) as.POSIXct(&quot;01-12-2001 14:30&quot;, tz = &quot;EST&quot;, format = &quot;%d-%m-%Y %H:%M&quot;) ## [1] &quot;2022-12-07 11:44:17 CET&quot; ## [1] &quot;2015-10-28 15:30:42 CET&quot; ## [1] &quot;2001-12-01 14:30:00 EST&quot; Time zone names are standardized (so-called “Olson time zones”) and are retrieved from the underlying operating system. We can explicitly retrieve them using the OlsonNames() function. Also, we can easily print the current platform’s time zone by using the Sys.timezone() function. Exercise 10.6 - time zones # print the current time zone # print out 10 randomly selected time zone names installed on the current platform # print the current time zone Sys.timezone() # print out 10 randomly selected time zone names installed on the current platform sample(OlsonNames(), 10) ## [1] &quot;Europe/Warsaw&quot; ## [1] &quot;Europe/Uzhgorod&quot; &quot;Etc/GMT+11&quot; &quot;US/Hawaii&quot; ## [4] &quot;America/Regina&quot; &quot;GMT&quot; &quot;America/Araguaina&quot; ## [7] &quot;America/Phoenix&quot; &quot;Europe/Tiraspol&quot; &quot;Asia/Macao&quot; ## [10] &quot;America/Matamoros&quot; Timestamps can also use + and - operators (with integers as the second operand) to add or substract seconds from the timestamp. Additionally, we can subtract two timestamps to get the difference in seconds, or use the difftime function with the selected time unit value. Exercise 10.7 - timestamp arithmetics # print out what the time will be 1000 seconds from now # print out how many hours have passed since midnight 1/1/2015 # print out what the time will be 1000 seconds from now Sys.time() + 1000 # print out how many hours have passed since midnight 1/1/2015. by far difftime(Sys.time(), &quot;2015-01-01 00:00:00&quot;, units = &quot;hours&quot;) ## [1] &quot;2022-12-07 12:00:57 CET&quot; ## Time difference of 69539.74 hours The class POSIXlt is very similar to its compact relative POSIXct. We use the similarly fashioned as.POSIXlt function to create one, however the difference is that we end up with a list which allows us to easily extract certain parameters from a timestamp, such as number of seconds, minutes, day of the week, etc. We can easily see all the elements of the list if we create a POSIXlt object and then call the unclass function on it, which will convert it to an “ordinary” list. We can even go a step further - if we put this list through the unlist function, we get a simple, easily interpretable character vector as a result. Exercise 10.8 - class POSIXlt # convert the following character string to a timestamp of type `POSIXlt` # store the result in the variable `t_long` # &quot;01/05/2013 13:35&quot; # print just the number of hours of the timestamp `t_long` # then just the number of minutes # you can find this information in subelements called `hour` and `minute` # remove the class and list property of the variable `t_long` # and print it on the screen # convert the following character string to a timestamp of type `POSIXlt` # store the result in the variable `t_long` # &quot;01/05/2013 13:35&quot; t_long &lt;- as.POSIXlt(&quot;01/05/2013 13:35&quot;, format = &quot;%d/%m/%Y %H:%M&quot;) # print just the number of hours of the timestamp `t_long` # then just the number of minutes # you can find this information in subelements called `hour` and `minute` t_long$hour t_long$min # remove the class and list property of the variable `t_long` # and print it on the screen t_long %&gt;% unclass() %&gt;% unlist() ## [1] 13 ## [1] 35 ## sec min hour mday mon year wday yday isdst zone gmtoff ## &quot;0&quot; &quot;35&quot; &quot;13&quot; &quot;1&quot; &quot;4&quot; &quot;113&quot; &quot;3&quot; &quot;120&quot; &quot;1&quot; &quot;CEST&quot; NA 10.2 The lubridate package Although the R language has relatively good support for working with dates and timestamps, we can make managing them significantly more efficient by using a package called lubridate package. If we analyze data where the time component is very important, or manage data sets that use exotic ways of noting date and time, then we can greatly simplify and accelerate the analysis process by using the features provided by this package. One of the things that may be most helpful to developers who don’t like to write formatted date parsing specifications is the family of date parsing functions whose names match the overall “structure” of the record we want to parse. For example, the function called ymd can parse character strings in which the date is written in the order year-month-day. The function is “smart” enough to interpret the details of the record itself, such as delimiters, character fields, etc. If the record has a different day, month, and year layout, it is only necessary to arrange the letters appropriately in the function name. Exercise 10.9 - date parsing functions of the lubridate package # library(lubridate) # load if needed! # using the functions in the `lubridate` package # parse the following character strings into dates and print them on the screen # &quot;2016-07-31&quot; # &quot;28/2/1983&quot; # &quot;07#31#1996&quot; # &quot;20010830&quot; # using the functions in the `lubridate` package # parse the following character strings into dates and print them on the screen # &quot;2016-07-31&quot; # &quot;28/2/1983&quot; # &quot;07#31#1996&quot; # &quot;20010830&quot; ymd(&quot;2016-07-31&quot;) dmy(&quot;28/2/1983&quot;) mdy(&quot;07#31#1996&quot;) ymd(&quot;20010830&quot;) ## [1] &quot;2016-07-31&quot; ## [1] &quot;1983-02-28&quot; ## [1] &quot;1996-07-31&quot; ## [1] &quot;2001-08-30&quot; The aforementioned approach can also be used for timestamps, we just add the underscore and then the “letters” for hours, minutes and/or seconds (e.g. ymd_hms). Exercise 10.10 - timestamp parsing functions of the lubridate package # using the functions in the `lubridate` package # parse the following character strings to timestamps and print them on the screen # &quot;17/05/1977 10:15 pm&quot; # &quot;20160429 05:10:17&quot; # using the functions in the `lubridate` package # parse the following character strings to timestamps and print them on the screen # &quot;17/05/1977 10:15 pm&quot; # &quot;20160429 05/10/17&quot; dmy_hm(&quot;17/05/1977 10:15 pm&quot;) ymd_hms(&quot;20160429 05:10:17&quot;) ## [1] &quot;1977-05-17 22:15:00 UTC&quot; ## [1] &quot;2016-04-29 05:10:17 UTC&quot; Note that these functions always sets UTC for the time zone. This was intentionally designed to motivate the use of a consistent time zone in the data set we are analyzing. If desired, we can set the time zone with the tz parameter during parsing. Similarly, with timestamps already initialized, we can manage time zones using the following functions force_tz - “enforces” the change to a new time zone while leaving the timestamp values the same with_tz - converts a timestamp into one that matches the requested time zone t &lt;- ymd_hms(&quot;20161129 05:10:17&quot;, tz = &quot;EST&quot;) t force_tz(t, tz = &quot;CET&quot;) with_tz(t, tz = &quot;CET&quot;) ## [1] &quot;2016-11-29 05:10:17 EST&quot; ## [1] &quot;2016-11-29 05:10:17 CET&quot; ## [1] &quot;2016-11-29 11:10:17 CET&quot; The lubridate package also makes it easy to extract date and time segments from timestamps with functions such as year, week, month, etc. The same functions can also be used to change any of the timestamp components. Exercise 10.11 - extracting timestamp elements x &lt;- dmy_hms(&quot;7/19/1996 4:15:27 PM&quot;) ## Warning: All formats failed to parse. No formats found. # extract and print hours from the timestamp above, followed by minutes # set the year of the above timestamp to 2011, and the month to June # print timestamp `x` on the screen x &lt;- dmy_hms(&quot;7/19/1996 4:15:27 PM&quot;) ## Warning: All formats failed to parse. No formats found. # extract and print hours from the timestamp above, followed by minutes hour(x) minute(x) # set the year of the above timestamp to 2011, and the month to June year(x) &lt;- 2011 month(x) &lt;- 6 # print timestamp `x` on the screen x ## [1] NA ## [1] NA ## [1] NA See the lubridate documentation for a complete list of features. For the current date and time, lubridate offers alternatives to the Sys.Date() and Sys.time() functions, which are simply called today() and now(). Exercise 10.12 - functions today and now # print out tomorrow&#39;s date # print the timestamp which happened exactly an hour ago # print out tomorrow&#39;s date today() + 1 # print the timestamp which happened exactly an hour ago now() - 60 * 60 ## [1] &quot;2022-12-08&quot; ## [1] &quot;2022-12-07 10:44:18 CET&quot; We already mentioned that managing time-related data can become very complex, especially considering that time intervals can be expressed generically (e.g., “2 years”) or specifically (the span of two dates), and that mathematical and calendar ways of expressing time intervals do not necessarily match (e.g., “period of one year” can mathematically mean “the exact number of seconds in 365 days” but also the contextually dependent “period until the same date next year”). The lubridate package defines four options for defining time-related objects: instant - timestamp rounded to the second duration - “generically” defined interval in seconds period - similar to duration, but allows you to define durations that do not always last mathematically (e.g. “3 months”) interval - the time interval between two specific moments We have already met the “istants”, these are the timestamps we have already shown. To create durations and periods, we have intuitively defined functions that are named by English names for time units, with durations having the letter d as a prefix (from duration). Hence, we have the functions called minutes/dminutes, hours/dhours, weeks/dweeks etc. (note that there is no dmonths function, since we cannot unambiguously convert one month into seconds). Exercise 10.13 - durations and periods # print out objects which represent the duration and period of 3 weeks # use the variable `v` to store a period of 5 years, 3 months and 2 days # add the above period to today&#39;s date # print out objects which represent the duration and period of 3 weeks weeks(3) dweeks(3) # use the variable `v` to store a period of 5 years, 3 months and 2 days v &lt;- years(5) + months(3) + days(2) # add the above period to today&#39;s date today() + v ## [1] &quot;21d 0H 0M 0S&quot; ## [1] &quot;1814400s (~3 weeks)&quot; ## [1] &quot;2028-03-09&quot; Notice that the above expression would not be consistent if obtained “mathematically”. Finally, we can create an interval by using the interval function and providing the start and end timestamps, or by using the as.interval function and giving the duration/period and the start timestamp. We can also use the operator %--% with two timestamps as operands. Exercise 10.14 - intervals # create a variable `interval1` to store the interval # between 6 months before today and 6 months after today # create a variable `interval2` and store the interval from today # until the date that will happen in 4 months, 3 weeks and 2 days # create a variable `interval3` that will store the interval # between 1.5.2002. and 1.7.2002. # print out all three intervals # create a variable `interval1` to store the interval # between 6 months before today and 6 months after today interval1 &lt;- interval(today() - months(6), today() + months(6)) # create a variable `interval2` and store the interval from today # until the date that will happen in 4 months, 3 weeks and 2 days interval2 &lt;- as.interval(months(4) + weeks(3) + days(2), today()) # create a variable `interval3` that will store the interval # between 1.5.2002. and 1.7.2002. interval3 &lt;- dmy(&quot;1.5.2002&quot;) %--% dmy(&quot;1.7.2002&quot;) # print out all three intervals interval1 interval2 interval3 ## [1] 2022-06-07 UTC--2023-06-07 UTC ## [1] 2022-12-07 UTC--2023-04-30 UTC ## [1] 2002-05-01 UTC--2002-07-01 UTC When we have intervals defined we can then: check if a timestamp is within an interval with the help of the operator %within% check whether the intervals overlap by using the function int_overlaps() easily retrieve the start and end of intervals using the functions int_start() and int_end() “merge” two intervals with the help of the union function or find the intersection between them with the help of the intersect function other stuff we can learn by looking at the documentation Exercise 10.15 - working with intervals # check whether today is within the interval defined by the variable `interval1` # if `interval1` and `interval2` overlap # print out their intersection # check whether today is within the interval defined by the variable `interval1` today() %within% interval1 # if `interval1` and `interval2` overlap # print out their intersection if(int_overlaps(interval1, interval1)) intersect(interval1, interval2) ## [1] TRUE ## [1] 2022-12-07 UTC--2023-04-30 UTC In this section, we are introduced to some of the functionality offered by the base R’s date and time classes as well as some of the functionalities offered by the lubridate package. For more information, see the official documentation of the R language and the lubridate package, or the article called “Dates and Times Made Easy with lubridate” written by the author of the package Hadley Wickham, available at this link . 10.3 Working with character strings R has very good support for character strings. However, the functions offered by base R are a bit unintuitive and inconsistent when compared to similar functions offered by other programming languages commonly used for text analysis (such as Perl or Python). It is for these specific reasons that the stringr package emerged, offering a very popular alternative to existing character string functions. However, before getting acquainted with the features offered by this package, it is necessary to briefly address the general issues of managing character strings in data analysis as well as introduce a technology without which the implementation of character string analysis is almost unthinkable - “regular expressions”. 10.3.1 Text analysis and regular expressions Text analysis is an inevitable element of data analysis. Whether it’s simple category identification, searching for specific patterns, or something performing more complex tasks commonly known as text mining, it’s hard to imagine any meaningful data analysis that doesn’t at some point require knowledge of at least the basic methods of managing sets of character strings. Regardless of the complexity of character string analysis we want to perform, one technology is ubiquitous and universally applicable - regular expressions. This is a special “language” that we use to define “patterns” which we use to search or process textual information in various ways. A thorough review of regular expression technology is beyond the scope of this coursebook. Below, we will provide only a brief overview. If you have never encountered this technology before, we strongly recommend that you make the effort and master at least the basic concepts, preferably using one of many excellent web resources. One very short yet effective regular expression mini-courses can be found here . A regular expression is simply a string of characters that represents the pattern we are looking for within a text. Eg. the regular expression gram is contained in the character string Programming language R but is not in the character string Text analysis. We say we found a “match” with the first string but not with the second. This kind of regular expression is not too flexible - the true power of regular expressions lies in using special symbols which enable describing patterns in a more “generic” way. Let’s demonsrate this on a simple example. One common scenarios of using regular expressions is checking whether the user has entered an address that corresponds to the “general” form of the email address. One possibility is to simply use the expression @ as a regular expression we want to find a “match” with the email adress we are checking for validity. This can help with filtering out a certain number of invalid email adresses, but will also allow “addresses” such as @@@ and @23456. With a little “work” on the expression, you could come up with a slightly better solution, which may look something like this: \\w+@\\w+\\.\\w+ Although it looks like a series of random characters, with basic knowledge of regular expressions (and, in this case, using the “Perl” standard) we can interpret the above expression relatively easily. The character \\w stands for “letter, number or underscore”, the sign + means “1 or more”, etc. If you wanted to “transcribe” the above regular expression in a spoken language, it would be “one or more letters, digits or underscores’, followed by the sign @, then again one or more letters, digits or underscores, then a dot and then finally one or more letters, digits or underscores.” While this is not an overly sophisticated regular expression, it is still better than the first attempt. Further refinement is certainly possible, and although subsequent additions are increasingly making it harder to be easily interpreted by the human, we are also gaining more and more control over the formal definitions of what an email address should look like (for such specific uses, it is often worthwhile to check publicly available regular expression repositories where we can find complex but of high quality and carefully tested expressions that are easy enough to copy into our program code). We already stated that the above expression is written in so-called “Perl standard”. Unfortunately, today there isn’t a single standard for regular expressions. Most often used are so-called “POSIX standard” in two versions - BRE and ERE (Basic Regular Expressions and Extended Regular Expressions) which are pretty similar, except for the fact that BRE relies a bit on the \\ character and doesn’t recognize some of the “newer” symbols that ERE uses. Another popular standard is the already mentioned “Perl standard” which is a version of regular expressions implemented in the Perl programming language. Because Perl is one of the leading languages for text processing, this standard has become one of the most widely accepted methods of using regular expressions. In general, almost all popular programming languages have support for regular expressions, either embedded in the language or with the help of additional packages. R is one of the languages that already includes support for regular expressions in its base package. What’s more, R has built-in parallel support for the three most widely used standards mentioned above - POSIX ERE, POSIX BRE and Perl. POSIX ERE is the default setting, and with certain parameters we can easily “switch” to BRE (extended = FALSE) or Perl (perl = TRUE). In the following paragraphs, we will stick with the ERE standard, but it is also important to know that the above settings may be used if we already have previously constructed regular expressions that have been developed in another standard (and we do not want to be bothered by switching from one standard to another). The following table gives a brief overview of some of the more commonly used regular expression elements in the language R: Element Meaning abcd literal string “abcd” 1234 literal string “1234” \\\\d or [:digit:] or [0-9] any digit \\\\D or [:alpha:] or [A-Za-z] any letter [:alnum:] any alphanumeric character . any character \\\\. dot (full stop) [abc] only the characters listed [^abc] all characters except those listed * zero or more repetitions + one or more repetitions {n} exactly n repetitions {m, n} at least m, at most n repetitions ? optional character [:space:] or \\\\ s any blank (space, tab, new line) [:punct:] punctuation marks ^ ... $ a start and end markers (ab|cd) string “ab” or string “cd” Note that when using the special character \\ as a part of a regular expression we actually have to use the double character \\\\ (the first time to indicate to R that a special character follows, the second time to literally use it as part of the regular expression). The basic functions of the R language to work with character strings (and thus regular expressions) are, among other things, grep,grepl, regexrp,gregexrp, regmatches, sub, gsub etc. But since the stringr package offers a set of alternative functions with almost the same functionality but with far more intuitive names and more consistent signatures, we will focus on functions from that package, leaving the base functions to readers as an optional exercise to be learned from the official documentation. 10.3.2 The stringr package We have already stated that the stringr package actually reimplements to some extent the already existing functions of the language R, but in a more intuitive and consistent way. To be more precise, the functions of the stringr package have slightly reduced functionality, which is actually by design - one of the imperatives when designing this package was to identify the most commonly used functionalities for text analysis and focus on that primarily. Functionality that is “thrown out” concerns specific cases for which the developer will need to look for alternative solutions (often in the form of basic functions), but the benefit is in simpler, more intuitive features that are easier to learn and use effectively in the long-term effectively. Additional benefits of using the stringr package are: consistent treatment of factors as character strings consistent ordering of parameters, which is especially useful when used in conjunction with the operator %&gt;% We can start with some simpler functions for which we do not need regular expressions (we list simplified function signatures, for more precise definitions consult the package documentation): str_c(string1, string2, ...) - merge character strings, alternative to paste0 str_length(string) - returns the length of the character string str_sub(string, start, end) - returns a substring using start and end as letter indexes (negative index means “counting from the back”) str_sub(string, start, end) &lt;- string2 - modifies string by exchanging the defined substring with string2 (which does need not be the same length as the dropped substring!) str_trim(string) - returns a string with removed blanks from the beginning and end of a string Exercise 10.16 - basic functions for working with character strings string1 &lt;- &quot; This is an example&quot; string2 &lt;- &quot;of string concatenation! &quot; # using one line of instructions concatenate the above strings, # remove the blanks at the beginning and end of the string from the result, # then select the substring from 35th to 55th character # and print the final result on the screen string &lt;- &quot;R is overly complicated and not an easy language!&quot; # in the upper character string, replace all the characters # from 6th place (counted from the start) # to 14th (counting from the end) # with an empty string # print the string string1 &lt;- &quot; This is an example&quot; string2 &lt;- &quot; of string concatenation! &quot; # using one line of instructions concatenate the above strings, # remove the blanks at the beginning and end of the string from the result, # then select the substring from 22nd to 41st character # and print the final result on the screen str_c(string1, string2)%&gt;% str_trim()%&gt;% str_sub(22, 41) string &lt;- &quot;R is overly complicated and not an easy language!&quot; # in the upper character string, replace all the characters # from 6th place (counted from the start) # to 14th (counting from the end) # with an empty string str_sub(string, 6, -14) &lt;- &quot;&quot; # print the string string ## [1] &quot; string concatenatio&quot; ## [1] &quot;R is asy language!&quot; The str_c function also has a sep parameter if we want to paste the strings with a specific separator, and the collapse parameter which is NULL by default, but which can be used to merge elements of a character vector into a single string (with the value of the parameter used as a separator). Exercise 10.17 - merging character strings string1 &lt;- &quot;To merge&quot; string2 &lt;- &quot;these strings&quot; string3 &lt;- &quot;you need some space!&quot; # merge the above strings into a single string and print the result arrays &lt;- c(&quot;These&quot;, &quot;vector&quot;, &quot;elements&quot;, &quot;should&quot;, &quot;be&quot;, &quot;joined...&quot;) # merge the elements of the above vector into one string and print the result string1 &lt;- &quot;To merge&quot; string2 &lt;- &quot;these strings&quot; string3 &lt;- &quot;you need some space!&quot; # merge the above strings into a single string and print the result str_c(string1, string2, string3, sep = &quot; &quot;) strings &lt;- c(&quot;These&quot;, &quot;vector&quot;, &quot;elements&quot;, &quot;should&quot;, &quot;be&quot;, &quot;joined...&quot;) # merge the elements of the above vector into one string and print the result str_c(strings, collapse = &quot; &quot;) ## [1] &quot;To merge these strings you need some space!&quot; ## [1] &quot;These vector elements should be joined...&quot; Let’s look at some stringr functions that work with regular expressions: str_detect(string, pattern) - returns TRUE if string contains pattern, otherwiseFALSE str_extract(string, pattern) - returns a string of characters corresponding to the first occurrence of a pattern str_extract_all(string, pattern) - returns a list with all occurrences that match the pattern str_replace(string, pattern, replacement) - changes the first occurrence of a pattern with the replacement str_replace_all(string, pattern, replacement) - changes all occurrences of a pattern with the replacement All of these functions are vectorized, which means that they behave logically (ie, “parallelized”) when we use a character vector with multiple elements in place of a specific parameter. For example, if we give a vector of strings and a vector of replacements to the str_replace function, elements of the first vector and replacements will “pair up” in place of a given pattern. We can have other combinations, such as a vector of original elements and a vector of patterns, all three parameters as vectors with multiple elements etc. but every time the behavior of the function is consistent with the already learned principle of vectorization. Exercise 10.18 - functions and regular expressions addresses &lt;- c(&quot;pero.peric@fer.hr&quot;, &quot;iva.ivic@etfos.hr&quot;, &quot;ppetrovic@gmail.com&quot;, &quot;branko1987@yahoo.com&quot;, &quot;jaRULZ4EVR@gmail.nz&quot;, &quot;dperkovic@efzg.hr&quot;, &quot;lalaic1998@gmail.co.uk&quot;, &quot;perica.markic@fer.hr&quot;) # print the total number of mail addresses which belong to the `fer.hr` subdomain # print all addresses that contain at least one digit # list all addresses that have a vowel as the second character # print all unique email address subdomains # (subdomain part of the address is everything after behind the `@` character) # anonymize the addresses above: all character strings in front of &#39;@&#39; # should be replaced with random 6-digit numbers # print the total number of mail addresses which belong to the `fer.hr` subdomain str_detect(addresses, &quot;fer\\\\.hr&quot;)%&gt;% sum # print all addresses that contain at least one digit addresses[str_detect(addresses, &#39;[:digit:]&#39;)] # list all addresses that have a vowel as the second character str_detect(addresses, &quot;^.[aeiouAEIOU]&quot;) %&gt;% addresses[.] # print all unique email address subdomains # (subdomain part of the address is everything after behind the `@` character) str_extract(addresses, &#39;@(.*)&#39;) %&gt;% str_sub(2) %&gt;% unique # anonymize the addresses above: all character strings in front of &#39;@&#39; # should be replaced with random 6-digit numbers sample(100000: 999999, length(addresses)) %&gt;% as.character %&gt;% str_replace(addresses, &#39;^[^@]*&#39;, .) ## [1] 2 ## [1] &quot;branko1987@yahoo.com&quot; &quot;jaRULZ4EVR@gmail.nz&quot; &quot;lalaic1998@gmail.co.uk&quot; ## [1] &quot;pero.peric@fer.hr&quot; &quot;jaRULZ4EVR@gmail.nz&quot; &quot;lalaic1998@gmail.co.uk&quot; ## [4] &quot;perica.markic@fer.hr&quot; ## [1] &quot;fer.hr&quot; &quot;etfos.hr&quot; &quot;gmail.com&quot; &quot;yahoo.com&quot; &quot;gmail.nz&quot; ## [6] &quot;efzg.hr&quot; &quot;gmail.co.uk&quot; ## [1] &quot;715037@fer.hr&quot; &quot;206896@etfos.hr&quot; &quot;861759@gmail.com&quot; ## [4] &quot;278787@yahoo.com&quot; &quot;581691@gmail.nz&quot; &quot;258345@efzg.hr&quot; ## [7] &quot;618764@gmail.co.uk&quot; &quot;112453@fer.hr&quot; Finally, we learn one relatively useful function called str_split. This function splits the character string into a vector of character strings, depending on the given separator (which may be a space, some other chosen character(s), or even a regular expression), and is often used as a “more primitive” alternative to the read.csv andread.table functions when we want to parse the input “manually”, or - more commonly - to break a column of text into individual words for the purposes of text analysis. This function accepts a character string (or a collection of strings) as input, disassembles it according to the chosen separator and then returns the list of pieces as a result; if we disassemble only one string, we can easily translate the result into a vector using the unlist function. str_split(&quot;Example of str_split function&quot;, pattern = &quot;[:space:]&quot;) %&gt;% unlist ## [1] &quot;Example&quot; &quot;of&quot; &quot;str_split&quot; &quot;function&quot; We will now try to perform a very simple example of text analysis - figuring out which words happen most frequently in a chosen text. To do this we first need to read a text file into an R object. One of the simplest ways to achieve this is using the file function (which opens up the connection towards the textual file) and then the readLines function which will read a chosen number of lines and store them in a character vector. For smaller files we can also immediately read the entire file simply by omitting the number of lines we want to read. An example of using these two functions may look like this: con &lt;- file(&quot;textFile.txt&quot;, &quot;r&quot;) # r = &quot;read&quot; rows &lt;- readLines(con) # or readLines(con, n = 100) close(con) # closing the connection The next assignment will use two files HobbitChapterOne.txt - the text we want to analyse and stopwords.txt - file with frequent words which are “uninteresting” from the analysis point of view Exercise 10.19 - simple text analysis # store the text from `HobbitChapterOne.txt` into a variable called `hobbit` # and text from `stopwords.txt` into a variable called `stopwords` # perform the next steps: # - merge all text segments from `hobbit` into one long character strings # - remove all punctuation marks from the text # - change all text to &quot;lowercase&quot; (use `tolower`) # - split the text using spaces as a separator # - remove &quot;empty words&quot; (words of length 0) if such exist # - remove all words which are present in the `stopwords` variable too # - count the frequencies of the words # - print on screen 20 most frequent words # store the text from `HobbitChapterOne.txt` into a variable called `hobbit` # and text from `stopwords.txt` into a variable called `stopwords` con &lt;- file(&quot;HobbitChapterOne.txt&quot;) hobbit &lt;- readLines(con) close(con) con &lt;- file(&quot;stopwords.txt&quot;) stopwords &lt;- readLines(con) close(con) # perform the next steps: # - merge all text segments from `hobbit` into one long character strings # - remove all punctuation marks from the text # - change all text to &quot;lowercase&quot; (use `tolower`) # - split the text using spaces as a separator # - remove &quot;empty words&quot; (words of length 0) if such exist # - remove all words which are present in the `stopwords` variable too # - count the frequencies of the words # - print on screen 20 most frequent words hobbit %&gt;% str_c(collapse = &quot; &quot;) %&gt;% str_replace_all(&#39;[:punct:]&#39;, &#39;&#39;) %&gt;% tolower %&gt;% str_split(&#39;[:space:]&#39;) %&gt;% unlist -&gt; hobbit2 hobbit3 &lt;- hobbit2[!(hobbit2 %in% stopwords | nchar(hobbit2) == 0)] freq &lt;- table(hobbit3) %&gt;% sort(decreasing = T) freq[1:20] ## hobbit3 ## bilbo gandalf one thorin dwarves door baggins good hobbit little ## 39 36 36 34 31 27 25 25 25 24 ## long went know time away go old things come morning ## 24 23 20 19 17 17 17 17 16 16 Exercise Tasks The following tasks relate to the data set stored in the CSV file crimeSample.csv, which is a sample from the record of criminal incidents in the City of Philadelphia (the original data set can be found at this link ). The original set of columns was reduced and 1000 incidents were randomly sampled from the set of all observations. Before solving problems, load the data into the crimes data box and familiarize yourself with the data set (str,head, etc.) Convert the timestamp column from character type to POSIXct type. Add the following columns to the data frame: Year,Month, Hour. Fill in the columns with the appropriate information from the timestamp. Answer the question: in what month does the most crime occur? Which hour of the day is “most dangerous” according to the data? Answer the question: What is the percentage of incidents where the incident description contains the word burglary '' or robbery ’’? (tip: convert the entire crime description column to lowercase using the tolower() function. Print any unique four-digit numbers you can find on street names where a criminal incident is recorded. Let’s Program in Ru by Damir Pintar is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License . Based on work at https://ratnip.github.io/FER_OPJR/ "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
